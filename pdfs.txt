ArtificiaI Intelligence:  
How knowledge is created, 
transferred, and used
Trends in China, Europe, 
and the United States

Contents

Foreword 
Executive summary 
Highlights 
Introduction 

Chapter 1 
Identifying Artificial Intelligence 
research 
Using AI to define AI 

Chapter 2 
Artificial Intelligence:  
a multifaceted field  
2.1  Teaching, research, industry, and media perspectives 
2.2  Seven AI research clusters 

Chapter 3 
Artificial Intelligence research  
growth and regional trends   
3.1  Global trends in AI research 
3.2  Regional research trends in AI  
3.3  Regional research impact and usage comparison 
3.4  AI knowledge transfer 

4
8
10
12

18

20

24

26
27

30

32
38
54
56

Chapter 4 
Artificial Intelligence education   
4.1  A brief overview of online AI education 
4.2  Case study on AI graduates in China 

Chapter 5 
The imperative role of ethics  
in Artificial Intelligence    
5.1  Ethics and AI 
5.2  AI for the good and AI doing good: questions on  

ethics and AI  

Concluding remarks and future research  
Appendices  

62

64
66

70

72

76

79
81

3

Foreword
Artificial Intelligence:  
How knowledge is created, 
transferred, and used

Dan Olley, 
Chief Technology Officer (CTO), 
Elsevier, United States

“In recent years, artificial intelligence, or AI, has 
gained a surge in attention from policy makers, 
universities, researchers, corporations, media, 
and the public. Driven by advances in big data 
and computing power, breakthroughs in AI 
research and technology seem to happen almost 
daily. Expectations, but also fears, are mounting 
about the transformational power of AI to 
change society. In this whirlwind of attention 
and development, terms are getting confused. 
“artificial intelligence,” “machine learning,” and 
“data science” are often used interchangeably, 
yet they are not the same. AI is often intuitively 
understood as an umbrella term to describe the 
overall objective of making computers apply 
judgment as a human being would. Themes, 
such as deep learning, drop out of the AI 
umbrella to become their own research fields 
and technologies.

The confusion of terms, in a field with such 
potential to transform lives, needs to be 
addressed to ensure that policy objectives are 
correctly translated into research priorities, 
student education matches job market needs, 
and media can compare the knowledge being 
developed in various countries and regions 
across the globe. This is exactly the challenge we 
have set ourselves to tackle with this report. After 
all, we are an information analytics company 
focused on research and health, with data assets 
that can provide valuable insight into these 
important issues.

Powered by extensive datasets from our own 
and public sources—examined by our data 
scientists by applying machine learning on 
high-performance computing technology and 
validated in close collaboration with domain 
experts from research institutions and industry 
around the world—we have characterized the 
field of AI in a structured and comprehensive 
way. We then used this characterization to 
understand how AI knowledge is created, 
transferred, and used worldwide, with a focus 
on the “big 3” geographies: China, Europe, and 
the United States. We looked well beyond the 
traditional bibliometrics of published journal 
articles, examining also conferences, preprints, 
education, and competitions.

As I look at the resulting report, what most 
resonates with me is the section on approaches 
to AI, ethics, and responsible innovation. 
Traditional machine learning techniques rely 
on a human to decide what facets of the data 
are the most important to the model they are 
building. However, new techniques rely on the 
machine itself to decide what is important in 
the data to drive the required outputs. This is a 
fundamental shift as the focus moves from the 
design of the software program to the design of 
the training and testing data. This is important 
because as AI algorithms and models get more 
complex, there has understandably been a rise 
in the call for explainability. Why are we getting 

4

ARTIFICIAL INTELLIGENCE: HOW KNOWLEDGE IS CREATED, TRANSFERRED, AND USEDWith this report, we aim to make a contribution 
to the responsible development, dissemination, 
and use of AI knowledge for the benefit of 
society. This report marks the start of a wider 
engagement of RELX, both on our online AI 
resource center where more in-depth insights 
are available, and through our collaborations in 
the research community and beyond. As CTO of 
Elsevier, I look forward to further engaging with 
you in the future.”

a certain result? How and what has the machine 
seen as important in the data? Is there any 
unconscious bias in the result? 

Given the natural preconception that computers 
work with linear programs to give finite 
results, people often want to understand the 
“program flow” of the model. While there is 
some extremely valuable work going on to 
look inside the “black box” of modern machine 
learning techniques, this report clearly reveals 
a need to reset public preconceptions of how 
machines work with these new techniques, and 
the probabilistic results they give, to be able 
to properly discuss topics of ethics and bias. 
This change in mindset will shift the focus of 
the discussion to be as much about how we are 
designing our training of these machines to 
cover questions of ethics and bias as it is about 
peering into the models we have created to try 
and explain what has happened.

This is exactly what we now do at Elsevier with 
so-called “data squads”: new algorithms are 
developed by a multi-skilled team that combines 
knowledge of the machine learning algorithms 
being used, the domain being worked on, and 
software engineering, testing, and ethics. In this 
way, we ensure that we design the machine’s 
“training curricula” for the algorithm’s intended 
purpose, while being able to mitigate any 
unintended consequences.

5

Foreword

A source-based approach 
to measuring AI publication 
volume

Dr. Raymond Perrault, 
Senior Technical Advisor, 
Artificial Intelligence Center at 
SRI International, United States

“Counting publications in AI is difficult, as the 
field is notoriously tricky to bound. Russell and 
Norvig1 point out two main axes over which 
work is dispersed. The first goes from reasoning 
at one end to behavior at the other. The second 
restricts explanations to those that can be 
shown to closely reflect processes in humans 
(i.e., the cognitive science end) to those that are 
constrained by a broader appeal to rationality 
and optimization, and are more suitable to 
applications. Another obvious dimension is 
from research on new techniques to their 
applications in a wide range of domains. Since 
AI has absorbed basic techniques from so many 
fields (e.g., logic, probability and statistics, 
optimization, photogrammetry, neuroscience, 
and game theory, to name a few) and its methods 
are being applied in so many other fields (e.g., 
speech recognition, computer vision, robotics, 
cybersecurity, bioinformatics, and healthcare) it is 
not easy to draw a line between AI and fields both 
upstream and downstream from it. 
 
What should or should not be considered AI also 
changes over time. Before the late 1980s, natural 
language processing (based on Chomskian 
linguistics, related parsing techniques, and first-
order semantics) was definitely part of AI, and 
speech recognition (based on signal processing 
and Hidden Markov Models) was not. Both 
subareas are now largely driven by machine 
learning, and so are clearly within mainstream AI. 
 
If there is a basis for drawing a line around AI, 
I believe it rests in the social fabric of the field, 
as expressed by the sources where new work 
appears, namely its journals and conferences, 
tied together by researchers who tend to work 
in one or two subareas at a time and mostly 
publish in a small set of related sources. As one 
of these sources, the AI spectrum of conferences 

ranges from the traditional venues for symbolic 
AI, e.g., IJCAI,2 AAAI,3 ICAPS,4 and KR;5 to major 
venues for machine learning and probabilistic 
reasoning, e.g., NIPS,6 ICML,7 and UAI;8 to more 
independent application conferences such as 
KDD9 and SIGIR.10
 
Basing counts of publications on sources 
provides a way to systematically and transparently 
describe what is included in an area (e.g., AI), or a 
group core of areas (e.g., the subareas of AI, or all 
of computer science), and to systematically vary 
the breadth and granularity of the specifications 
of the cores. All the information necessary is 
in indexes such as Scopus®. Alternatively, this 
could be done by training classifiers operating 
on publication content, always with ground truth 
given by the core-based tags. 
 
This report follows this approach and applies 
multiple ways to shape and structure the field 
of AI. It is a very welcome contribution to 
understanding and monitoring the dynamics 
of an ever-emerging field. Systematizing and 
benchmarking the approaches over different 
sources and cluster algorithms would be 
interesting future research.”

1  Russell, S., Norvig, P. Artificial Intelligence: A Modern 

Approach. 3rd ed. Essex, UK: Pearson Education 
Limited; 2014.
International Joint Conference on Artificial Intelligence.

2 
3  Association for the Advancement of Artificial 

4 

Intelligence.
International Conference on Automated Planning and 
Scheduling.

International Conference on Machine Learning.

5  Principles of Knowledge Representation and Reasoning.
6  Neural Information Processing Systems.
7 
8  Uncertainty in Artificial Intelligence.
9  Knowledge Discovery in Databases.
10  Special Interest Group on Information Retrieval.

6

ARTIFICIAL INTELLIGENCE: HOW KNOWLEDGE IS CREATED, TRANSFERRED, AND USEDForeword

Defining AI: new approaches 
help with AI ontologies

Prof. Enrico Motta, 
Professor of Knowledge 
Technologies, The Open 
University, United Kingdom 

research communities, as it is the case, for 
instance, with work in the highly important area 
of AI ethics. 

On a personal level, this work is also very 
exciting for me because it provides the basis 
for interesting new research. One of my 
main research areas concerns the use of AI 
technologies to develop innovative solutions that 
can help people to make sense of the dynamics 
of scientific research. Within this broad context, 
my team has developed an original approach 
to the automatic generation of taxonomies of 
research areas and, for example, it would be 
extremely interesting to investigate to what 
extent these different methods can cover the 
research space and to what extent they can be 
combined to improve accuracy. This is just one 
example of the many interesting possibilities for 
further research opened up by this work.

In sum, this is not just an excellent piece of 
work, but also the start of a very interesting line 
of research. I congratulate the Elsevier team for 
their tremendous work and I look forward to 
further developments in this space.”

“Disciplines do not exist per se. They emerge 
because of a collective construction process, 
whereby a community of researchers comes 
together, formulating and sharing common 
objectives, methods, and conceptualizations. 
Hence, disciplines are essentially about 
research communities. As these evolve, so do 
the associated disciplines. Thus, attempts at 
characterizing disciplines are in my view more 
successful if they follow a bottom-up approach, 
focusing less on top-down definitions than on 
identifying the relevant body of work.

Given this premise, I am very happy to endorse 
this report produced by the Elsevier team, which 
provides an operational characterization of the 
field of AI, in terms of 600,000 documents 
and over 700 field-specific keywords. This 
is an impressive piece of work that, to my 
knowledge, provides the most comprehensive 
characterization of AI outputs produced so far. 
Crucially, in contrast with manually developed 
taxonomies of research areas, which inevitably 
end up reflecting the specific viewpoints 
of the experts involved in the process, this 
characterization is data-driven, using machine 
learning and text mining techniques to classify 
documents and identify the relevant keywords. 
Thus, in my view, the report enjoys greater 
validity, providing a more objective reflection 
of the variety of existing contributions to the AI 
field. 

In addition to its scientific value, there is also 
no doubt that this report will be a very valuable 
practical resource for people who wish to explore 
this space. For example, it will be very interesting 
to use this comprehensive characterization of 
the AI field to get a better understanding of key 
trends and topics, especially when the relevant 
body of work may be spread across different 

FOREWORD

7

Executive summary

The growing importance and relevance of artificial intelligence (AI) 
to humanity is undisputed: AI assistants and recommendations, 
for instance, are increasingly embedded in our daily lives. 
However, AI does not seem to have a universally agreed definition. 
Our classification methodology contributes to the understanding 
of an evolving field with a shifting structure. AI clusters around 
the areas of Search and Optimization, Fuzzy Systems, Natural 
Language Processing and Knowledge Representation, Computer 
Vision, Machine Learning and Probabilistic Reasoning, Planning 
and Decision Making, and Neural Networks.

While the field spans several domains and can be viewed from 
different standpoints, such as teaching, research, industry, and 
media, there seems to be little overlap in vocabulary between these 
perspectives. Industry tends to emphasize algorithms, possibly for 
efficient gains in time and human labor. The increasing societal 
relevance of AI and potential ethical concerns raised by the 
growing use of algorithms reflect the visibility of applications and 
ethics themes in the media, which makes AI more imperative and 
intuitive to the public. Interestingly, ethics keywords are also more 
heavily represented in teaching, potentially as a result of public 
interest and some government mandates, like in The Netherlands. 
In AI research, ethics keywords are currently not explicitly 
visible, which poses the question of whether ethical analysis is 
forthcoming among AI researchers, whether such discussions 
are conducted outside of the AI field, or whether they take place 
outside of research altogether. This observation is noteworthy, 
as responsible innovation in AI is crucial to ensure safe and fair 
outcomes for all.

The apparent lack of a common language across perspectives calls 
into question the quality of understanding and communication 
across the AI field. With closer and instant collaboration across 
geographies and sectors, research dialogue shifts away from 
traditional sequential translation and towards parallel dialogues, 
online and through media and social media channels. New 
stakeholders, such as students, freelancers, and citizens, become 
involved in research, for example, on competition platforms like 
Kaggle. A common language and understanding would better 
connect actors in the AI ecosystem.

AI has also emerged as an area of importance for national 
competitiveness. Several national and international AI policies and 
strategies have been put forth in recent years, as both causes and 
consequences of growing AI research ecosystems. This has led 
to increased scientific output through a variety of dissemination 
modes, including publications, preprints, conferences, 
competitions, and software. 

There are strong regional differences in AI activity. China aspires 
to lead globally in AI and is supported by ambitious national 
policies. A net brain gain of AI researchers in China also suggests 
an attractive research environment. China’s AI focuses on 
computer vision and does not have a dedicated natural language 
processing and knowledge representation cluster, including 
speech recognition, possibly because this type of research in 
China is conducted by corporations that may not publish as many 
scientific articles. It shows robust growth of its research and 
education ecosystems, with a rapid rise in scholarly output and 
similar research usage as other regions. China’s AI research has a 
rapidly increasing yet still comparatively low citation impact, which 
could be a symptom of regional, rather than global, reach. This 
is also apparent through its relatively low levels of international 
collaboration and mobility in research, which yield a comparatively 
small but highly cited corpus of AI research. As in many other 
research areas, collaboration is key to success, as demonstrated 
by increasing discussions on global social media and growing 
international AI competition numbers.

Europe is defined in this report as the 44 countries belonging 
to the European Union (EU) and associated countries eligible 
for Horizon 2020 funding. It is the largest region in AI scholarly 
output, with high and rising levels of international collaborations 
outside of Europe, but appears to be losing academic AI talent, 
especially in recent years. The broad spectrum of AI research in 
Europe reflects the diversity of European countries, each with their 
own agenda and specialties. Focus areas of European AI research 
include genetic programming for pattern recognition, fuzzy 
systems, and speech and face recognition. Deep learning research 
in Europe appears less connected to other subfields than it is in 
other regions, and AI robotics in Europe appear to be embedded in 
the machine learning cluster. 

8

ARTIFICIAL INTELLIGENCE: HOW KNOWLEDGE IS CREATED, TRANSFERRED, AND USEDThe United States corporate sector attracts talent and is strong in 
AI research, possibly due to their cross-sector joint labs tradition. 
The United States academic sector is also robust, both in terms of 
scholarly output and talent retention. The country appears to be 
leading the way in international AI competitions, and United States 
researchers increasingly collaborate internationally on AI research. 
AI in the United States has a strong focus on specific algorithms 
and separates speech and image recognition into distinct clusters. 
The corpus shows less diversity in AI research than Europe but 
more diversity than China. 

Among other key contributors in AI, we note the rapid emergence 
of India, today the third largest country in terms of AI publications 
after China and the United States. Iran is ninth in publication 
output in 2017, on par with countries like France and Canada. Last 
year, Russia surpassed Singapore and The Netherlands in research 
output, yet remains behind Turkey. Germany and Japan remain 
fifth and sixt largest producers of AI research globally.

In this report, we provide insights for the benefit of research 
evaluators, research funders, policy makers, and researchers. We 
use a bottom-up approach to delineate the research fields of AI 
and invite further collaborative research on corpus definition. Our 
analysis also raises several questions of interest for potential future 
investigations: 

•  Is there a relationship between research performance in AI and 
research performance in more traditional fields that support AI 
(such as computer science, linguistics, mathematics, etc.)? 
•  How does AI research translate into real-life applications, 

societal impact, and economic growth? 

•  Where do internationally mobile AI researchers come from and 

go to? 

•  How sustainable is the recent growth in publications and how 
will countries and sectors continue to compete and collaborate?

9
9

Highlights

The field has grown annually by 5.3% in the 
last decade and 12.9% in the last 5 years. It 
has emerged as an area of importance for 
national competitiveness, yet also sees growing 
international collaboration. Europe is still the 
largest actor in AI research, despite rapid growth 
and ambition from China, while the United States 
supports a strong corporate sector alongside 
academia.
 introduction & chapter 3 

Artificial intelligence research focuses on 
Search and Optimization, Fuzzy Systems, 
Natural Language Processing and Knowledge 
Representation, Computer Vision, Machine 
Learning and Probabilistic Reasoning, Planning 
and Decision Making, and Neural Networks.
 chapter 2 

There is increasing societal relevance of AI, 
particularly notable in small but growing 
application fields like health sciences, 
agriculture, or the social sciences; high public 
interest is reflected in social media and blog 
mentions. Despite this societal relevance, 
ethics is not yet strongly reflected in the 
research corpus, although recent conferences 
reveal a growing focus on ethics.
 chapters 3 & 5 

10

ARTIFICIAL INTELLIGENCE: HOW KNOWLEDGE IS CREATED, TRANSFERRED, AND USED11

The United States corporate sector attracts 
talent and is strong in research, possibly due 
to their cross-sector joint labs tradition. The 
academic sector is also robust, both in terms of 
scholarly output and talent retention.
 chapter 3 

Among other key countries in AI research, we 
note the rapid emergence of India, today the 
third largest producer of AI publications after 
China and the United States. 
 chapter 3 

China aspires to lead globally in AI and is 
supported by ambitious policies and rapid 
growth, especially in computer vision and fuzzy 
systems. A recent brain gain of AI researchers 
also suggests an increasingly attractive 
research environment, and citation impact is 
also growing. However, compared to other 
regions, China’s research appears to have a 
regional, rather than global, reach.
 introduction & chapter 3 

Europe is the largest and most diverse region 
in terms of AI scholarly output, with high and 
rising levels of international collaborations 
outside of Europe. However, Europe appears to 
be losing AI talent in recent years, especially in 
academia.
 chapter 3 

11

Introduction

The field of artificial intelligence (AI) is broad, dynamic, and rapidly 
evolving, and is producing technologies with enormous global 
societal implications. 11, 12, 13, 14  For example, advances in facial and 
speech recognition have produced virtual assistant technologies 
that are being integrated into daily life like Siri, Alexa, Google, 
iFLYTEK, and Baidu.15  AI-based recommender systems have 
revolutionized online search optimization and digital ad targeting. 
In the realm of image interpretation, AI is improving medical 
image analysis for rapid and accurate diagnoses and treatment 
planning.16 Research in AI is both theoretical and applied, and 
transcends traditional disciplinary boundaries, bringing together 
experts from diverse fields of study.17

Clarifying the scope and activity within this large field can help 
research leaders, policy makers, funders and investors, and the 
public navigate AI and understand how it has evolved over time. 
This effort may also provide clues as to where AI is headed and 
how policies might be shaped to continue making advances in a 
responsible way. For this report, Elsevier used High-Performance 
Computing Cluster (HPCC) developed at RELX and drew on their 
analytic expertise as well as insights from internal and external 
experts in AI research and application. This combined approach 
allowed us to ask, “How is knowledge in AI created, transferred, 
and used?” 

11  World Economic Forum. Artificial Intelligence and Robots. https://toplink.

weforum.org/knowledge/insight/a1Gb0000000pTDREA2/explore/summary.
12  Abbany, Z. What good is AI for UN development goals? DW. May 16, 2018. 

https://p.dw.com/p/2xllV.

13  Schwab, K. The 4th Industrial Revolution. New York, NY: World Economic 

Forum. 2016.

14  Hager, G.D., et al. Artificial Intelligence for Social Good. Washington, DC: 

Computing Community Consortium; 2017.  
https://cra.org/ccc/wp-content/uploads/sites/2/2016/04/AI-for-Social-Good-
Workshop-Report.pdf.

15  Adams, R.L. 10 Powerful Examples of Artificial Intelligence in Use Today. 

Forbes. 10 January 2017.  
https://www.forbes.com/sites/robertadams/2017/01/10/10-powerful-examples-
of-artificial-intelligence-in-use-today/#5590a7c9420d.

16  Gray, A. 7 Amazing Ways Artificial Intelligence is Used in Healthcare. World 

Economic Forum. 20 September 2018.  
https://www.weforum.org/agenda/2018/09/7-amazing-ways-artificial-
intelligence-is-used-in-healthcare/.

17  Cockburn, I.M., et al. The impact of artificial intelligence on innovation. 
National Bureau of Economic Research. Working paper No. 2449; 2018. 
http://www.nber.org/papers/w24449.pdf.

Alessandro Annoni 
Head of Digital Economy 
Unit, Joint Research Centre, 
European Commission 

“We are only at the beginning of a rapid 
period of transformation of our economy and 
society due to the convergence of many digital 
technologies. Looking at the world of digital 
transformation, we live in an era that can be 
defined as the “Cambrian explosion of data”, 
and advanced data analytics are needed for us to 
navigate this world. AI is central to this change 
and offers major opportunities to improve our 
lives but ethical and secure-by-design algorithms 
are crucial to building trust in this disruptive 
technology. We also need a broader engagement 
of civil society on the values that need to be 
embedded in AI and the directions for future 
development.”

12

ARTIFICIAL INTELLIGENCE: HOW KNOWLEDGE IS CREATED, TRANSFERRED, AND USEDAI as a field brings together several domains—teaching, research, 
industry, and the media. AI discoveries and new technologies 
become core milestones in AI history, media reports influence 
public opinion, and the voices of various stakeholders influence 
policy. Breakthroughs bump up the hype (and research funding) 
surrounding AI, causing both excitement and concerns around 
adoption, including the potential for loss of jobs, privacy and 
control, misuse, and reaching “the singularity”—the point at 
which a machine can improve itself, independent of humans.18, 19  
With each advance, researchers, industry, and policy makers are 
asked to balance the transformational potential of AI with human 
safety and privacy.

While AI is a high priority on the agendas of policy makers and 
research and industry leaders and attracts daily news attention,  
it also lacks a universal definition. In the broadest terms, AI 
refers to the creation of machines (agents) that think and act like 
humans.20, 21, 22, 23, 24  We can also differentiate between weak AI, i.e., 
machines that can simulate thinking within a narrow context to 
accomplish a specific task, and strong AI, i.e., intelligent machines 
that can reason. Yet, per Stanford’s AI100 report,25 “the lack of a 
precise, universally accepted definition of AI probably has helped 
the field to grow, blossom, and advance at an ever-accelerating 
pace.” 

The dynamic nature of AI is reflected in the so called “AI effect,” 
which, according, to Hofstadter,26 means that “AI is whatever 
hasn't been done yet.” Today, emphasis is often on what AI can 
do: practitioners in AI focus on “the problems it will solve and 
the benefits the technology can have for society. It’s no longer 
a primary objective for most to get to AI that operates just like 
a human brain, but to use its unique capabilities to enhance 
our world.”27 This focus on applications also means that many AI 
research outputs are found in non-AI journals or conferences. 
For these reasons, Elsevier took a “bottom-up” approach to 
characterize AI research, starting its analysis from the various 
domains in which AI is applied rather than relying on a single 
definition of AI. 

The structure of the document is as follows. In the remainder 
of this chapter we give an overview of recent national policies in 
AI, reflecting the importance of AI to governments. Chapter one 
describes how we have, in the absence of a clear definition for AI, 
identified the relevant body of research published. In chapter two, 
we provide information on research areas that together make up 
AI. In chapter three, we use the research corpus from chapter one 
to identify global and regional trends as well as explore knowledge 
transfer. Chapter four takes a look at AI education, and chapter five 
reflects on ethics in AI. Finally, in the conclusion we suggest areas 
for further research.

18   Walsh, T. Machines that Think. Amherst, NY: Prometheus Books; 2018.
19  Tegmark M. Life 3.0: Being Human in the Age of Artificial Intelligence. New York, 

NY: Knopf; 2017.

20  McCarthy, J., et al. A Proposal for the Dartmouth Summer Research Project 

on Artificial Intelligence. 1955.  
http://raysolomonoff.com/dartmouth/boxa/dart564props.pdf.

21  Cellan-Jones, R. Artificial intelligence - hype, hope and fear. BBC News, p. 3. 

16 October 2017. http://www.bbc.co.uk/news/technology-41634316.

22   Russel, S., Norvig, P. Artificial Intelligence: A Modern Approach. 3rd ed. Essex, 

UK: Pearson Education Limited; 2014.

23  Searle, J.R. Minds, brains, and programs. Behav Brain Sci. 1980;3(3):417-457. 

https://doi.org/10.1017/S0140525X00005756.

24  Encyclopedia Britannica. Artificial intelligence. Encyclopedia Britannica. 2018. 

https://www.britannica.com/technology/artificial-intelligence.

25  Stanford. AI100 Report. 2017.  

https://ai100.stanford.edu/2016-report/section-i-what-artificial-intelligence/
defining-ai. 

26  Hofstadter, D. Gödel, Esher, Bach: An Eternal Golden Braid. New York, NY: 

Basic Books, Inc. 1979.

27  Marr, B. The Key Definitions of Artificial Intelligence (AI) That Explain Its 

Importance. Forbes. 14 February 2018.  
https://www.forbes.com/sites/bernardmarr/2018/02/14/the-key-definitions-of-
artificial-intelligence-ai-that-explain-its-importance/#6268887e4f5d

13

Introduction

National strategies 
and policies in AI

The capacity for AI research, technology, and application is seen as 
vital to national competitiveness, security, and economic strength. 
In the last two years alone, several countries and regions have 
developed and released AI strategic plans, essentially setting up 
a race to become the global leader in the field.28 These strategies 
generally call for more investment to build the AI workforce and 
research and development capacity; anticipate how AI will change 
jobs and economies; and examine the social, economic, and ethical 
implications of AI.

AI policies developed as part of these national strategies vary 
widely from country to country, but focus on several elements: 
governance and regulation, ethics, security, and research, among 
others. Here we describe some of the specific research and 
innovation policies in AI, and the differences between countries 
and regions across the world. It is worth noting that where 
the United States and European governments seem to take a 
supportive role with AI policies that encourage research and 
industry, the Chinese government takes a more active role in 
determining the direction of AI in the country. Several countries, 
including Canada, the United States, China, Japan, and several in 
Europe allocate dedicated funding to achieving their strategies. 

China issued its New-Generation Artificial Intelligence Development 
Plan29 in July 2017, with key targets for the AI field through 
2030 and the goal to become a world leader in AI theory, 
technology, and application. The three-year action plan focuses on 
strengthening its manufacturing capabilities and support systems 
and attracting and training a skilled AI workforce. The Chinese 
government budgeted over $2 billion for major R&D programs 
in 201830 and announced a $2.1 billion investment into an AI 
technology park in Beijing. In addition to these R&D investments, 
large datasets (consistent with the size of the Chinese population) 
and a relaxation of data regulations have created an advantage 
for China. Chinese corporate giants such as Baidu, Alibaba, and 
Tencent are also investing in AI research, alongside investment 
firms such as Sinovation Ventures,31 which established an AI 
Institute in 2016. 

In April 2018, the European Commission (EC) outlined a three-
pronged approach to AI: increase public and private investment in 
AI, prepare for socio-economic changes, and ensure an appropriate 
ethical and legal framework. They also called for cooperation across 
member states as a “European AI Alliance.” The EC announced 
that it would increase its AI research investment to €1.5 billion for 
the 2018-2020 period under the Horizon 2020 program. Per the 
commission, “this investment is expected to trigger an additional 
€2.5 billion of funding from existing public-private partnerships, 
for example, on big data and robotics.”32 The European Union 
(EU) member states also signed a Declaration of Cooperation on 
Artificial Intelligence33 on issues such as research, socio-economic 
challenges, and legal and ethical frameworks. The importance 
of AI to the EC is visible through the Joint Research Centre's 
2018 AI report, which investigates a broad range of industrial, 
business, and research activities (including patenting, frontier 
research, venture capital, start-ups, and public funded projects).34 

28   Dutton, T. An Overview of National AI Strategies. Medium Politics + AI. 28 June 

2018. https://medium.com/politics-ai/an-overview-of-national-ai-strategies-
2a70ec6edfd.

29  The State Council. The People’s Republic of China. China issues guidelines 

on artificial intelligence development. 20 July 2017. http://english.gov.cn/
policies/latest_releases/2017/07/20/content_281475742458322.htm. 
30  China to spend over USD 2 billion in R&D this year. The Economic 
Times. 7 January 2018. https://economictimes.indiatimes.com/news/
international/business/china-to-spend-over-usd-2-billion-in-rd-this-year/
articleshow/62403032.cms. 

31  Sinovation Ventures AI Engineering Institute. http://ai.chuangxin.com/. 
32  European Commission. Artificial intelligence: Commission outlines a 

European approach to boost investment and set ethical guidelines. 25 April 
2018. http://europa.eu/rapid/press-release_IP-18-3362_en.htm.

33  European Commission. EU Member States sign up to cooperate on artificial 

intelligence. 10 April 2018. https://ec.europa.eu/digital-single-market/en/
news/eu-member-states-sign-cooperate-artificial-intelligence.

34  Craglia M. (Ed.), Annoni A., Benczur P. et al. 2018. Artificial Intelligence: A 

European Perspective, Luxembourg: Publications Office 

14

ARTIFICIAL INTELLIGENCE: HOW KNOWLEDGE IS CREATED, TRANSFERRED, AND USED35  AI for Humanity. French strategy for artificial intelligence.  

https://www.aiforhumanity.fr/en/.

36  Artificial intelligence: Making France a leader. 30 March 2018. https://www.

gouvernement.fr/en/artificial-intelligence-making-france-a-leader. 

37  The Agency for Digital Italy (AGID). Artificial Intelligence at the Service of 

Citizens. 2018. https://ia.italia.it/assets/whitepaper.pdf.

38  AI Hub Europe. Exclusive: German AI-Strategy Paper in English. 26 July 2018. 

http://ai-europe.eu/exclusive-german-ai-strategy-paper-in-english/.

39  HM Government. Industrial Strategy: Building a Britain Fit for the Future. 
2017. https://assets.publishing.service.gov.uk/government/uploads/system/
uploads/attachment_data/file/664563/industrial-strategy-white-paper-web-
ready-version.pdf.

40  Department for Business, Energy & Industrial Strategy, Department for 

Digital, Culture Media & Sport. Policy paper: AI Sector Deal. 26 April 2108. 
https://www.gov.uk/government/publications/artificial-intelligence-sector-
deal/ai-sector-deal#executive-summary.

41  Ministry of Economic Affairs and Employment. Finland’s Age of Artificial 

Intelligence. 2017. http://julkaisut.valtioneuvosto.fi/bitstream/
handle/10024/160391/TEMrap_47_2017_verkkojulkaisu.pdf.

42  Ministry of Industry, Business and Financial Affairs. New Strategy to Make 

Denmark the New Digital Frontrunner. 30 January 2018.  
https://eng.em.dk/news/2018/januar/new-strategy-to-make-denmark-the-
new-digital-frontrunner/.

43  Government Offices of Sweden. National Approach for Artificial Intelligence. 

2018. https://www.regeringen.se/informationsmaterial/2018/05/nationell-
inriktning-for-artificiell-intelligens/. 

44  Executive Office of the President National Science and Technology Council 

Committee on Technology. Preparing for the Future of Artificial Intelligence. 
October 2016. https://obamawhitehouse.archives.gov/sites/default/files/
whitehouse_files/microsites/ostp/NSTC/preparing_for_the_future_of_ai.pdf.

45  National Science and Technology Council, Networking and Information 

Technology Research and Development Subcommittee. The National Artificial 
Intelligence Research and Development Strategic Plan. October 2016.  
https://www.nitrd.gov/PUBS/national_ai_rd_strategic_plan.pdf.

46  The White House Office of Science and Technology Policy. Summary of the 
2018 White House Summit on Artificial Intelligence for American Industry. 
10 May 2018. https://www.whitehouse.gov/wp-content/uploads/2018/05/
Summary-Report-of-White-House-AI-Summit.pdf . 

Many AI strategies have also emerged at the national level in EU 
member states in recent years, resulting in a diversity of plans and 
approaches in the region. France recently declared AI a national 
priority35 and announced a strategic plan For a Meaningful Artificial 
Intelligence.36 In March 2018, Italy released Artificial Intelligence 
at the Service of Citizens37 and the German government is due 
to release a national AI strategy in December 2018.38 The United 
Kingdom (UK) published its Industrial Strategy39 in November 
2017 and its Artificial Intelligence Sector Deal in April 2018.40 
Other European countries that have recently released national 
strategies or reports on AI include Finland (Finland’s Age of Artificial 
Intelligence41), Denmark (New Strategy to Make Denmark the New 
Digital Frontrunner42), and Sweden (National Approach for Artificial 
Intelligence43).

Interest in AI in the United States (US) was signaled by the 
release of a report from the National Science and Technology 
Council (Preparing for the Future of Artificial Intelligence43) in 
October 2016. The report noted that unclassified research on AI 
was being managed through the Networking and Information 
Technology Research and Development programme, supported 
by several federal funding agencies. At the time of the report, 
federal investment in unclassified AI research was estimated 
to be at US$1.2 billion and it was recommended that future 
investment should focus on basic research and long-term, high-
risk initiatives, as the private sector investment in R&D would be 
limited. The National Artificial Intelligence Research and Development 
Strategic Plan45 that accompanied the report set several objectives 
for federally funded AI research, such as ensuring effective 
human-AI collaboration, developing shared public datasets, and 
measuring and evaluating AI technologies through standards 
and benchmarks. In 2018, the White House hosted the “Artificial 
Intelligence for American Industry”46 summit, which promoted a 
“free market approach to scientific discovery that harnesses the 
combined strengths of government, industry, and academia” and 
examined “new ways to form stronger public-private partnerships 
to accelerate AI R&D.” AI was included as a priority area in FY19 
budget, particularly funding for projects focused on transportation, 
healthcare, workforce training, and military applications.

INTRODUCTION

15

Strategic planning in AI is underway in several other countries.47 
Canada became the first country to release a national AI strategy 
in 2017. The United Arab Emirates also launched an AI strategy 
in 2017, the first country to do so in the Middle East. In 2018, 
India released its national AI strategy,48 while Japan unveiled 
its Artificial Intelligence Technology Strategy in March 201749, 
and the South Korean government announced a five-year plan 
to invest in and strengthen AI research and development. AI 
plans and programmes are in various stages of development in 
Malaysia, Singapore, and Taiwan. Mexico and Russia have released 
research priorities and strategic outlines while Tunisia and Kenya 
have formed task forces to examine the development of AI in 
Africa. Several Nordic and Baltic countries formed a regional 
collaboration in 2018 to develop AI capacity. Together, these efforts 
underscore the growing recognition by individual countries and 
regions of the potential impact of AI on society and human life and 
the need to develop knowledge and expertise in this field.

47  Dutton, T. An Overview of National AI Strategies. Medium Politics + AI. 28 June 

2018. https://medium.com/politics-ai/an-overview-of-national-ai-strategies-
2a70ec6edfd.

48  NITI Ayog. Discussion Paper: National Strategy for Artificial Intelligence. 

June 2018. http://www.niti.gov.in/writereaddata/files/document_publication/
NationalStrategy-for-AI-Discussion-Paper.pdf.

49  Strategic Council for AI Technology, Artificial Intelligence Technology 
Strategy, March 2017, http://www.nedo.go.jp/content/100865202.pdf.

16

ARTIFICIAL INTELLIGENCE: HOW KNOWLEDGE IS CREATED, TRANSFERRED, AND USEDInterview

Dr. Zhiyun Zhao
National New-Generation 
Artificial Intelligence 
Development Research Center, 
Ministry of Science and 
Technology of the People’s 
Republic of China, Institute 
of Scientific and Technical 
Information of China (ISTIC) 

What is the China National New Generation 
Artificial Intelligence Development Research 
Center? 
In July 2017, the State Council issued its “New-
Generation Artificial Intelligence Development 
Plan,” which proposed that a new Artificial 
Intelligence Planning and Promotion Office 
would be run through the Ministry of Science and 
Technology. The Ministry would be responsible 
for “promoting the construction of artificial 
intelligence think tanks and supporting various 
think tanks to carry out labor, [as] research on 
major issues of intelligence provides strong 
intellectual support for the development of 
artificial intelligence.” To implement the plan, the 
Ministry of Science and Technology coordinated 
research strengths across relevant internal 
and external departments, and established the 
National New-Generation Artificial Intelligence 
Development Research Center. This Center is 
a high-end AI research platform established 
to accelerate AI development planning and 
strengthen the strategic research support of AI 
development on a national scale. By bringing 
together both domestic and foreign research 
forces, especially young AI talent, we will establish 
a stable and sustained strategic research team to 
further strengthen AI research and evaluation. 

What is China’s AI strategy? How can it 
be realized? How can it evolve to remain 
successful? 
China’s new AI strategy aims to establish the 
first mover advantage through top level and 
systematic AI deployment in three steps. By 2020, 
China’s overall AI technology and application will 
be globally competitive. By 2025, we expect to 
achieve major breakthroughs in the basic theory 
of AI, and our AI technology and application will 
be among the world’s best. By 2030, China will be 
the world’s major innovation center in AI theory, 

technology, and application. The establishment 
of these objectives was based on the current 
strong foundation of AI development in China. 
China's AI development strategy puts forward 
an overall framework of “building a system, 
grasping dual attributes, adhering to the trinity, 
and strengthening the four major supports.” 50 
This strategy considers the current status of AI 
technology and the overall economic and social 
development of China.

What is China’s AI policy? How is it determined? 
How can it adapt to the fast-changing AI 
landscape? 
In order to follow through with our AI strategy and 
achieve our “three-step” goals, we have increased 
the resource allocation and special policies for 
AI. First, it is necessary to make full use of the 
existing funds and other stock resources, to 
increase the support of the central financial 
funds to guide multi-channel capital investment 
in the market, and to build several international 
leading innovation bases in the AI field. Second, 
we need to propose special safeguard measures 
through laws and regulations, ethical norms, key 
policies, intellectual property rights and standards, 
regulatory assessment, labor training, and popular 
science. We also need to integrate industrial 
policies, innovation policies, and social policies 
to achieve coordination of incentive development 
and rational regulation. Of course, we also fully 
realize that the continuous improvement and 
acceleration of AI development means that its 
impact on economic, social, legal, ethical, and 
other aspects cannot be clearly defined in the 
short term. Creating and implementing policy at 
such a fast pace is a global challenge. 

50  State Council Issued Notice of the New Generation 
Artificial Intelligence Development Plan. 8 July 2017. 
https://flia.org/wp-content/uploads/2017/07/A-New-
Generation-of-Artificial-Intelligence-Development-
Plan-1.pdf

17

Chapter 1

Identifying 
Artificial 
Intelligence 
research

The AI field has multiple definitions, but lacks a universally 
agreed understanding. AI means different things to different 
people: there are more differences than commonalities in 
how AI is spoken about in education, research, industry, 
and the media. This chapter describes our methodology for 
characterizing the field and determining what is in and what is 
out of scope.

18

ARTIFICIAL INTELLIGENCE: HOW KNOWLEDGE IS CREATED, TRANSFERRED, AND USEDHighlights

More than 600,000 AI scholarly publications 
extracted using AI technologies.

Core AI keywords with a large proportion of AI 
scholarly publications include Back-propagation 
Neural Network, Genetics-based Machine 
Learning, Cohen-Grossberg Neural Networks, 
Back-propagation Algorithm, Neural Networks 
Learning.

19

Using AI to define AI

Examining which words are used to talk about AI from the 
perspectives of teaching, research, industry, and the media, we see 
that there is not one common definition for AI: its meaning differs 
depending on the outlook with which it is approached.51,52,53 

How is AI 
being taught?

In many studies analyzing research dynamics, either a journal 
category or a keyword approach verified by experts is used to 
define a research area.54 Extracting keywords from bodies of text 
from different perspectives (see Figure 1.1) allows us to reduce 
personal bias as well as take a view of the field that goes beyond 
research only. The width and breadth of the AI field, combined 
with its undefined and pervasive nature, however, makes manual 
approaches challenging and time-consuming. Therefore, following 
consultation with external AI experts, we chose to employ 
supervised AI techniques to further gain speed and efficiency. This 
methodology also allowed us to maintain the width and breadth 
of AI keywords, while sharpening the precision of the resulting 
research corpus of publications. The details of our methodology 
are explained in separate technical documentation on the Elsevier 
AI Resource Center.55  

51   McKinsey Global Institute. Artificial Intelligence – The Next Digital 
Frontier? June 2017. https://www.mckinsey.com/~/media/McKinsey/
Industries/Advanced%20Electronics/Our%20Insights/How%20artificial%20
intelligence%20can%20deliver%20real%20value%20to%20companies/MGI-
Artificial-Intelligence-Discussion-paper.ashx. 

52  Clarivate Analytics. Artificial Intelligence – The Innovators and Disruptors for 

Next Generation Digital Transformation. 11 September 2017.  
https://clarivate.com/blog/ip-solutions/artificial-intelligence-innovators-
disruptors-next-generation-digital-transformation/. 

53  OECD. OECD Science, Technology and Industry Scoreboard 2017: The Digital 

Transformation. Paris, France: OECD Publishing; 2017.  
https://doi.org/10.1787/9789264268821-en. 

54  See e.g., Elsevier. A Global Outlook on Disaster Science. 2015. 
https://www.elsevier.com/__data/assets/pdf_file/0008/538091/
ElsevierDisasterScienceReport-PDF.pdf; Elsevier. Sustainability Science in 
a Global Landscape. 2017. https://www.elsevier.com/__data/assets/pdf_
file/0018/119061/SustainabilityScienceReport-Web.pdf; or the above-mentioned 
reports from McKinsey Global Institute and Clarivate Analytics.

55  Elsevier. Artificial Intelligence Resource Center. https://www.elsevier.com/

connect/ai-resource-center.

How is AI being 
researched?

Teaching

M

e

dia

Rese

a
r
c

h

Industry

How is AI being 
talked about in 
media?

How is AI being 
described in 
patents?

figure 1.1  
We extracted keywords from texts reflecting 
four perspectives on AI to define the field.

20

ARTIFICIAL INTELLIGENCE: HOW KNOWLEDGE IS CREATED, TRANSFERRED, AND USED- Expert input
- Meta-data like 
   journals, title, abstract

„,…(cid:9)(cid:9) gold set 

training documents

†(cid:9)(cid:9) 

keywords

(cid:10)m 

documents
from Scopus

Supervised
classifier

Teaching
textbook, structure, 
MOOCs

Research
government expert 
panels

Industry
patent analysis

Media
news article 
concepts

(cid:20)(cid:19)(cid:19),(cid:19)(cid:19)(cid:19) long list 
of keywords and 
concepts
- de-duplication
- consolidating 
   keywords into 
   concepts 
   (Finger Printing)
- expert review

(cid:10)(cid:9)(cid:9),(cid:9)(cid:9)(cid:9)

AI

documents

Fields and 
structure of 
AI research

AI research 
topics

Metrics on AI 
publications

Identify relevant AI 

documentation

Extract and re€ne 

keywords

Identify all relevant 

publications

Optimize the 

resulting article list

Search for keywords in 

publication corpus

figure 1.2  
Process followed for selecting relevant 
AI publications for our analyses.

We mined the text and structure of representative books, the 
syllabi of massive open online courses (MOOCs), patents, news 
items and included keywords from research experts. To identify 
meaningful concepts, we used the Elsevier FingerPrint Engine™, 
which reduced this long list to 20,000 concepts. The list of 
concepts was shortened to 797 unique keywords following manual 
review (Figure 1.2).

We searched for each keyword in the titles, abstracts, and keywords 
of documents included in a Scopus May 2018 dataset, retrieving 5.7 
million unique documents, including many false positives related 
to application terms (e.g., “finite elements”), broad terms (e.g., 
“ethical values”), or similar terms from other fields (e.g., “neural 
networks” in biology).

The Elsevier Fingerprint Engine™ identifies concepts 
and their importance in any given text by using a wide 
range of thesauri and data-driven controlled vocabularies 
covering all scientific disciplines, and by applying a variety 
of natural language processing (NLP) techniques. The 
advantage of using this technology is that the resulting 
terms are of high quality and more representative than 
standard sets of keywords, which often contain duplicates, 
synonyms, and irrelevant terms

USING AI TO DEFINE AI

21

In summary, our method still requires a pre-defined, trusted 
input of AI documents as either a clustering starting point or a 
gold standard for classifier training. Those inputs could be sets 
of articles/conference papers or a group of authors. We used a 
keyword and a supervised classification approach to identify them. 
Further research might evaluate and optimize starting points 
and algorithms to shape and structure the field more sharply and 
broadly. 

In line with recommendations of leading associations, like CRA56 
or Informatics Europe,57 we stress that the results should not be 
used to assess individual researchers’ productivity or performance. 
Rather, the metrics provide aggregate, descriptive trends and 
findings at the institutional or country level. 

We used supervised machine learning with further expert input on 
the training data set to eliminate false positives from the corpus 
while retaining relevant AI documents. The 797 keywords were 
ranked as high, medium, or low with regards to relevancy to the 
core field of AI and were assigned a respective weight. Figure 1.3 
provides examples of the keywords and their ratings, alongside 
their share of AI and non-AI publications.

We employed a standard machine learning approach to train and 
evaluate our classifier model. In parallel, 1,500 documents were 
manually classified by internal experts as either “AI” or “non-AI” to 
use as reference and training input for the algorithm to determine 
the classification. This gold set of documents was randomly 
partitioned to keep a subset of known answers out of the example 
data used to train the model. These holdout examples were then 
fed into the trained classifier to obtain predictions for those 
documents. These predictions were then compared to the known 
class for each example, revealing that the model identified AI 
documents with 85% precision compared to the set of documents 
initially classified by AI experts. The complete set of 5.7 million 
documents was run through the model to generate predictions 
that were used to reduce the number identified as AI documents to 
approximately 600,000. 

56  Computing Research Association. https://cra.org/. 
57   Esposito, F., et al.; for the Informatics Europe Research Evaluation Working 

Group. Informatics Research Evaluation. 20 October 2017.  
http://www.informatics-europe.org/component/phocadownload/category/10-
reports.html?download=63:research_evaluation_draft_20oct17. 

22

ARTIFICIAL INTELLIGENCE: HOW KNOWLEDGE IS CREATED, TRANSFERRED, AND USEDMore than 600,000 
AI scholarly 
publications 
extracted using  
AI technologies.

…„
‰Š

Š
‡
ƒˆ

‡‡‹
‰ˆ„

†„€
ƒ„
ƒ,†‰€

‰,…Š€
Š,ƒ†ˆ

‹,Š„€
ƒ‡,†Š„
‰€,ˆ‰€

Initial keywords examples

Back-propagation Neural Network
Back-propagation Algorithm
Cohen-Grossberg Neural Networks
Genetics-based Machine Learning
Neural Networks Learning

Autonomous Mobile Robot
Personal Assistant Systems
Soccer Robots
Automatic Translation
Self-driving Car

Nonlocality
Bias Currents
Choice Experiment
Boltzmann Equation
Biosensing

d
e
k
n
a
r
-
h
g
H

i

d
e
k
n
a
r
-
d
M

i

d
e
k
n
a
r
-
w
o
L

€,ƒ„…
†,„‡ˆ

Šƒ‰
ƒ…„
ƒ,‰ˆ„

‡‰†
†‰€

†Šˆ
ƒ‡
‡,ƒƒ‹

ƒˆ
‰ƒ

‡Š
‹…
ƒŠƒ

AI Publications

Non-AI Publications

figure 1.3  
High-, mid-, and low-ranked keywords with number of AI and non-AI 
publications, 1998-2017; sources: Scopus and Elsevier Fingerprint Engine.

USING AI TO DEFINE AI

23

Chapter 2

Artificial 
Intelligence:  
a multifaceted 
field 

The vocabulary used by actors from each perspective 
(teaching, research, industry, and media) reveals more 
divergence than commonality, while comparing keyword 
co-occurrences along the document set reveals the global 
structure of the field of AI in terms of subfields. This 
chapter presents an overview of our methodology and key 
findings on the composition of AI.

24

ARTIFICIAL INTELLIGENCE: HOW KNOWLEDGE IS CREATED, TRANSFERRED, AND USEDHighlights

Keywords shared across all 4 perspectives:
– Artificial Intelligence
– Deep Learning
– Machine Learning
– Neural Network
– Reinforcement Learning
– Speech Recognition
 section 2.1 

Artificial Intelligence focuses on: Search and 
Optimization, Fuzzy Systems, Natural Language 
Processing and Knowledge Representation, 
Computer Vision, Machine Learning and 
Probabilistic Reasoning, Planning and Decision 
Making, and Neural Networks.  
 section 2.2 

25

2.1 Teaching, research, 
industry, and media 
perspectives

In the previous chapter, we explained how we selected keywords 
and concepts describing AI, and how we used these to find the 
relevant research corpus in Scopus. Comparing the keywords from 
the four different perspectives, we find little overlap in the way AI 
is spoken about in education, research, industry, and the media. 
The four perspectives only share six broad and general keywords, 
most of which relate to learning: “Artificial Intelligence,” “Deep 
Learning,” “Machine Learning,” “Neural Network,” “Reinforcement 
Learning,” and “Speech Recognition.” Figure 2.1 shows that each 
perspective has at least 30% “unique” keywords, with up to 69% 
in industry, suggesting that the understanding of AI varies by 
perspective. This raises a question about communication: how can 
it be effective in the absence of a common language?

Keywords describing societal issues or ethics appear only in the 
perspectives of teaching and media, possibly due to government 
mandates (course curricula) and a new emerging two-way dialogue 
between society and research (social media). Industry differentiates 
strongly between software and hardware and media focuses on 
“strong AI” with its “own personality.” The physical embedding 
of AI and the idea of a personalized, “strong” AI is one driver 
for AI hype in the media. Teaching provides broad overviews of 
approaches, architectures, or tools. Many experts in research 
currently focus on neural networks.

figure 2.1  
Keyword mapping  
(number of keywords) between 
AI perspectives.

Media
(cid:21)(cid:23)

Teaching
(cid:23)(cid:22)(cid:21)

(cid:28)(cid:27)

Research
(cid:13)(cid:23)

(cid:30)(cid:29)

(cid:22)

(cid:26)(cid:25)

(cid:29)

(cid:26)

(cid:26)(cid:24)

(cid:26)(cid:28)(cid:29)

Industry
(cid:22)(cid:13)(cid:12)

(cid:31)(cid:31)(cid:31)

26

ARTIFICIAL INTELLIGENCE: HOW KNOWLEDGE IS CREATED, TRANSFERRED, AND USED2.2 Seven AI research 
clusters

We aimed to provide more depth to our subsequent analyses 
by structuring AI into research areas, using an unsupervised 
clustering technique.58 This approach maps the keywords of all 
perspectives into clusters and illustrates their connections, based 
on co-occurrence within the documents. Co-occurrence indicates 
that those clusters do not stand alone, but strongly relate to each 
other, e.g., neural networks in a computer vision document. How do 
capabilities connect with each other and to application fields? The 
resulting graph illustrates the subfields of AI (Figure 2.2) and their 
connections through co-occurence in scholarly publications. On  
the Elsevier AI Resource Center,59 the graph is interactive, allowing 
users to browse individual connections and clusters, by region and 
over time. 

As shows in Figure 2.2, AI seems to cluster around the areas 
of Search and Optimization, Fuzzy Systems, Natural Language 
Processing and Knowledge Representation, Computer Vision, 
Machine Learning and Probabilistic Reasoning, Planning and 
Decision Making, and Neural Networks. Societal application fields, 
such as self-driving cars or robotics, are embedded into Planning 
and Decision Making as they have fewer underlying publications. 
The clusters seem to focus on statistics-based AI. Knowledge-
based capabilities, such as “Ontologies or Semantics,” do not 
form a cluster on their own, but are embedded in other clusters, 
predominantly in “Natural Language Processing and Knowledge 
Representation.” Further research might investigate the sensitivity of 
this approach to the number of keywords and related publications 
in terms of normalized proportions over time. The strong growth of 
publications in recent years within the learning system field might 
outweigh knowledge-based approaches from more than 15 years ago.

Figure 2.2 illustrates the breadth of industry keywords (green), 
especially in the areas of “Fuzzy Systems” and “Computer Vision,” 
whereas specific research keywords appear in “Neural Networks,” 
teaching keywords in “Search and Optimization,” and media 
keywords in fields such as “Planning and Decision Making” and 
“Natural Language Processing and Knowledge Representation.” 60  
The relatively low proportion of media-driven keywords could 
indicate that these are not key AI research fields, or that they are 
still in their research infancy, representing only a fraction of AI 
documents. 

The online interactive graph61 allows the exploration of 
connections and co-occurrences through time. For instance, it 
shows the intensification of the two clusters “Machine Learning 
and Probabilistic Reasonin” and “Neural Networks.” It also 
reveals that the clusters “Deep Learning” in 2003 and “Swarm 
Intelligence” in 2000 have no co-occurring keywords but grow 
to become visible nodes on the graph in more recent years. 
Co-occurrences illustrate that certain learning system and 
neural network approaches are predominantly used in specific 
application fields, like “Recurrent Neural Networks” with “Natural 
Language Processing and Knowledge Representation.” They 
also show that the keyword “Convolutional Neural Networks” is 
linked with “Computer Vision” and “Collaborative Filtering” with 
“Recommender Systems.” Some connections indicate potential 
hierarchical relations, such as “Artificial Intelligence” co-occurring 
with the keyword “Neural Network,” and further co-occurring 
with specific forms of neural networks.

58  Louvain clustering:  

 

https://perso.uclouvain.be/vincent.blondel/research/louvain.html 
“The Louvain method is a simple, efficient and easy-to-implement method 
for identifying communities in large networks...The method is a greedy 
optimization method that attempts to optimize the ‘modularity’ of a partition 
of the network...The original idea for the method is due to Etienne Lefebvre 
who first developed it during his Master thesis at UCL (Louvain-la-Neuve) 
in March 2007...The method was first published in: ‘Fast unfolding of 
communities in large networks,’ Vincent D Blondel, Jean-Loup Guillaume, 
Renaud Lambiotte, Etienne Lefebvre, Journal of Statistical Mechanics: Theory 
and Experiment 2008 (10), P10008 (12pp) doi: 10.1088/1742-5468/2008/10/
P10008. arXiv: http://arxiv.org/abs/0803.0476.”

59  Elsevier. Artificial Intelligence Resource Center.  

https://www.elsevier.com/connect/ai-resource-center.

60  Learn more about these in Science Direct Topic Pages:  

 

https://www.sciencedirect.com/topics/index 
Fuzzy Systems: https://www.sciencedirect.com/topics/chemical-engineering/
fuzzy-systems; Speech Recognition:  
https://www.sciencedirect.com/topics/neuroscience/speech-recognition; 
Computer Vision: https://www.sciencedirect.com/topics/food-science/
computer-vision-technology (specific application field) or Face recognition:  
https://www.sciencedirect.com/topics/neuroscience/face-recognition;  
Learning Systems: https://www.sciencedirect.com/topics/chemical-
engineering/learning-systems;  
Neural Networks: https://www.sciencedirect.com/topics/veterinary-science-
and-veterinary-medicine/neural-network-software. 

61  Elsevier. Artificial Intelligence Resource Center.  

https://www.elsevier.com/connect/ai-resource-center. 

ARTIFICIAL INTELLIGENCE: A MULTIFACETED FIELD

27

In summary, our co-occurrence analysis reveals 
a sub-structure of the AI field, determined by 
its document corpus and keyword selection. 
Those might influence the weighting and share 
of subfields, such as knowledge-based fields. 
Further research might explore normalized 
approaches to compare subfields per year and 
investigate the sensitivity of keywords to the 
structure of the field. In chapter 3 we will use 
these clusters to present global and regional 
trends in AI.

Search and 
Optimization

Fuzzy 
Systems

Planning and 
Decision Making

Natural Language 
Processing and 
Knowledge 
Representation

28

ARTIFICIAL INTELLIGENCE: HOW KNOWLEDGE IS CREATED, TRANSFERRED, AND USEDThe AI research field 
clusters around seven 
main research areas.

Machine Learning 
and Probabilistic 
Reasoning

Computer 
Vision

Neural 
Networks

figure 2.2  
Keyword clusters and co-occurrences in the AI field, 2017;  
the color of the keyword represents its originating perspective: 
Teaching: orange, Research: blue, Industry: green, Media: pink, 
Multiple perspectives: black. source: Scopus. 

ARTIFICIAL INTELLIGENCE: A MULTIFACETED FIELD

29

Chapter 3

Artificial Intelligence 
research growth 
and regional trends  

The purpose of this chapter is to identify and illustrate 
developments in AI research for three large geographies – 
China, Europe, and the United States. It investigates research 
outputs (including articles, conference papers, preprints, and 
competitions) and the resulting impact of scholarly publications, 
measured in the form of citations and downloads. Cross-sector 
research collaborations and researcher mobility analyses illustrate 
knowledge transfer. Analyses of subject fields, publication sectors, 
and top institutions help understand growth drivers and key players 
in the global research arena.

30

ARTIFICIAL INTELLIGENCE: HOW KNOWLEDGE IS CREATED, TRANSFERRED, AND USEDHighlights
AI research publications have grown by 12.9% 
annually over the last 5 years.
 section 3.1 

arXiv preprints in core AI categories have grown 
37.4% annually over the last 5 years, and especially 
fast in “Machine Learning” and “Computer Vision 
and Pattern Recognition”.
 section 3.1 

China drives a lot of the global AI growth in 
publications, and also shows strong increases in 
citation impact.
 section 3.2 

China has a strong focus on Computer Vision. 
Robotics belongs to Machine Learning and 
Probabilistic Reasoning in Europe and the  
United States.
 section 3.2 

Over 70% of recent corporate AI research in the 
United States is published as conference papers.
Academic-corporate collaborations in the United 
States account for 9% of AI publication, with high 
volume and citation impact from Microsoft and 
IBM.
 section 3.4 

31

3.1 Global trends in AI research

Counting peer-reviewed publications is a common and easily 
understood measurement of research output. This section aims 
to give an overall view on all types of scholarly output, indexed 
by Scopus, namely journal articles (further referred to as articles), 
conference papers, and others, like review or survey papers. The 
following analysis is based on the refined corpus of more than 
600,000 AI publications from 1998 to 2017, retrieved from Scopus 
(May 2018) following the method explained in chapter 2. In this 
chapter, we also examine preprints, conferences, and competitions.  

The development of the AI field can be seen as occurring in four 
phases of five years each, with the new economy and Internet 
emerging around 2000 alongside several of today’s corporate 
players, like Amazon or Google. The Think Tank Eurasia Group 
and Sinovation Ventures65 and Dr Kai-Fu Lee66 identify four areas 
of AI: Internet AI (recommender systems), Business AI (fraud 
detection, financial forecasting), Perception AI (smart devices), and 
Autonomous AI (new hardware applications, like self-driving cars).

Comparators selection and rationale 
Many countries have recognized AI as an innovation driver. 
For a comprehensive global view of the dynamics of the 
AI field, we selected comparable regions over a period 
of 20 years (1998-2017) for analyses of various research 
dimensions (e.g., output, number of researchers, funding). 
As AI is now included as a key topic within innovation 
and research policies in many countries, it was important 
that the regions chosen for analysis connect to defined 
policy spheres. This consideration led us to choose 
Europe, including the 28 European Union Member States 
and affiliated countries under the EU’s Horizon 2020 
research funding program, such as Turkey and Israel. As 
the analyses illustrate, emerging countries like India, or 
smaller countries like Singapore, are not less relevant
for a comprehensive view on AI but would require a 
different comparative structure.

The graph in Figure 3.1 illustrates the overall growth of the AI 
research field with now approximately 60,000 publications per 
year. Globally, the field of AI has shown strong growth of 12.9% 
in the last 5 years. Many AI historical timelines exist in literature, 
highlighting key events and discoveries along the 60-year journey 
of the field, including the “AI winters,”62 understood as periods 
of disillusionment with the technology. From 2005 onwards for 
instance, research in neural networks starts winning vision and 
speech competitions, and by 2009 is dominant against some of the 
benchmark sets.63 Around 2014-2015, several good review (survey) 
papers on deep learning start to appear.64 

AI research publications 
have grown by  
12.9% annually over  
the last 5 years

62   Wikipedia. AI Winter. https://en.wikipedia.org/wiki/AI_winter. 
63  Computer Vision. http://people.idsia.ch/~juergen/vision.html.
• 

The NORB Object Recognition Benchmark.  
https://cs.nyu.edu/~ylclab/data/norb-v1.0/. 
The CIFAR Image Classification Benchmark.  
http://www.cs.toronto.edu/~kriz/cifar.html. 
The MNIST Handwritten Digits Benchmark.  
http://yann.lecun.com/exdb/mnist/. 
The Weizmann & KTH Human Action Recognition Benchmarks.  
http://www.nada.kth.se/cvap/actions/. 

• 

• 

• 

•  Chinese characters from the ICDAR 2013 competition.  

http://www.nlpr.ia.ac.cn/events/CHRcompetition2013/competition/Home.html.

64  Historical overviews: Schmidhuber, J. Deep learning in neural networks:  

An overview. Neural Networks. 2015;61:85-117.  
https://doi.org/10.1016/j.neunet.2014.09.003; Review (survey) article:  
LeCun, Y., et al. Deep learning. Nature. 2015;521:436-444.  
http://www.nature.com/articles/nature14539.

65  Eurasia Group, Sinovation Ventures. China embraces AI: a close look and  

a long view. December 2017.  
https://www.eurasiagroup.net/files/upload/China_Embraces_AI.pdf.

66  Lee, K-F. AI Superpowers: China, Silicon Valley, and the New World Order.  

New York, NY: Houghton Mifflin Harcourt; 2018.  
https://aisuperpowers.com/about/about-the-book. 

32

ARTIFICIAL INTELLIGENCE: HOW KNOWLEDGE IS CREATED, TRANSFERRED, AND USEDChina

Europe

United States

Global

President Xi Jinping 
calling for breakthroughs 
in S&T ((cid:31)(cid:30)(cid:29)(cid:25))

Letter against 
autonomous 
weapons ((cid:31)(cid:30)(cid:29)(cid:24))

United States National AI 
R&D Strategic Plan ((cid:31)(cid:30)(cid:29)(cid:23))

Europe: FP(cid:22) funding program ((cid:31)(cid:30)(cid:30)(cid:23)) 

China National Medium- and 
Long-Term Plan for the Development 
of Science and Technology ((cid:31)(cid:30)(cid:30)(cid:25))

Europe: new Innovation agenda (EITs) ((cid:31)(cid:30)(cid:29)(cid:25))
Launch of Horizon(cid:31)(cid:30)(cid:31)(cid:30) ((cid:31)(cid:30)(cid:29)(cid:25))

Financial crisis ((cid:31)(cid:30)(cid:30)(cid:28)) 

(cid:29)(cid:27)(cid:27)(cid:28)

(cid:29)(cid:27)(cid:27)(cid:27)

(cid:31)(cid:30)(cid:30)(cid:30)

(cid:31)(cid:30)(cid:30)(cid:29) (cid:31)(cid:30)(cid:30)(cid:31) (cid:31)(cid:30)(cid:30)(cid:26) (cid:31)(cid:30)(cid:30)(cid:25) (cid:31)(cid:30)(cid:30)(cid:24) (cid:31)(cid:30)(cid:30)(cid:23) (cid:31)(cid:30)(cid:30)(cid:22) (cid:31)(cid:30)(cid:30)(cid:28) (cid:31)(cid:30)(cid:30)(cid:27) (cid:31)(cid:30)(cid:29)(cid:30)

(cid:31)(cid:30)(cid:29)(cid:29) (cid:31)(cid:30)(cid:29)(cid:31) (cid:31)(cid:30)(cid:29)(cid:26) (cid:31)(cid:30)(cid:29)(cid:25) (cid:31)(cid:30)(cid:29)(cid:24) (cid:31)(cid:30)(cid:29)(cid:23) (cid:31)(cid:30)(cid:29)(cid:22)

(cid:31)(cid:30)(cid:29)(cid:28)

First robots for 
home, e.g. 
cleaning ((cid:31)(cid:30)(cid:30)(cid:29))

First self-driving 
cars ((cid:31)(cid:30)(cid:30)(cid:24))

Speech recognition 
on smartphone ((cid:31)(cid:30)(cid:30)(cid:28))

Google’s autonomous car ((cid:31)(cid:30)(cid:30)(cid:27))

Apples SIRI, Cortana, Google Now ((cid:31)(cid:30)(cid:29)(cid:29)-(cid:31)(cid:30)(cid:29)(cid:25))

Evangelist Andrew 
Ng training an AI 
(“loving cats”) ((cid:31)(cid:30)(cid:29)(cid:31)) 

Google DeepMind 
winning Go ((cid:31)(cid:30)(cid:29)(cid:23))

Google Duplex ((cid:31)(cid:30)(cid:29)(cid:28))

figure 3.1  
Selected AI-relevant policies and events 
(upper panel) and technology breakthroughs 
(lower panel), 1998-2018.

 

I
A
n
o
 
s
n
o
i
t
a
c
i
l

b
u
p
 
f
o
 
r
e
b
m
u
n

 
l
a
b
o
G

l

(cid:3)(cid:9),(cid:9)(cid:9)(cid:9)

(cid:4)(cid:9),(cid:9)(cid:9)(cid:9)

(cid:2)(cid:9),(cid:9)(cid:9)(cid:9)

(cid:5)(cid:9),(cid:9)(cid:9)(cid:9)

(cid:6)(cid:9),(cid:9)(cid:9)(cid:9)

(cid:7)(cid:9),(cid:9)(cid:9)(cid:9)

(cid:31)(cid:9),(cid:9)(cid:9)(cid:9)

(cid:9)

(cid:31)(cid:30)(cid:30)(cid:29)

(cid:31)(cid:30)(cid:30)(cid:30) (cid:7)(cid:9)(cid:9)(cid:9)

(cid:7)(cid:9)(cid:9)(cid:31) (cid:7)(cid:9)(cid:9)(cid:7) (cid:7)(cid:9)(cid:9)(cid:6) (cid:7)(cid:9)(cid:9)(cid:5) (cid:7)(cid:9)(cid:9)(cid:2) (cid:7)(cid:9)(cid:9)(cid:4) (cid:7)(cid:9)(cid:9)(cid:3) (cid:7)(cid:9)(cid:9)(cid:29) (cid:7)(cid:9)(cid:9)(cid:30) (cid:7)(cid:9)(cid:31)(cid:9)

(cid:7)(cid:9)(cid:31)(cid:31) (cid:7)(cid:9)(cid:31)(cid:7) (cid:7)(cid:9)(cid:31)(cid:6) (cid:7)(cid:9)(cid:31)(cid:5) (cid:7)(cid:9)(cid:31)(cid:2) (cid:7)(cid:9)(cid:31)(cid:4) (cid:7)(cid:9)(cid:31)(cid:3)

figure 3.1  
Annual number of AI publications (all 
document types), 1998-2017; source: Scopus.

ARTIFICIAL INTELLIGENCE RESEARCH GROWTH  AND REGIONAL TRENDS

33

The growth of research in the AI general capabilities of computer 
vision, neural networks, and machine learning systems is 
also apparent in the growth of publications (e.g., articles and 
conference papers) by co-occurrence cluster as illustrated in  
Figure 3.2. These research fields seem to explain the steep increase 
in publications after 2012. From the AI ecosystem, we see the rise 
of graphical processing units (GPUs) and the launch of ImageNet 
in 2012, a big open database with image training data that might 
have helped ignite this development.

Within the context of the growth of the arXiv corpus, preprints 
in the 12 core AI subject areas have grown significantly as a 
percentage of the number of preprints in arXiv as a whole. In 
1998, these 12 categories together account for only 149 preprints, 
or 0.62% of all preprints submitted to the arXiv repository. With 
gradual increases from 1998 to 2014, this percentage then rises 
sharply starting in 2015; in 2017, preprint submissions in these 12 
categories account for more than 12% of all preprints submitted 
to arXiv.

Diachronic development in the number of publications by cluster 
do not show big differences between articles and conference 
papers. While the field of “Computer Vision” seems to benefit from 
developments in “Machine Learning and Probabilistic Reasoning” 
and “Neural Networks,” “Natural Language Processing and 
Knowledge Representation” and other capabilities are less affected.

Looking at the arXiv preprints submitted to the 12 core AI subject 
categories, we attempted to discern changes to submission 
patterns. Have AI researchers focused on different types of AI 
research over time, based on the number of preprints submitted 
to each subject category? Figure 3.3 depicts the proportion of 
preprints submitted to each category over time.

Preprints are another mechanism for disseminating AI research, 
and are typically used to circulate preliminary research outputs 
pending formal publication. arXiv is a popular academic preprint 
repository that has become an increasingly important channel 
for research dissemination in many fields of science and 
mathematics.67 To examine trends in AI preprints over time, we 
first needed to determine which preprints should be considered 
AI research. Including arXiv categories obviously related to AI 
(e.g., cs.AI – Artificial Intelligence or stat. ML – Machine Learning) 
would miss important categories like computer vision and pattern 
recognition. Therefore, relying on titles and abstract text from 
arXiv, we used a refined list of 142 keywords and 12 arXiv subject 
areas designated by experts as having high relevance to the field 
of AI.

arXiv preprints in core  
AI categories have 
grown by 37.4% annually 
over the last 5 years.

67  Cornell University Library. arXiv monthly submission rates.  

https://arxiv.org/stats/monthly_submissions. Accessed 3 September 2018.

34

ARTIFICIAL INTELLIGENCE: HOW KNOWLEDGE IS CREATED, TRANSFERRED, AND USEDs
n
o
i
t
a
c
i
l

b
u
p
 
f
o
 
r
e
b
m
u
N

s
t
n
i
r
p
e
r
p
 
v
i
X
r
a
 
f
o
n
o
i
t
r
o
p
o
r
P

 

(cid:8)(cid:14),(cid:14)(cid:14)(cid:14)

(cid:9)(cid:13),(cid:14)(cid:14)(cid:14)

(cid:9)(cid:14),(cid:14)(cid:14)(cid:14)

(cid:10)(cid:13),(cid:14)(cid:14)(cid:14)

(cid:10)(cid:14),(cid:14)(cid:14)(cid:14)

(cid:11)(cid:13),(cid:14)(cid:14)(cid:14)

(cid:11)(cid:14),(cid:14)(cid:14)(cid:14)

(cid:13),(cid:14)(cid:14)(cid:14)

(cid:14)

(cid:31)(cid:27)(cid:27)%

(cid:30)(cid:27)%

(cid:29)(cid:27)%

(cid:22)(cid:27)%

(cid:23)(cid:27)%

(cid:24)(cid:27)%

(cid:25)(cid:27)%

(cid:26)(cid:27)%

(cid:28)(cid:27)%

(cid:31)(cid:27)%

(cid:27)%

figure 3.2  
Annual number of AI 
publications by keyword 
co-occurrence cluster (all 
document types), 1998-2017; 
sources: Scopus and Elsevier 
clustering.

figure 3.3  
Proportion of arXiv preprints 
submitted in core AI 
categories, per category,  
1998-2017; source: arXiv.

(cid:6)
(cid:7)
(cid:7)
(cid:11)

(cid:7)
(cid:7)
(cid:7)
(cid:11)

(cid:14)
(cid:14)
(cid:14)
(cid:10)

(cid:11)
(cid:14)
(cid:14)
(cid:10)

(cid:10)
(cid:14)
(cid:14)
(cid:10)

(cid:9)
(cid:14)
(cid:14)
(cid:10)

(cid:8)
(cid:14)
(cid:14)
(cid:10)

(cid:13)
(cid:14)
(cid:14)
(cid:10)

(cid:4)
(cid:14)
(cid:14)
(cid:10)

(cid:5)
(cid:14)
(cid:14)
(cid:10)

(cid:6)
(cid:14)
(cid:14)
(cid:10)

(cid:7)
(cid:14)
(cid:14)
(cid:10)

(cid:14)
(cid:11)
(cid:14)
(cid:10)

(cid:11)
(cid:11)
(cid:14)
(cid:10)

(cid:10)
(cid:11)
(cid:14)
(cid:10)

(cid:9)
(cid:11)
(cid:14)
(cid:10)

(cid:8)
(cid:11)
(cid:14)
(cid:10)

(cid:13)
(cid:11)
(cid:14)
(cid:10)

(cid:4)
(cid:11)
(cid:14)
(cid:10)

(cid:5)
(cid:11)
(cid:14)
(cid:10)

Machine Learning and Probabilistic Reasoning
Neutral Networks
Computer Vision
Natural Language Processing and Knowledge Representation

Search and Optimization
Fuzzy Systems
Planning and Decision Making

(cid:29)
(cid:30)
(cid:30)
(cid:31)

(cid:30)
(cid:30)
(cid:30)
(cid:31)

(cid:27)
(cid:27)
(cid:27)
(cid:28)

(cid:31)
(cid:27)
(cid:27)
(cid:28)

(cid:28)
(cid:27)
(cid:27)
(cid:28)

(cid:26)
(cid:27)
(cid:27)
(cid:28)

(cid:25)
(cid:27)
(cid:27)
(cid:28)

(cid:24)
(cid:27)
(cid:27)
(cid:28)

(cid:23)
(cid:27)
(cid:27)
(cid:28)

(cid:22)
(cid:27)
(cid:27)
(cid:28)

(cid:29)
(cid:27)
(cid:27)
(cid:28)

(cid:30)
(cid:27)
(cid:27)
(cid:28)

(cid:27)
(cid:31)
(cid:27)
(cid:28)

(cid:31)
(cid:31)
(cid:27)
(cid:28)

(cid:28)
(cid:31)
(cid:27)
(cid:28)

(cid:26)
(cid:31)
(cid:27)
(cid:28)

(cid:25)
(cid:31)
(cid:27)
(cid:28)

(cid:24)
(cid:31)
(cid:27)
(cid:28)

(cid:23)
(cid:31)
(cid:27)
(cid:28)

(cid:22)
(cid:31)
(cid:27)
(cid:28)

(cid:29)
(cid:31)
(cid:27)
(cid:28)

Computational Linguistics

Arti(cid:141)cial Intelligence

Neural and Evolutionary Computation

Multiagent Systems

Computer Vision and Pattern Recognition
Machine Learning (computer science)

Robotics

Information Retrieval

Machine Learning (statistics)

Image and Video Processing

Sound
Audio and Speech Processing

ARTIFICIAL INTELLIGENCE RESEARCH GROWTH  AND REGIONAL TRENDS

35

Additionally, platforms like arXiv seem to be increasing the 
specificity allowed to researchers by adding new and more 
precise subject area designations, for example, distinguishing 
between statistics and computer science research in machine 
learning (started in 2007, 10.8% in 2018) or adding subject 
categories (“Computer Science - Sound” was added in 2004, 
and both “Audio and Speech Processing” and “Image and 
Video Processing” were both added in 2017).

Both arXiv preprint and Scopus publication analyses illustrate 
the evolution of the AI field, based on areas the platforms’ 
researchers are focusing on. While more generic terms like 
“Artificial Intelligence” see their submission rates erode on 
arXiv over time, they are actually emerging as umbrella terms. 

The volume of preprints 
in “Machine Learning” 
and “Computer 
Vision and Pattern 
Recognition” has grown 
rapidly in recent years.

The analysis of arXiv preprints in any of the 12 core AI subject areas 
shows dramatic growth in content relating to these topics, even 
relative to the growth of arXiv itself. Preprints in subject areas 
relating to core AI concepts account for 11.6% of all arXiv content 
in 2017, and 15.1% of submissions to date for 2018—a dramatic 
change from only a few years ago (2015: 5.61% of all arXiv content). 
This growth might be attributable to increased attention, funding, 
and research in the core AI areas, but it might also be indicative 
of the rise of arXiv as an important and trusted tool for research 
dissemination in these areas, as large AI research labs like Google 
DeepMind adopt the platform.

Research focus has likely shifted within the core AI fields over the 
past 20 years. More traditionally, computational linguistics and 
natural language processing research dominates arXiv submissions 
within these subject areas in 1998 (112 of the 149 papers submitted 
in all 12 categories, or 75.2%). While that area is still a factor in 
the AI research landscape, the arXiv data also points to a dramatic 
rise in the fields of computer vision and pattern recognition 
(from 1.3% of core AI submissions in 1998 to 32.7% in 2018) and 
machine learning (1.3% in 1998 to 17.8% in 2018)—both of these 
areas focus on the application of deep learning technologies. 

36

ARTIFICIAL INTELLIGENCE: HOW KNOWLEDGE IS CREATED, TRANSFERRED, AND USEDDr. Roberto M. Cesar Jr.
Adjunct Coordinator, São Paulo 
Research Foundation (FAPESP), 
Brazil

AI research output: beyond 
traditionally published papers

“AI and machine learning have attracted 
increasing attention in recent years, building 
into a kind of unforeseen revolution that 
has re-organized the scientific community, 
private sector, government, and society. Many 
intellectual tasks are currently being automated 
by AI processes, reflecting a culmination of the 
efforts and advances made across many different 
scientific communities (including computer 
scientists, engineers, and neuroscientists, among 
many others) working in research institutions 
and companies all over the world.

AI open-source libraries and training data 
sets are being produced, shared, and used 
interchangeably by researchers, programmers, 
and students from various disciplines. To better 
understand this phenomenon, it is important to 
recognize that AI and machine learning methods 
typically involve four fundamental elements: 

1.  Learning and classification algorithms. 
2.  Data to train and to evaluate the algorithms. 
 Data scientists to code, set up the software, 
3. 
and prepare the data. 
 Computer hardware to store and run the 
code. 

4. 

The unique characteristics of the AI field make 
it challenging to evaluate its development. 
Traditionally, research advances in computer 
science and related fields are disseminated as 
papers published in journals and conference 

proceedings. Thus, commonly used research 
performance indicators have included the 
number of published papers and citations. 
However, it is now clear that these indicators 
only cover a fraction of the advances being made 
within each of the four AI research elements 
described above. In fact, the AI R&D community 
has adapted and expanded over time to include 
multiple disciplines devoted to increasing 
research efforts that integrate all four elements. 

Many groups in academia and industry plan, as 
part of their research activities, the production 
and release of datasets and machine learning-
specific libraries, making them available at 
certain times through papers submitted to 
peer-reviewed journals. This “roll out” is like the 
planned advertising campaign in the production 
of a new movie, which often involves “watch the 
movie, read the book, listen to the soundtrack, 
and buy the t-shirt.” Therefore, it is essential to 
develop new indicators that track the interim 
release of AI open-source libraries and public 
datasets and can better describe the AI research 
landscape than published papers alone.

Initiatives that help us understand the 
development of the AI field are important, not 
only so that we can remain up-to-date on the 
research advances being made, but also so 
we can analyze the possible outcomes of this 
ongoing revolution and its impact on society.”

ARTIFICIAL INTELLIGENCE RESEARCH GROWTH  AND REGIONAL TRENDS

37

3.2 Regional research trends in AI 

The rise of China

As shown in Figure 3.4, Europe is still the largest contributor to AI 
research but continues to lose publication share. The United States 
is regaining ground lost in the last five years. China is bound to 
overtake Europe in publication output in AI in the near future, 
having already overtaken the United States in 2004. 

Figure 3.5 illustrates that other individual countries are showing 
strong development in AI. For instance, India emerges as the third 
largest country in AI research in the last five years. Other emerging 
countries, like Iran, appear among the top 10 countries in AI 
research. Established research nations like Japan are also growing 
in terms of AI publication output, but with less vigour than the 
United States or China. Full country-level data is available through 
the Elsevier AI Resource Center.68

Share of world publications in AI

(cid:25)(cid:31)(cid:31)%

(cid:26)(cid:31)%

(cid:27)(cid:31)%

(cid:28)(cid:31)%

(cid:29)(cid:31)%

(cid:31)%

(cid:4)(cid:25)%

(cid:29)(cid:2)%

(cid:4)(cid:2)%

(cid:6)%

(cid:29)(cid:6)%

(cid:29)(cid:31)%

(cid:4)(cid:4)%

(cid:25)(cid:26)%

(cid:29)(cid:26)%

(cid:25)(cid:2)%

(cid:4)(cid:25)%

(cid:29)(cid:27)%

(cid:29)(cid:6)%

(cid:25)(cid:3)%

(cid:4)(cid:31)%

(cid:29)(cid:28)%

(cid:25)(cid:6)(cid:6)(cid:26) – (cid:29)(cid:31)(cid:31)(cid:29)

(cid:29)(cid:31)(cid:31)(cid:4) – (cid:29)(cid:31)(cid:31)(cid:3)

(cid:29)(cid:31)(cid:31)(cid:26) – (cid:29)(cid:31)(cid:25)(cid:29)

(cid:29)(cid:31)(cid:25)(cid:4) – (cid:29)(cid:31)(cid:25)(cid:3)

China

Europe

United States

Other

figure 3.4  
Share of global publication output in AI (all document types) 
for periods 1998-2002, 2003-2007, 2008-2012, and 2013-2017, 
per region; source: Scopus.

Number of publications in AI

(cid:25)(cid:27),(cid:31)(cid:31)(cid:31)

(cid:25)(cid:28),(cid:31)(cid:31)(cid:31)

(cid:25)(cid:30),(cid:31)(cid:31)(cid:31)

(cid:25)(cid:31),(cid:31)(cid:31)(cid:31)

(cid:26),(cid:31)(cid:31)(cid:31)

(cid:27),(cid:31)(cid:31)(cid:31)

(cid:28),(cid:31)(cid:31)(cid:31)

(cid:30),(cid:31)(cid:31)(cid:31)

68   Elsevier. Artificial Intelligence Resource Center.  

https://www.elsevier.com/connect/ai-resource-center

(cid:31)

(cid:30)(cid:31)(cid:25)(cid:24)

China
Germany

(cid:30)(cid:31)(cid:25)(cid:28)

(cid:30)(cid:31)(cid:25)(cid:23)

(cid:30)(cid:31)(cid:25)(cid:27)

(cid:30)(cid:31)(cid:25)(cid:22)

United States
Japan

Spain

India
Iran

United Kingdom
France

Italy

figure 3.5  
Publication output per country/territory (all document types), 
2013-2017; source: Scopus.

38

ARTIFICIAL INTELLIGENCE: HOW KNOWLEDGE IS CREATED, TRANSFERRED, AND USEDIn Europe and the United States,  
AI research has a stronger focus on 
health while in China the emphasis is  
on agriculture.

Success in AI in application fields, like the health sciences, mobility, 
or agriculture, fuels interest and growth in AI research. This section 
investigates the specialization of regions in AI research fields and 
clusters and reveals the focus on AI applications in medicine in 
Europe and the United States

Relative research focus per region

Natural Sciences

(cid:2).(cid:127)

(cid:129).(cid:141)

(cid:129).(cid:127)

(cid:127).(cid:141)

(cid:127).(cid:127)

Humanities

Social Sciences

Engineering and 
Technology

Medical and 
Health Sciences

Agricultural Sciences

China

Europe

United States

World Average

figure 3.6  
Relative Activity Index (RAI) of publications (all 
document types) per FORD category per region, 2017; 
dashed line indicates world average; source: Scopus.

The purpose of the OECD Fields of Research and 
Development (FORD) categories are to break down R&D 
expenditure and personnel by fields of research and 
development. FORD categories are used to classify R&D by 
fields of inquiry, namely, broad knowledge domains based 
primarily on the content of the R&D subject matter. 

The Relative Activity Index (RAI) approximates the 
specialization of a region by comparing it to the global 
research activity in the AI field. RAI is defined as the share 
of a country’s publication output in AI relative to the global 
share of publications in AI. A value of 1.0 indicates that a 
country’s research activity in AI corresponds exactly with 
the global activity in AI; higher than 1.0 implies a greater 
emphasis, while lower than 1.0 suggests a lesser focus.

Nearly 60% of AI research publications fall within the natural 
sciences, which is also seeing the fastest growth rate. Other fields, 
like the agricultural sciences, also show strong growth but on a 
smaller base (~2%). Figure 3.6 reveals China’s strong specialization 
in AI in the agricultural sciences, and the United States’ focus on 
the medical and health sciences. Europe and the United States’ 
apparent emphasis on the humanities refers to a very low number 
of publications and may be influenced by language.

ARTIFICIAL INTELLIGENCE RESEARCH GROWTH  AND REGIONAL TRENDS

39

China

Europe

figure 3.7  
Keyword co-occurrences with 500+ shared 
publications (all document types) for China, 
Europe, and the United States, 2017; sources: 
Scopus and Elsevier clustering.

United States

40

ARTIFICIAL INTELLIGENCE: HOW KNOWLEDGE IS CREATED, TRANSFERRED, AND USEDA comparison of keyword co-occurrences (Figures 3.7) illustrates 
how each region’s AI research specializes, helping identify common 
interests and differentiation, such as shared “Fuzzy Systems” 
clusters but distinct clusters for several types of research under the 
term “Neural Network.”

The United States has a thinner cluster structure, due to its 
overall lower volume of publications. This includes a less 
differentiated field compared to the strongly industry-influenced 
clusters “Fuzzy Systems” and “Computer Vision” in China and 
Europe. China’s most apparent difference from Europe and the 
United States is the lack of a “Natural Language Processing and 
Knowledge Representation” cluster. This might be due to low 

publication volumes for China in this area, as research on this 
topic may be driven by corporations (which publish fewer papers 
than universities) in that country. Expert interviews confirm 
the strong Chinese focus in the area of “Face Recognition.” 
Among Chinese publications, the “Neural Network” cluster 
appears very differentiated, including in prediction models and 
backpropagation, as well as robotics. In Europe and the United 
States, robotics is part of the “Machine Learning and Probabilistic 
Reasoning” cluster. In China and Europe, we identify additional 
clusters on “Genetic Programming” and “Evolutionary Algorithms” 
for topics like “Pattern Recognition.” Further details on regional 
specialization is obtained through analysis of publications per year 
and co-occurrence clusters for each region (Figures 3.8-3.10).

Robotics belongs  
to Machine Learning 
and Probabilistic 
Reasoning in Europe 
and the United States.

ARTIFICIAL INTELLIGENCE RESEARCH GROWTH  AND REGIONAL TRENDS

41

China

s
n
o
i
t
a
c
i
l

b
u
P

(cid:31),(cid:29)(cid:29)(cid:29)

(cid:28),(cid:29)(cid:29)(cid:29)

(cid:27),(cid:29)(cid:29)(cid:29)

(cid:26),(cid:29)(cid:29)(cid:29)

(cid:25),(cid:29)(cid:29)(cid:29)

(cid:24),(cid:29)(cid:29)(cid:29)

(cid:23),(cid:29)(cid:29)(cid:29)

(cid:29)

(cid:10)
(cid:11)
(cid:11)
(cid:23)

(cid:11)
(cid:11)
(cid:11)
(cid:23)

Computer Vision
Planning and 
Decision Making

Strong Chinese 
focus on 
Computer Vision.

China

(cid:23)(cid:29),(cid:29)(cid:29)(cid:29)

s
n
o
i
t
a
c
i
l

b
u
P

(cid:11),(cid:29)(cid:29)(cid:29)

(cid:10),(cid:29)(cid:29)(cid:29)

(cid:31),(cid:29)(cid:29)(cid:29)

(cid:28),(cid:29)(cid:29)(cid:29)

(cid:27),(cid:29)(cid:29)(cid:29)

(cid:26),(cid:29)(cid:29)(cid:29)

(cid:25),(cid:29)(cid:29)(cid:29)

(cid:24),(cid:29)(cid:29)(cid:29)

(cid:23),(cid:29)(cid:29)(cid:29)

(cid:29)

(cid:10)
(cid:11)
(cid:11)
(cid:23)

(cid:11)
(cid:11)
(cid:11)
(cid:23)

(cid:29)
(cid:29)
(cid:29)
(cid:24)

(cid:23)
(cid:29)
(cid:29)
(cid:24)

(cid:24)
(cid:29)
(cid:29)
(cid:24)

(cid:25)
(cid:29)
(cid:29)
(cid:24)

(cid:26)
(cid:29)
(cid:29)
(cid:24)

(cid:27)
(cid:29)
(cid:29)
(cid:24)

(cid:28)
(cid:29)
(cid:29)
(cid:24)

(cid:31)
(cid:29)
(cid:29)
(cid:24)

(cid:10)
(cid:29)
(cid:29)
(cid:24)

(cid:11)
(cid:29)
(cid:29)
(cid:24)

(cid:29)
(cid:23)
(cid:29)
(cid:24)

(cid:23)
(cid:23)
(cid:29)
(cid:24)

(cid:24)
(cid:23)
(cid:29)
(cid:24)

(cid:25)
(cid:23)
(cid:29)
(cid:24)

(cid:26)
(cid:23)
(cid:29)
(cid:24)

(cid:27)
(cid:23)
(cid:29)
(cid:24)

(cid:28)
(cid:23)
(cid:29)
(cid:24)

(cid:31)
(cid:23)
(cid:29)
(cid:24)

Computer Vision
Planning and 
Decision Making

Fuzzy Systems
Natural Language Processing 
and Knowledge Representation

Neural Networks

figure 3.8  
Annual publications per cluster for China 
(all document types), 1998-2017; sources: 
Scopus and Elsevier clustering.

China has a clear focus on the area of “Computer Vision,” with 
very rapid recent growth, and sees a flattening of its research in 
“Fuzzy Systems,” which drove China’s publication growth in the 
first decade. “Machine Learning and Probabilistic Reasoning” and 
“Search and Optimization” impact all subfields, yet “Computer 
Vision” particularly benefits from developments in those areas. 
The spikes in 2009 are due to strong conference expansion in 
the field of engineering around that time. With the rise of neural 
networks, China seems to shift away from research topics in 
engineering, like “Fuzzy Systems.”

42

ARTIFICIAL INTELLIGENCE: HOW KNOWLEDGE IS CREATED, TRANSFERRED, AND USEDEurope

(cid:23)(cid:29),(cid:29)(cid:29)(cid:29)

s
n
o
i
t
a
c
i
l

b
u
P

(cid:11),(cid:29)(cid:29)(cid:29)

(cid:10),(cid:29)(cid:29)(cid:29)

(cid:31),(cid:29)(cid:29)(cid:29)

(cid:28),(cid:29)(cid:29)(cid:29)

(cid:27),(cid:29)(cid:29)(cid:29)

(cid:26),(cid:29)(cid:29)(cid:29)

(cid:25),(cid:29)(cid:29)(cid:29)

(cid:24),(cid:29)(cid:29)(cid:29)

(cid:23),(cid:29)(cid:29)(cid:29)

(cid:29)

(cid:10)
(cid:11)
(cid:11)
(cid:23)

(cid:11)
(cid:11)
(cid:11)
(cid:23)

(cid:29)
(cid:29)
(cid:29)
(cid:24)

(cid:23)
(cid:29)
(cid:29)
(cid:24)

(cid:24)
(cid:29)
(cid:29)
(cid:24)

(cid:25)
(cid:29)
(cid:29)
(cid:24)

(cid:26)
(cid:29)
(cid:29)
(cid:24)

(cid:27)
(cid:29)
(cid:29)
(cid:24)

(cid:28)
(cid:29)
(cid:29)
(cid:24)

(cid:31)
(cid:29)
(cid:29)
(cid:24)

(cid:10)
(cid:29)
(cid:29)
(cid:24)

(cid:11)
(cid:29)
(cid:29)
(cid:24)

(cid:29)
(cid:23)
(cid:29)
(cid:24)

(cid:23)
(cid:23)
(cid:29)
(cid:24)

(cid:24)
(cid:23)
(cid:29)
(cid:24)

(cid:25)
(cid:23)
(cid:29)
(cid:24)

(cid:26)
(cid:23)
(cid:29)
(cid:24)

(cid:27)
(cid:23)
(cid:29)
(cid:24)

(cid:28)
(cid:23)
(cid:29)
(cid:24)

(cid:31)
(cid:23)
(cid:29)
(cid:24)

United States

(cid:23)(cid:29),(cid:29)(cid:29)(cid:29)

Europe

(cid:11),(cid:29)(cid:29)(cid:29)
(cid:31),(cid:29)(cid:29)(cid:29)
(cid:10),(cid:29)(cid:29)(cid:29)
(cid:28),(cid:29)(cid:29)(cid:29)
(cid:31),(cid:29)(cid:29)(cid:29)
(cid:27),(cid:29)(cid:29)(cid:29)
(cid:28),(cid:29)(cid:29)(cid:29)

s
n
o
i
t
a
c
i
l

s
n
o
i
t
a
c
i
l

b
u
P

b
u
P

(cid:26),(cid:29)(cid:29)(cid:29)
(cid:27),(cid:29)(cid:29)(cid:29)

(cid:26),(cid:29)(cid:29)(cid:29)
(cid:25),(cid:29)(cid:29)(cid:29)
(cid:25),(cid:29)(cid:29)(cid:29)
(cid:24),(cid:29)(cid:29)(cid:29)
(cid:24),(cid:29)(cid:29)(cid:29)
(cid:23),(cid:29)(cid:29)(cid:29)
(cid:23),(cid:29)(cid:29)(cid:29)

(cid:29)
(cid:29)

(cid:10)
(cid:11)
(cid:11)
(cid:23)

(cid:10)
(cid:11)
(cid:11)
(cid:23)

(cid:11)
(cid:11)
(cid:11)
(cid:23)

(cid:11)
(cid:11)
(cid:11)
(cid:23)

(cid:29)
(cid:29)
(cid:29)
(cid:24)

(cid:29)
(cid:29)
(cid:29)
(cid:24)

(cid:23)
(cid:29)
(cid:29)
(cid:24)

(cid:23)
(cid:29)
(cid:29)
(cid:24)

(cid:24)
(cid:29)
(cid:29)
(cid:24)

(cid:24)
(cid:29)
(cid:29)
(cid:24)

(cid:25)
(cid:29)
(cid:29)
(cid:24)

(cid:25)
(cid:29)
(cid:29)
(cid:24)

(cid:26)
(cid:29)
(cid:29)
(cid:24)

(cid:26)
(cid:29)
(cid:29)
(cid:24)

(cid:27)
(cid:29)
(cid:29)
(cid:24)

(cid:27)
(cid:29)
(cid:29)
(cid:24)

(cid:28)
(cid:29)
(cid:29)
(cid:24)

(cid:28)
(cid:29)
(cid:29)
(cid:24)

(cid:31)
(cid:29)
(cid:29)
(cid:24)

(cid:31)
(cid:29)
(cid:29)
(cid:24)

(cid:10)
(cid:29)
(cid:29)
(cid:24)

(cid:10)
(cid:29)
(cid:29)
(cid:24)

(cid:11)
(cid:29)
(cid:29)
(cid:24)

(cid:11)
(cid:29)
(cid:29)
(cid:24)

(cid:29)
(cid:23)
(cid:29)
(cid:24)

(cid:29)
(cid:23)
(cid:29)
(cid:24)

(cid:23)
(cid:23)
(cid:29)
(cid:24)

(cid:23)
(cid:23)
(cid:29)
(cid:24)

(cid:24)
(cid:23)
(cid:29)
(cid:24)

(cid:24)
(cid:23)
(cid:29)
(cid:24)

(cid:25)
(cid:23)
(cid:29)
(cid:24)

(cid:25)
(cid:23)
(cid:29)
(cid:24)

(cid:26)
(cid:23)
(cid:29)
(cid:24)

(cid:26)
(cid:23)
(cid:29)
(cid:24)

(cid:27)
(cid:23)
(cid:29)
(cid:24)

(cid:27)
(cid:23)
(cid:29)
(cid:24)

(cid:28)
(cid:23)
(cid:29)
(cid:24)

(cid:28)
(cid:23)
(cid:29)
(cid:24)

(cid:31)
(cid:23)
(cid:29)
(cid:24)

(cid:31)
(cid:23)
(cid:29)
(cid:24)

United States

s
n
o
i
t
a
c
i
l

b
u
P

(cid:31),(cid:29)(cid:29)(cid:29)

(cid:28),(cid:29)(cid:29)(cid:29)

(cid:27),(cid:29)(cid:29)(cid:29)

(cid:26),(cid:29)(cid:29)(cid:29)

(cid:25),(cid:29)(cid:29)(cid:29)

(cid:24),(cid:29)(cid:29)(cid:29)

(cid:23),(cid:29)(cid:29)(cid:29)

(cid:29)

(cid:10)
(cid:11)
(cid:11)
(cid:23)

(cid:11)
(cid:11)
(cid:11)
(cid:23)

Computer Vision
Planning and 
Decision Making

Fuzzy Systems
Natural Language Processing 
and Knowledge Representation

Neural Networks

Computer Vision
Computer Vision
Planning and 
Planning and 
Decision Making
Decision Making

Fuzzy Systems
Fuzzy Systems
Natural Language Processing 
Natural Language Processing 
and Knowledge Representation
and Knowledge Representation

Neural Networks
Neural Networks

Computer Vision
Planning and 
Decision Making

figure 3.9  
Annual publications per cluster for Europe 
(all document types), 1998-2017; sources: 
Scopus and Elsevier clustering.

figure 3.10 
Annual publications per cluster for the United 
States (all document types), 1998-2017; sources: 
Scopus and Elsevier clustering.

Europe and the United States show similar cluster patterns, with 
the areas of “Planning and Decision Making” and “Computer 
Vision” strongly driving the AI field. Publications from Europe 
focus more on “Planning and Decision Making” than on 
“Computer Vision.” “Neural Networks” research is rapidly growing 
in terms of journal articles but less so in conference papers across 
all regions, whereas “Natural Language Processing and Knowledge 
Representation” research shows stronger growth in conference 
papers across the regions.

In addition to the influence of language, the differences in AI 
research specialization between China and the United States 
might also result from different priorities; in China, we see a 
focus of AI research on agriculture and in the United States on 
health. “Planning and Decision Making” is applied to automated 
driving systems, reinforcement learning, robotics, human-
computer interface, computer games and films, logistics, and 
mobile networks. A possible explanation may be found in the long 
industrial tradition in Europe and United States.

ARTIFICIAL INTELLIGENCE RESEARCH GROWTH  AND REGIONAL TRENDS

43

Prof. Fredrick Heintz 
Associate Professor of Computer Science 
at Linköping University Linköping, 
President Swedish AI, Sweden

The importance of conferences 
to the AI field
“In computer science, especially in fast moving 
areas such as artificial intelligence, there is a 
long tradition of high-impact and high-prestige 
conferences. This has led to most results first 
being published at international conferences with 
thorough peer review and low acceptance rates. 
For the top conferences in the field, it is common 
to have an acceptance rate of 15-20%. This makes 
the conferences both highly competitive and 
timely. The main advantages of conferences over 
journals are that they have a fast turnaround 
time, they reoccur every year, and they have a 
clear submission deadline. Many researchers also 
publish in journals, often merging and extending 
conference papers because journals provide 
more space to share details. As the importance 
of bibliometrics continues to increase, more 
researchers are also publishing in journals. For 
the AI/machine learning part of the Wallenberg 
AI, Autonomous Systems and Software Program 
(WASP), Sweden's largest individual research 
program, we have explicitly set a goal to increase 
the number of publications from Swedish 
researchers at the top general AI and machine 
learning conferences, namely AAAI, ICML, IJCAI, 
and NIPS.69 Achieving this goal will increase the 
presence of Swedish researchers at these venues 
and set the standard for the researchers in WASP—
to aim for the top general conferences in the field.”

The AI conference landscape

Key AI conferences, and specifically their calls for papers, give an 
early indication of the current trends in AI research. Figure 3.11 is 
comprised of over 300 keywords manually extracted from the call 
for papers from the top 10 AI conferences in 2018, suggested by 
the Stanford AI Index.70 The focus on “Learning” and “Machine 
Learning Systems” continues, but we also see a strong interest in 
multi-agent topics. 

As illustrated in Figure 3.12, the AI conference landscape is 
complex: conferences overlap across subfields, with strong 
connections between core AI and the field of data mining. 
AI conferences also touch upon associated fields such as 
mathematics, statistics, brain science, robotics, computer graphics, 
linguistics, cognitive science, social science, bioinformatics, 
computer systems, or high-performance computing.71 Similarly, as 
noted by Raymond Perrault in this report’s foreword, traditional 
conferences in symbolic AI use the term “Artificial Intelligence” 
while newer AI conferences use machine learning and probabilistic 
reasoning terms and/or connect with more independent 
application conferences.

69  Association for the Advancement of Artificial Intelligence, 

International Conference on Machine Learning, 
International Joint Conferences on Artificial Intelligence, 
Neural Information Processing Systems

70   Artificial Intelligence Index. 2017 Annual Report.  

http://cdn.aiindex.org/2017-report.pdf.

71  ML, DM, and AI Conference Map. 2015. Updated 25 November 2017.  

http://www.kamishima.net/archive/MLDMAImap.pdf.

44

ARTIFICIAL INTELLIGENCE: HOW KNOWLEDGE IS CREATED, TRANSFERRED, AND USEDSupervised
Coding

scheduling

Validation
Single
Mixed

Decision

Preference
simulation
agents

robotics

Visual

Sensing
machine
games

Graphical

Semantics
Game

change

planning

Expansion

Cooperative

MultiAgent
agentbased
Methods
reasoning

Systems
logics
Analysis
Deep
Theory
Vision
argumentation

Learning
Representation

Models

Inference
Neural
Programming

Markov
relaxation
Networks
domains
Probabilistics

MCMC
AI

Prediction

Humanintheloop

schedule

ordersorted

Kernel

Spaces

norms

Speech

Adversarial

Structure

Image

tolerant

Photography

cooperation

figure 3.11 
Keyword cloud from calls for papers by the 10 key 
AI conferences in 2018 suggested by the AI Index.

Statistics

Mathematics

Learning Theory

FOCS
ICALP

STOC
STACS

SODA
ESA

Theoretical 
Computer Science

COLT

ALT

Brain Science

Neural Network
ICANN

IJCNN

ICONIP

AISTATS

ACML

NIPS

ICLR

Planning

Mathematical
Logic
Robotics

Computer 
Vision
ICPR

ECCV

ICCV
CVPR
ACCV

Arti…cial Intelligence
IJCAL
AAAI
IAAI
ECAI
PRCAI
KES

Agent
AAMAS
PRIMA

Computer 
Graphics

InterSpeech 
ICASSP

Speech Signal
Processing

PODS

Machine Learning

Database

ICML

UAI

ECMLPKDD

ILP

Evolutionary
Computation
GECCO
CEC

Knowledge
Representation
ISWC

SIGMOND

VLDB

ICDE
EDBT

Big Data

KDD
ICDM

PAKDD
SDM DS

DSAA

CIKM

Data Mining

WSDM

HCOMP

RecSys

High-Performance
Computing

Computer 
Systems

Bioinformatics
Cheminformatics

WWW
ICWMS
WI

World
Wide
Web

ACL
NAACL
COLING

EMNLP
CoNLL
EACL

IJCNLP

Natural Language
Processing

SIGIR
TREC

ECIR

AIR
Information
Retrieval

Linguistics

SIGCHI
IUI
CSCW

Human
Computer
Interaction

Cognitive Science

Network

Social
Science

figure 3.12 
Landscape of AI conferences, courtesy of Prof. Toshihiro 
Kamishima; National Institute of Advanced Industrial Science 
and Technology (AIST), Japan; source: kamishima.net.

ARTIFICIAL INTELLIGENCE RESEARCH GROWTH  AND REGIONAL TRENDS

45

Nearly half of DBLP 
AI conference papers 
include an author 
from Europe.

(cid:25),(cid:26)(cid:31)(cid:31)

(cid:25),(cid:27)(cid:31)(cid:31)

(cid:25),(cid:28)(cid:31)(cid:31)

(cid:25),(cid:29)(cid:31)(cid:31)

(cid:25),(cid:31)(cid:31)(cid:31)

(cid:26)(cid:31)(cid:31)

(cid:27)(cid:31)(cid:31)

(cid:28)(cid:31)(cid:31)

(cid:29)(cid:31)(cid:31)

(cid:31)

s
d
r
o
w
y
e
k
 
I
A
 
e
r
o
c
 
g
n
h
c
t
a
m

i

 
s
e
l
t
i
t
 
h
t
i

w
 
s
e
c
n
e
r
e
f
n
o
c
 
t
a
 
s
r
e
p
a
p
 
e
c
n
e
r
e
f
n
o
c
 
f
o
 
r
e
b
m
u
N

(cid:28)%

(cid:28)(cid:26)%

(cid:29)(cid:28)%

(cid:29)(cid:29)%
(cid:29)%

€%

(cid:28)(cid:26)%

(cid:29)(cid:31)%

(cid:29)(cid:28)%

(cid:25)%

(cid:25)(cid:31)(cid:31)%

(cid:26)(cid:31)%

(cid:27)(cid:31)%

(cid:28)(cid:31)%

(cid:29)(cid:31)%

(cid:31)%

(cid:25)‡,(cid:26)%

€,€%

†,‡%

(cid:26),(cid:27)%
-(cid:25),(cid:26)%

(cid:25)‚‚(cid:26) – (cid:29)(cid:31)(cid:31)€

(cid:29)(cid:31)(cid:31)(cid:26) – (cid:29)(cid:31)(cid:25)(cid:26)

CAGR (cid:29)(cid:31)(cid:31)(cid:26) – (cid:29)(cid:31)(cid:25)(cid:26) 

China

Europe

United States

Other

Unknown

figure 3.13 
DBLP-tracked conference papers with core 
AI terms in their titles, by region, 1998-2017.

We dive deeper in the diachronic and regional trends of AI 
conferences using data from the Digital Bibliography & Library 
Project (DBLP) Computer Science Bibliography website.72,73,74   

Looking at a very narrow subset of AI-related conferences that 
contain the 142 core AI keywords in their titles, we see that once 
again China has seen the most dramatic increase in conference 
papers over the two decades. However, this increase is not 
significantly different than the overall increase in conference 
papers in the region over the same years. In fact, for each of 
the regions except the United States, the growth of conference 
papers with core AI terms in their titles is less than the growth in 
DBLP-tracked conference papers overall, and the difference for the 
United States is not significant (see Figure 3.13).

If there is an increasing amount of AI-related academic activity, as 
measured by number of conference papers with core AI keywords 
in their titles, it is not apparent in the data examined from the 
DBLP. However, multiple issues with the DBLP data, including 
incomplete coverage of some computer science topics, make 
it impossible to draw definitive conclusions. Further research 
to understand how well the DBLP corpus reflects real-world 
conference research activity, and which areas of computer science 
have better coverage in the database, is needed to better measure 
research activity in this area.

72  dblp Computer Science Bibliography. https://dblp.uni-trier.de/.
73  Ley, M. DBLP: some lessons learned. Proceedings of the VLDB Endowment. 

2009;2(2):1493-1500. doi: 10.14778/1687553.1687577. 

74  dblp Computer Science Bibliography. Statistics – Records in DBLP.  

https://dblp.uni-trier.de/statistics/recordsindblp.html.

46

ARTIFICIAL INTELLIGENCE: HOW KNOWLEDGE IS CREATED, TRANSFERRED, AND USEDChina

s
r
e
p
a
p
 
e
c
n
e
r
e
f
n
o
c
 
f
o
 
e
r
a
h
S

(cid:14)(cid:19)%

(cid:11)(cid:19)%

(cid:15)(cid:19)%

(cid:12)(cid:19)%

(cid:16)(cid:19)%

(cid:18)(cid:19)%

(cid:13)(cid:19)%

(cid:19)

(cid:9)
(cid:10)
(cid:10)
(cid:13)

(cid:10)
(cid:10)
(cid:10)
(cid:13)

(cid:19)
(cid:19)
(cid:19)
(cid:18)

(cid:13)
(cid:19)
(cid:19)
(cid:18)

(cid:18)
(cid:19)
(cid:19)
(cid:18)

(cid:16)
(cid:19)
(cid:19)
(cid:18)

(cid:12)
(cid:19)
(cid:19)
(cid:18)

(cid:15)
(cid:19)
(cid:19)
(cid:18)

(cid:11)
(cid:19)
(cid:19)
(cid:18)

(cid:14)
(cid:19)
(cid:19)
(cid:18)

(cid:9)
(cid:19)
(cid:19)
(cid:18)

(cid:10)
(cid:19)
(cid:19)
(cid:18)

(cid:19)
(cid:13)
(cid:19)
(cid:18)

(cid:13)
(cid:13)
(cid:19)
(cid:18)

(cid:18)
(cid:13)
(cid:19)
(cid:18)

(cid:16)
(cid:13)
(cid:19)
(cid:18)

(cid:12)
(cid:13)
(cid:19)
(cid:18)

(cid:15)
(cid:13)
(cid:19)
(cid:18)

(cid:11)
(cid:13)
(cid:19)
(cid:18)

(cid:14)
(cid:13)
(cid:19)
(cid:18)

Corporate

Government

All

figure 3.14 
Share of conference papers in AI per sector for China, 
1998-2017; source: Scopus.

Europe

s
r
e
p
a
p
 
e
c
n
e
r
e
f
n
o
c
 
f
o
 
e
r
a
h
S

(cid:14)(cid:19)%

(cid:11)(cid:19)%

(cid:15)(cid:19)%

(cid:12)(cid:19)%

(cid:16)(cid:19)%

(cid:18)(cid:19)%

(cid:13)(cid:19)%

(cid:19)

(cid:2)
(cid:3)
(cid:3)
(cid:13)

(cid:3)
(cid:3)
(cid:3)
(cid:13)

(cid:19)
(cid:19)
(cid:19)
(cid:18)

(cid:13)
(cid:19)
(cid:19)
(cid:18)

(cid:18)
(cid:19)
(cid:19)
(cid:18)

(cid:16)
(cid:19)
(cid:19)
(cid:18)

(cid:12)
(cid:19)
(cid:19)
(cid:18)

(cid:15)
(cid:19)
(cid:19)
(cid:18)

(cid:11)
(cid:19)
(cid:19)
(cid:18)

(cid:14)
(cid:19)
(cid:19)
(cid:18)

(cid:2)
(cid:19)
(cid:19)
(cid:18)

(cid:3)
(cid:19)
(cid:19)
(cid:18)

(cid:19)
(cid:13)
(cid:19)
(cid:18)

(cid:13)
(cid:13)
(cid:19)
(cid:18)

(cid:18)
(cid:13)
(cid:19)
(cid:18)

(cid:16)
(cid:13)
(cid:19)
(cid:18)

(cid:12)
(cid:13)
(cid:19)
(cid:18)

(cid:15)
(cid:13)
(cid:19)
(cid:18)

(cid:11)
(cid:13)
(cid:19)
(cid:18)

(cid:14)
(cid:13)
(cid:19)
(cid:18)

Corporate

Government

All

figure 3.15 
Share of conference papers in AI per sector for Europe, 
1998-2017; source: Scopus.

United States

s
r
e
p
a
p
 
e
c
n
e
r
e
f
n
o
c
 
f
o
 
e
r
a
h
S

(cid:14)(cid:19)%

(cid:11)(cid:19)%

(cid:15)(cid:19)%

(cid:12)(cid:19)%

(cid:16)(cid:19)%

(cid:18)(cid:19)%

(cid:13)(cid:19)%

(cid:19)

(cid:2)
(cid:3)
(cid:3)
(cid:13)

(cid:3)
(cid:3)
(cid:3)
(cid:13)

(cid:19)
(cid:19)
(cid:19)
(cid:18)

(cid:13)
(cid:19)
(cid:19)
(cid:18)

(cid:18)
(cid:19)
(cid:19)
(cid:18)

(cid:16)
(cid:19)
(cid:19)
(cid:18)

(cid:12)
(cid:19)
(cid:19)
(cid:18)

(cid:15)
(cid:19)
(cid:19)
(cid:18)

(cid:11)
(cid:19)
(cid:19)
(cid:18)

(cid:14)
(cid:19)
(cid:19)
(cid:18)

(cid:2)
(cid:19)
(cid:19)
(cid:18)

(cid:3)
(cid:19)
(cid:19)
(cid:18)

(cid:19)
(cid:13)
(cid:19)
(cid:18)

(cid:13)
(cid:13)
(cid:19)
(cid:18)

(cid:18)
(cid:13)
(cid:19)
(cid:18)

(cid:16)
(cid:13)
(cid:19)
(cid:18)

(cid:12)
(cid:13)
(cid:19)
(cid:18)

(cid:15)
(cid:13)
(cid:19)
(cid:18)

(cid:11)
(cid:13)
(cid:19)
(cid:18)

(cid:14)
(cid:13)
(cid:19)
(cid:18)

Corporate

Government

All

We gain further insight on various research output types by 
examining conference papers across sectors. In all regions, 
academia is by far the biggest contributor, matching its share 
of conference papers within Scopus almost directly with the 
overall share. 

In China, the corporate sector has a higher share of conference 
papers among all publications and the government sector has 
the lowest (see Figure 3.14). In Europe, the corporate sector 
has only a slightly higher share of conference papers and the 
government sector a slightly lower one, but the differences 
are less pronounced than for China (see Figure 3.15). In the 
United States, the corporate sector has a consistently higher 
share of conference papers. The government sector starts with a 
comparatively high share of conference papers, which declines 
in recent years (see Figure 3.16).

Over 70% of recent 
corporate AI research 
in the United States 
is published as 
conference papers.

figure 3.16 
Share of conference papers in AI 
per sector for United States,  
1998-2017; source: Scopus.

ARTIFICIAL INTELLIGENCE RESEARCH GROWTH  AND REGIONAL TRENDS

47

Key Contributors (academic and corporate institutions)

Number of publications (all)

Field-Weighted Citation Impact  

China
Chinese Academy of Sciences

Tsinghua University

Harbin Institute of Technology

Shanghai Jiao Tong University

Zhejiang University

Europe
Universite Paris Saclay (France)
INRIA Institut National de Recherche en 
Informatique et en Automatique (France)
Imperial College London (United Kingdom)

Universite Pierre et Marie Curie (France)

University of Granada (Spain)

United States
Carnegie Mellon University

Massachusetts Institute of Technology

Microso(cid:141) USA

IBM

Stanford University

figure 3.17 
Top 5 institutional contributors per region by number of AI 
publications (all document types), 2013-2017; source: SciVal.

(cid:20),(cid:29)(cid:24)(cid:31)

(cid:23),(cid:26)(cid:27) 

(cid:31),(cid:28)(cid:29)(cid:24)

(cid:31),(cid:29)(cid:27)(cid:31)

(cid:28), (cid:28)(cid:20)

(cid:28),(cid:26)(cid:25)(cid:31)

(cid:26),(cid:28)(cid:25)(cid:26)

(cid:25), (cid:20)(cid:29)

(cid:25), (cid:28)(cid:27)

(cid:25), (cid:28)(cid:24)

(cid:31),(cid:29)(cid:28)(cid:27)

(cid:26),(cid:28)(cid:25)(cid:26)

(cid:26),(cid:24)(cid:31)(cid:27)

(cid:26),(cid:28)(cid:23)(cid:25) 

(cid:26),(cid:26)(cid:28)(cid:23)

(cid:25).(cid:24)(cid:31)

(cid:25).  

(cid:25).(cid:29)(cid:27)

(cid:25).(cid:25)(cid:20)

(cid:25).(cid:25)(cid:25)

(cid:25).(cid:24) 

(cid:26).   

(cid:26).(cid:28)(cid:20)

(cid:25).(cid:28)(cid:27)

(cid:25).(cid:26)(cid:26)

(cid:28).(cid:29)(cid:31)

(cid:28).(cid:31)(cid:20)

(cid:26).(cid:31)(cid:23)

(cid:23).(cid:27)(cid:31)

(cid:23).(cid:23)(cid:31)

48

ARTIFICIAL INTELLIGENCE: HOW KNOWLEDGE IS CREATED, TRANSFERRED, AND USEDField-Weighted Citation Impact (FWCI) is an indicator of 
the citation impact of a publication. It is calculated by 
comparing the number of citations actually received by 
a publication with the number of citations expected for 
a publication of the same document type, publication 
year, and subject. FWCI is always defined with reference 
to a global baseline of 1.0 and intrinsically accounts for 
differences in citation accrual over time, differences in 
citation rates for different document ages (e.g., older 
documents are expected to have accrued more citations 
than more recently published documents), document 
types (e.g., reviews typically attract more citations than 
research articles), and subjects (e.g., publications in 
medicine accrue citations more quickly than publications 
in mathematics).

Within the regions, we identify key institutions based on number 
of publications and FWCI. This information should be seen in the 
context of the overall regional output and citation impact to gain 
insight into the institutional structure of a region, i.e., a region 
with several mid-sized contributors in AI might appear lower in 
such a list compared to regions with big, centralized research 
organizations. The major 100 contributors to AI publication output 
represent 41% (99k of 241k) of the global AI corpus and hold 32% 
(109k of 338k) of the global conference papers. China stands out 
in the top 100 with over one-third of major contributors (37), 
while the United States (19) and Europe (21) together hold another 
one-third and the remaining countries hold the final one-third. 
The three key regions hold 75% of the world’s contributors to 
AI publications. Figure 3.17 illustrates a few top contributors 
per region. The United States not only has two major corporate 
contributors, but Microsoft USA is also an outstanding contributor 
to citation impact. All top five contributors have citation impacts 
three to five times higher than the world average. Europe is 
dominated by French institutions, followed by British and Spanish 
institutions. France and Italy have strong national governmental 
research organisations with CNRS 75 and CNR. 76  

Other top contributors in China (in order of the number of 
AI publications) are the universities in Huazhong, Beihang, 
Northeastern, Southeast, Wuhan, Xi'an Jiaotong, Dalian, South 
China, and Xidian. In the United States, the following universities 
also make a sizeable contribution to the global AI corpus of 
research: Southern California, Georgia Institute of Technology, 
Illinois at Urbana-Champaign, Berkeley, Harvard, Maryland, 
Washington, Texas at Austin, Michigan, and Columbia. In Europe, 
we note the following universities as top contributors to AI 
publications: Edinburgh (United Kingdom), Leuven (Belgium), 
Politecnica de Catalunya (Spain), Oxford (United Kingdom), 
University College London (United Kingdom), Politecnica 
de Madrid (Spain), Manchester (United Kingdom), Technical 
University of Munich (Germany), Lisboa (Portugal), and Delft 
(the Netherlands). Other countries stand out in the top 100, 
such as Singapore, Iran, Canada, Taiwan, Hong Kong, Japan, and 
Australia, each with two major contributing institutions. Although 
they do not cluster as a key region, they might be important 
players to consider. Other countries like Germany might be 
underrepresented due to their federal research structure compared 
to peers like France, the United Kingdom, or Spain.

75  Centre National de la Recherche Scientifique.
76  Consiglio Nazionale delle Ricerche.

ARTIFICIAL INTELLIGENCE RESEARCH GROWTH  AND REGIONAL TRENDS

49

Prof. Chuan Tang 
Chengdu Library and 
Information Center, Chinese 
Academy of Sciences (CAS), 
China

Interview

How do AI researchers recognize excellent 
research? What indicators do they look for?
The indicators that AI scholars value include 
research that has been presented at top 
academic conferences, is being done at a 
large scale, has won international first-class 
competitions, and has undergone rigorous peer 
review.

How does Chinese science contribute to the 
advancement of AI in China and globally?
The level of AI research in China has rapidly 
increased in recent years, and China is now 
considered to be the most active country in 
this competitive field. At the top academic 
conferences on AI held in 2015,77 the number 
of research papers published by Chinese 
institutions ranked second, exceeding 20% of 
all papers published. In its National Artificial 
Intelligence Research and Development Strategic 
Plan (October 2016),78 the White House pointed 
out that the number of scientific research papers 
on deep learning in China has surpassed that 
of the United States. At the 2017 conference 
from the Association for the Advancement of 
Artificial Intelligence (AAAI), the number of 
papers submitted by Chinese researchers was the 
highest in the world. AI research in China has 
risen to win international attention for Chinese 
researchers, so much so that the AAAI adjusted 
its 2017 schedule to accommodate the Chinese 
New Year. However, in the areas of AI basic 
theory, key technologies, global influence, and 
leading figures in the field, China lags behind 
the world’s leading research institutions. The 
key players driving the development of deep 
learning are not Chinese scholars. Companies 
such as Baidu are hiring foreign experts to take 
charge of their AI-related business ventures.

What are the main problems, obstacles, and 
difficulties involved in the development of AI in 
China?
Among the key elements needed to develop the 
field, China has abundant policies in place and 
capital support, as well as advantages in terms 
of data volume and an application market that is 
unmatched in any other country. The problems, 

obstacles, and difficulties are concentrated in core 
technologies and talent, as well as employment 
and competition.

•  The AI chip is at the core of the industry, with 

the highest technical requirements, added 
value, and strategic positioning. However, 
China’s chip industry has been weak for some 
time, and there is a serious lack of chip design 
and chip foundry capabilities. 

•  China lacks long-term efforts in basic AI 
research. Most researchers tend to follow 
trends in Western countries and work on 
improving existing technologies. There is a 
lack of long-term research in promising areas 
of basic science, particularly in areas without 
obvious benefits in the short term. Although 
the number of published AI papers from China 
has surpassed that of other countries, their 
global influence is limited, resulting in lack of 
impact of the underlying AI technology beyond 
China. 

•  The development and application of AI 

technology requires a high-quality talent 
team. Per recent statistics, the total number 
of people involved in AI in China is only over 
50,000, ranking 7th in the world. Only 38.7% 
of those involved in China’s AI sector have 
more than 10 years of industry experience, 
and there are few domestic educational 
institutes with related majors such as machine 
learning. There is also uneven distribution of 
AI talent technology systems in China. Talent 
is concentrated in the application phase, while 
the infrastructure and technology layers remain 
weak. In general, China still lacks leading talent 
with international influence, innovative and 
entrepreneurial talent to promote industrial 
development, and an industry capable of 
applying AI skills and tools.

77  US, China most active in AI research, report finds. Nikkei 

Asian Review. 9 December 2016.  
https://asia.nikkei.com/Business/Science/US-China-
most-active-in-AI-research-report-finds.

78   National Science and Technology Council, Networking 

and Information Technology Research and Development 
Subcommittee. National Artificial Intelligence Research 
and Development Strategic Plan. October 2016. https://
www.nitrd.gov/PUBS/national_ai_rd_strategic_plan.pdf.

50

ARTIFICIAL INTELLIGENCE: HOW KNOWLEDGE IS CREATED, TRANSFERRED, AND USEDThe special case of AI competitions 

In parallel with or complementary to academia, competitions are 
another important arena for dissemination of AI research, and are 
also used as a vehicle for recruitment, training, and collaboration. 
For this purpose, we examined Kaggle,79 a leading platform for 
hosting public data and machine learning competitions, and a 
home to a dynamic community of data scientists and machine 
learning experts. 

Competition rewards range from knowledge to prestige to 
financial incentives and vary by competition category. Featured 
competitions usually have a financial reward, recruitment 
competitions offer jobs, and research competitions address 
complex problems and can contribute to breakthroughs within 
the community. For example, a competition was hosted for an 
algorithm that could identify the Higgs boson within particle 
collisions at CERN.80,81 Looking at incentives, 36% of competitions 
indicate knowledge as the reward; these competitions are primarily 
used as educational tools and reflect the collaborative nature of 
the field. Competitions with financial incentives do represent a 
sizeable percentage of competitions, however. Jobs represent 1% 
of competition rewards, and are usually hosted by Silicon Valley 
companies and corporations. The financial rewards offered on 
Kaggle vary greatly, and the number of entries to competitions like 
those on Kaggle does not necessarily correlate with the amount 
of prize money offered. High financial rewards seem to lead to 
increases in membership, but many competitions offering non-
financial rewards have had more submissions than those offering a 
job or financial reward. 

79   Kaggle. https://www.kaggle.com/.
80  CERN: Conseil Européen pour la Recherche Nucléaire, the European 

Organization for Nuclear Research. 

81  Jepsen, K. The machine learning community takes on the Higgs. Symmetry. 15 
July 2014. https://www.symmetrymagazine.org/article/july-2014/the-machine-
learning-community-takes-on-the-higgs.

ARTIFICIAL INTELLIGENCE RESEARCH GROWTH  AND REGIONAL TRENDS

51

75% of Kaggle datasets 
are created in the 
United States.

(cid:25),(cid:28)(cid:31)(cid:31)

(cid:25),(cid:31)(cid:31)(cid:31)

(cid:26),(cid:28)(cid:31)(cid:31)

(cid:26),(cid:31)(cid:31)(cid:31)

(cid:27),(cid:28)(cid:31)(cid:31)

(cid:27),(cid:31)(cid:31)(cid:31)

(cid:30),(cid:28)(cid:31)(cid:31)

(cid:30),(cid:31)(cid:31)(cid:31)

(cid:28)(cid:31)(cid:31)

(cid:31)

s
l
e
n
r
e
k
 
f
o
 
r
e
b
m
u
N

Iris Species

Global Terrorism 
Database

Credit Card
Fraud Detection

TMDB 500 Movie
Database

(cid:31)

(cid:30)(cid:31),(cid:31)(cid:31)(cid:31)

(cid:27)(cid:31),(cid:31)(cid:31)(cid:31)

(cid:26)(cid:31),(cid:31)(cid:31)(cid:31)

(cid:25)(cid:31),(cid:31)(cid:31)(cid:31)

(cid:28)(cid:31),(cid:31)(cid:31)(cid:31)

(cid:24)(cid:31),(cid:31)(cid:31)(cid:31)

(cid:23)(cid:31),(cid:31)(cid:31)(cid:31)

(cid:22)(cid:31),(cid:31)(cid:31)(cid:31)

(cid:21)(cid:31),(cid:31)(cid:31)(cid:31)

Number of views

figure 3.18 
Kaggle dataset views, downloads (size of nodes), and kernels, 2010-
2018; source: MetaKaggle, published under CC BY-NC-SA 4.0.82

25% of Kaggle user survey 
respondents are located in 
the United States.

52

ARTIFICIAL INTELLIGENCE: HOW KNOWLEDGE IS CREATED, TRANSFERRED, AND USEDLooking at the organizations that have uploaded datasets by 
region, it is apparent that Kaggle is heavily dominated by the 
United States, with 1,074 of the 1,441 datasets provided by 
organizations based within the United States. These numbers 
do not reflect the amount of sets uploaded by individuals, as 
out of the 9,572 datasets uploaded, only 1,441 were uploaded by 
organizations. Figure 3.18 analyzes Kaggle datasets and provides 
further insights into the community, in particular showing that 
some of the most downloaded and viewed datasets are not 
associated with competitions but are simply robust enough to 
allow users to continually contribute to their analysis.

survey, only 3% of the respondents are from China, and there are 
only 10 Chinese nationals in the top 100 users, with 40% of them 
residing overseas. The lack of Chinese users may be related to the 
relative obscurity of the website within that country, with the sheer 
volume of rival local websites such as Alibaba’s TianChi (天池)  
website, the Latest Activities & TianChi Competition page, 
and DataCastle, with 75,208 registered users. Other popular 
competitions are held by the Data Foundation, Kesci, China 
Computer Federation, Biendata, Big Data Research Center, Hack 
Data, Soda, and many more.83 This could indicate a preference in 
China for national over international competitions.

•  Views on Kaggle indicate the number of times users 
view a dataset online, and as such are an indicator of 
potential interest.

•  Downloads track the number of times users download a 
dataset and are therefore an indicator of further interest. 

•  Kernels are online notebooks in which code can be 
edited or run. The number of kernels is therefore an 
indicator of usage.

In 2017, Kaggle conducted a survey of its users to gather 
information about the community, and received responses from 
1.6% of Kaggle users. Most Kaggle users are in Asia, the United 
States, and Europe. These three regions account for nearly 70% of 
users, with over one-quarter in the United States. Within Europe, 
there are at least 400 respondents each from the United Kingdom, 
France, and Germany. The dominance of these nations within 
the AI sector is reflected in the distribution of the 50 top ranked 
users, with 10 users from France, 9 from the United Kingdom, 
and 6 from Germany. Asia, excluding China, also accounts for a 
large share of survey respondents. India accounts for 16.8% of 
total respondents and 9.3% of top 150 ranked users. In the Kaggle 

82  https://creativecommons.org/licenses/by-nc-sa/4.0/.
83  Zhihu. What are the data competition and related competition websites at 

home and abroad? https://www.zhihu.com/question/36374964.

ARTIFICIAL INTELLIGENCE RESEARCH GROWTH  AND REGIONAL TRENDS

53

3.3  Regional research impact 
and usage comparison

Computer science research is disseminated in a variety of 
publication types (e.g., journals, conferences, etc.) and forms 
(e.g., software, code, etc.). Thus, while article citations may not 
fully capture research impact in the AI field, they nevertheless 
play a relevant role, especially for comparative benchmarking 
of entities on scholarly impact. Article downloads also offer an 
interesting perspective on scholarly usage, revealing a different 
dimension of engagement from those that read an article but 
may not systematically publish or cite an article (e.g., students, 
practitioners, corporate researchers, the public, etc.). While citation 

Regional inequalities 
in citation impact 
do not apply to 
download impact.

impact is a lagging indicator, as the accumulation of citations 
takes time, measuring downloads allows for insights on impact 
immediately after the publication of an article.

For ease of comparison, the Field-Weighted Citation Impact (FWCI) 
and Field-Weighted Download Impact (FWDI) of articles published 
by researchers in the comparator regions were rebased to the 
global annual FWCI and FWDI values within AI, such that the 
FWCI and FWDI of all AI research articles equals 1.0 for all years. 
Figure 3.19 reveals that regional inequalities in citation impact are 
not reflected in download impact, suggesting comparable usage 
of each region’s research. While China’s FWCI is still below that of 
Europe and the United States, it shows tremendous growth over 
the past two decades, from half the world average to reaching the 
world average in recent years. Europe’s FWCI remains stable over 
the period, comfortably higher than the global average. The United 
States’ FWCI is the highest among regions, remaining between 
one and a half to two times as high as the global average over 
the period. The 2016-2017 dip in FWCI for the United States may 
be due to incomplete citation data, although there seems to be a 
slight decreasing trend following a 2014 peak. 

(cid:27).(cid:28)

(cid:27).(cid:31)

(cid:30).(cid:28)

(cid:30).(cid:31)

(cid:31).(cid:28)

(cid:31)

United States
Europe
China

FWCI
FWDI

(cid:30)(cid:5)(cid:5)(cid:4) (cid:30)(cid:5)(cid:5)(cid:5) (cid:27)(cid:31)(cid:31)(cid:31) (cid:27)(cid:31)(cid:31)(cid:30) (cid:27)(cid:31)(cid:31)(cid:27) (cid:27)(cid:31)(cid:31)(cid:3) (cid:27)(cid:31)(cid:31)(cid:2) (cid:27)(cid:31)(cid:31)(cid:28) (cid:27)(cid:31)(cid:31)(cid:1) (cid:27)(cid:31)(cid:31)(cid:127) (cid:27)(cid:31)(cid:31)(cid:4) (cid:27)(cid:31)(cid:31)(cid:5) (cid:27)(cid:31)(cid:30)(cid:31) (cid:27)(cid:31)(cid:30)(cid:30) (cid:27)(cid:31)(cid:30)(cid:27) (cid:27)(cid:31)(cid:30)(cid:3) (cid:27)(cid:31)(cid:30)(cid:2) (cid:27)(cid:31)(cid:30)(cid:28) (cid:27)(cid:31)(cid:30)(cid:1) (cid:27)(cid:31)(cid:30)(cid:127)

figure 3.19 
Rebased AI Field-Weighted Citation Impact (FWCI, bold lines) 
and Field-Weighted Download Impact (FWDI, dotted lines) 
(all document types) per region, 1998-2017; source: Scopus.

54

ARTIFICIAL INTELLIGENCE: HOW KNOWLEDGE IS CREATED, TRANSFERRED, AND USEDn
o
i
t
a
c
i
l

b
u
p
 
r
e
p
 
s
n
o
i
t
n
e
m

 
a
i
d
e
m

 
l
a
i
c
o
s
 
e
g
a
r
e
v
A

 

 

i

s
w
e
n
&
g
n
g
g
o
b
 
e
g
a
r
e
v
A

l

n
o
i
t
a
c
i
l

b
u
p
 
r
e
p
 
s
n
o
i
t
n
e
m

 

 

i

s
w
e
n
&
g
n
g
g
o
b
 
e
g
a
r
e
v
A

l

n
o
i
t
a
c
i
l

b
u
p
 
r
e
p
 
s
n
o
i
t
n
e
m

(cid:13).(cid:16)

(cid:13).(cid:17)

(cid:13).(cid:19)

(cid:19).(cid:14)

(cid:19).(cid:15)

(cid:19).(cid:16)

(cid:19).(cid:17)

(cid:19)

(cid:19).(cid:13)(cid:19)

(cid:19).(cid:19)(cid:14)

(cid:19).(cid:19)(cid:15)

(cid:19).(cid:19)(cid:16)

(cid:19).(cid:19)(cid:17)

(cid:19)

China

Europe

United States

China

Europe

United States

figure 3.20 
Average online mentions per publication per 
region, 2008-2018; source: PlumX dashboard.

but with a smaller base of research publications compared to the 
overall field of AI. 

In the same way as for AI subject categories, we look at the online 
mentions for research coming from the different regions. Figure 
3.20 reveals that China’s AI research is comparatively less discussed 
on social media (potentially due to access restrictions in that 
country) and in blogs/news, although language and coverage 
may influence the latter. Europe has more mentions than China, 
in particular on social media. Media/blog coverage of European 
research may also, to some extent, be negatively influenced by 
the variety of languages spoken in the region relative to the 
predominantly English sources covered. This can also account for 
the United States’ highest media outreach. From a global point of 
view, these dynamics underline the preponderance of English as 
the current lingua franca of AI research, as well as the comparatively 
lower international visibility and outreach of Chinese AI research.

Further exploration by region or subject is possible on the PlumX 
Dashboard accessible via the Elsevier AI Resource Center.85 

84   Plum Analytics. PlumX Dashboards. https://plumanalytics.com.
85  Elsevier. Artificial Intelligence Resource Center.  

https://www.elsevier.com/connect/ai-resource-center.

(cid:13).(cid:16)

(cid:13).(cid:17)

(cid:13).(cid:19)

n
o
i
t
a
c
i
l

Beyond citation and downloads, it is now possible to track the online 
attention received by research. The increasing diversity of scholarly 
communication outlets and connectivity of the research community 
now extends to the media or blog mentions as well as discussions 
on social media channels. The PlumX dashboard84 provides deeper 
and broader insights into mentions and captures for a variety of 
research outputs, such as publication usage (e.g., downloads), 
mentions (e.g., news references), social media (e.g., Facebook Likes, 
Twitter re-tweets), or captures (e.g., Mendeley, GitHub). 

 
a
i
d
e
m

(cid:19).(cid:15)

(cid:19).(cid:16)

(cid:19).(cid:14)

b
u
p
 
r
e
p
 
s
n
o
i
t
n
e
m

 
l
a
i
c
o
s
 
e
g
a
r
e
v
A

(cid:19).(cid:17)

(cid:19)

PlumX Metrics provide insights into the ways people 
United States
interact with research output (articles, conference papers, 
book chapters, etc.).  

Europe

China

PlumX Metrics use 50 sources, including Scopus, SSRN, 
arXiv, SciELO, Airiti, PubMed, YouTube, Vimeo, GitHub, 
Patents, and more. Plum analyzes and covers more than 
40 media sources, such as bepress, ORCID, VIVO, RSS 
Feeds, DOIs, PubMed, Books, SSRN, arXiv, SlideShare, 
SoundCloud, YouTube, Vimeo, Patents, Clinical Trials, 
GitHub, SourceForge, Dryad, figshare, and web pages.

As we see from AI competitions, the research community expands 
into non-institutional researchers and open-source platforms. 
The lines between AI research and application development blur. 
Mentions and captions are new channels to understand, earlier and 
in different ways, the interest in research publications (e.g., journal 
articles or conference papers, which comprise the majority of the AI 
corpus, in addition to a smaller number of book chapters and review 
papers, and a negligible number of other publication types). 

As expected given the substantial proportion of AI research in 
the natural sciences, this field contributes the largest number of 
online mentions (235k), yet when this is normalized for corpus size, 
has comparatively few mentions per publication. This probably 
stems from the specificity of the AI research topics, compared to 
the general interest in more societally relevant fields. Indeed, AI 
application fields, like agriculture and health sciences, are relatively 
strongly discussed and mentioned in social media, blogs, and news, 

ARTIFICIAL INTELLIGENCE RESEARCH GROWTH  AND REGIONAL TRENDS

55

3.4 AI knowledge transfer

Prof. Tieniu Tan 
Institute of Automation, 
Chinese Academy of 
Sciences (CAS), China

“Governments can enforce 
policies and regulations, 
provide sufficient funding, and 
develop and maintain adequate 
infrastructure to support the 
artificial intelligence field. 
Different countries may have 
different initiatives and strategies 
and compete for AI talent, but they 
should also collaborate. In our 
era, international collaboration is 
essential—no country can thrive in 
the AI field in isolation.”

Next to research publications, research collaboration is a core 
element of scholarly communication and knowledge transfer 
between regions, disciplines, and sectors. Collaborations have 
become the cornerstone of innovation and excellence, crossing 
borders, disciplines, and communities. Developments are 
propelled by low-cost travel, high-speed internet connectivity, 
mobile technology, social media, public engagement, and funding 
programs that encourage scholars, communities, and policy 
makers to expand their networks beyond their immediate working 
environments and traditional spheres of influence.

AI talent migrating from one sector to the other is another way of 
knowledge transfer, especially in emerging fields. A recent study by 
LinkedIn Talent solutions86 showed the outflow from academia into 
the corporate sector. The study hinted at other aspects of talent 
recruiting through up-skilling and sourcing talent from adjunct 
fields. On the other side, academia is facing higher competition 
on research talent87 as noted by The Guardian and the Financial 
Times. This section analyzes patterns of the three key regions—
China, Europe, and the United States—within academia across 
regions, between the corporate sector and academia, and along 
the different formats of transfer, such as researcher migration and 
collaboration.

AI grew from cross-discipline inspirations and cross-sector work, 
e.g., between academia and corporations. Collaborative research 
tends to be more impactful in terms of citation rates. Collaboration 
can usually be detected from the patterns of co-authorship of 
published articles or the acknowledgements within them. While 
co-authorship is not the only form of collaboration, particularly 
in fields such as the social sciences and arts and humanities, it 
can be quantified with reasonable robustness and is the basis for 
the indicators discussed in this section. Research collaboration 
is analyzed through the proxy of publications resulting from 
the efforts of two or more authors. Collaboration can be further 
subdivided into the following types: international collaboration, 
national collaboration, or institutional collaboration.

Single authorship is declining across all regions and AI research 
is becoming more collaborative. Europe and the United States are 
increasingly collaborating internationally. For the United States, 
this brings not only an expansion in publication share, but also 
higher citation impact. International collaboration in Europe in 
contrast drives mainly publication share. China is reducing its 
institutional collaboration and shifting to national and international 
collaboration. Its international collaboration brings more citation 
impact than for the United States and Europe. In the direct 
comparison of international collaboration (Figure 3.21) across 
the three regions, we see Europe’s strong increase in publication 
volume and China’s success in increasing volume and citation 
impact through international collaborations.

86  Henriques, P. 3 Unconventional Strategies for Recruiting Machine Learning 

Talent. LinkedIn Talent Blog. 15 August 2018.  
https://business.linkedin.com/talent-solutions/blog/trends-and-research/2018/
recruiting-machine-learning-talent. 

87   Sample, I. ‘We can’t compete’: why universities are losing their best AI 

scientists. The Guardian. 1 November 2017. https://www.theguardian.com/
science/2017/nov/01/cant-compete-universities-losing-best-ai-scientists.; 
Ram, A., UK universities alarmed by poaching of top computer science brains. 
Financial Times. 9 May 2018.  
https://www.ft.com/content/895caede-4fad-11e8-a7a9-37318e776bab 

56

ARTIFICIAL INTELLIGENCE: HOW KNOWLEDGE IS CREATED, TRANSFERRED, AND USEDStrong growth of 
international collaboration 
in AI research over the last 
two decades.

China

United States

Europe

figure 3.21 
Number of publications from 
international collaborations 
(all document types) and 
their rebased Field-Weighted 
Citation Impact (FWCI), 1998-
2017; source: Scopus.

(cid:26).(cid:28)

(cid:26).(cid:29)

(cid:26).(cid:25)

(cid:26).(cid:31)

(cid:31).(cid:27)

(cid:31).(cid:28)

(cid:31).(cid:29)

(cid:31).(cid:25)

(cid:31)

I

C
W
F
 
d
e
s
a
b
e
r

(cid:31)

(cid:24)%

(cid:26)(cid:31)%

(cid:26)(cid:24)%

(cid:25)(cid:31)%

(cid:25)(cid:24)%

(cid:22)(cid:31)%

(cid:22)(cid:24)%

(cid:29)(cid:31)%

(cid:29)(cid:24)%

number of publications

(cid:5).(cid:12)%

China

(cid:12).(cid:6)%

Europe

(cid:8).(cid:7)%

United States

(cid:12).(cid:10)%

World

(cid:5).(cid:6)(cid:10)

(cid:5).(cid:10)(cid:6)

(cid:5).(cid:4)(cid:12)

(cid:12).(cid:10)(cid:3)

figure 3.22 
Academic-corporate share of 
publications (left-hand side, 
dark color) and their Field-
Weighted Citation Impact, 
FWCI (right-hand side, light 
color) (all document types),  
1998-2017; source: Scopus. 

Share of academic-corporate publications

FWCI of academic-corporate publications

More than 90% of AI research is produced by the academic sector. 
Yet academic-corporate collaboration, analyzed here through the 
proxy of publications with authors across both sectors, plays a 
key role in terms of knowledge transfer and innovation. Quick 
research transfer into applications is a key goal of governments 
and innovation programs, stimulating economic development and 
job creation. 

Globally in all sectors, academic-corporate collaboration receives 
higher citation rates, and this is also the case for AI research 

conducted in each region (Figure 3.22). Such cross-sector 
collaborations are particularly prominent in the United States, 
accounting for nearly 9% of their output in the field with a 
citation impact of more than thrice the world average. This can 
be explained by the strong United States AI corporate sector, with 
companies such as Microsoft and IBM contributing significantly 
to AI scholarly output and impact. China is below the 3% global 
average share of academic-corporate publications, and Europe 
slightly above it, with both regions reaping similar citation impact 
benefits these collaborations.

ARTIFICIAL INTELLIGENCE RESEARCH GROWTH  AND REGIONAL TRENDS

57

(cid:26).(cid:27)%

(cid:26). %

Migratory 
Out(cid:5)ow
Migratory 
In(cid:5)ow

(cid:28)(cid:129).(cid:31)%

Transitory

9% of scholarly output 
by academic-corporate 
collaborations in the 
United States

(cid:127).(cid:26)%

(cid:27).(cid:26)%

(cid:143)(cid:29).(cid:27)%

(cid:129)(cid:29). %

(cid:25)(cid:31)(cid:31)%

(cid:143).(cid:129)%
(cid:143).(cid:27)%

(cid:25)(cid:127).(cid:29)%

(cid:26)(cid:31)%

(cid:27)(cid:31)%

(cid:28)(cid:31)%

(cid:127)(cid:129).(cid:127)%

s
r
e
h
c
r
a
e
s
e
r
 
f
o
 
e
r
a
h
S

(cid:29)(cid:31)%

(cid:31)%

China

Europe

United States

Share of AI researchers per mobility class

figure 3.23 
Share of AI researchers (%) per mobility class, 
1998-2017; source: Scopus.

(cid:143)(cid:127).(cid:129)%

Sedentary

Beyond research collaborations, researcher mobility indicates 
knowledge exchange—in person and as researchers physically 
relocate to other regions. Figure 3.23 illustrates the shares of each 
mobility class per region.

The approach presented here uses Scopus author profile 
data to derive a history of active authors. Based on the 
affiliations recorded in each author’s publications over 
time, authors are assigned to a mobility class defined by 
the type and duration of observed moves:  
•   Migratory — researchers who stay abroad or in the 

region for two years or more. 

•   Transitory — researchers who stay abroad or in the 

region for less than two years. 

•   Sedentary — researchers with only a regional affiliation 

in Scopus during the period 1998–2017.

Relative productivity is calculated by dividing the average 
number of publications per researcher for the specific 
mobility class in the region by that of all researchers from 
the region. Relative impact is calculated by dividing the 
average FWCI for the specific mobility class in the region 
by that of all researchers from the region.

58

ARTIFICIAL INTELLIGENCE: HOW KNOWLEDGE IS CREATED, TRANSFERRED, AND USEDChina

t
c
a
p
m

i
 
e
v
i
t
a
l
e
R

(cid:26).(cid:28)
(cid:26).(cid:31)
(cid:27).(cid:28)
(cid:27).(cid:31)
(cid:29).(cid:28)
(cid:29).(cid:31)
(cid:31).(cid:28)
(cid:31).(cid:31)

(cid:31).(cid:31)

Migration In(cid:5)ow

Migration Out(cid:5)ow

Sedentary

Transitory

(cid:31).(cid:28)

(cid:29).(cid:31)

(cid:29).(cid:28)

(cid:27).(cid:31)

relative productivity

figure 3.24 
Relative productivity and relative impact per mobility class for 
China, 1998-2017; bubble size represents the percentage of 
researchers in each mobility class; source: Scopus.

Europe

t
c
a
p
m

i
 
e
v
i
t
a
l
e
R

(cid:127).(cid:2)
(cid:127).(cid:5)
(cid:1).(cid:2)
(cid:1).(cid:5)
(cid:3).(cid:2)
(cid:3).(cid:5)
(cid:5).(cid:2)
(cid:5).(cid:5)

(cid:5).(cid:5)

Migration Out(cid:17)ow

Sedentary

Transitory

Migration In(cid:17)ow

(cid:5).(cid:2)

(cid:3).(cid:5)

(cid:3).(cid:2)

(cid:1).(cid:5)

relative productivity

figure 3.25 
Relative productivity and relative impact per mobility class for 
Europe, 1998-2017; bubble size represents the percentage of 
researchers in each mobility class; source: Scopus.

United States

t
c
a
p
m

i
 
e
v
i
t
a
l
e
R

(cid:127).(cid:2)
(cid:127).(cid:5)
(cid:1).(cid:2)
(cid:1).(cid:5)
(cid:3).(cid:2)
(cid:3).(cid:5)
(cid:5).(cid:2)
(cid:5).(cid:5)

(cid:5).(cid:5)

Sedentary

Migration In(cid:17)ow

Migration Out(cid:17)ow

Transitory

(cid:5).(cid:2)

(cid:3).(cid:5)

(cid:3).(cid:2)

(cid:1).(cid:5)

relative productivity

figure 3.26 
Relative productivity and relative impact per mobility class for the 
United States, 1998-2017; bubble size represents the percentage of 
researchers in each mobility class; source: Scopus. 

Europe sees a net outflow over the 20-year period, with 
7.8% migratory outflow over 6.8% migratory inflow. China 
has a small inflow surplus (0.1 percentage point), with 3.5% 
outflow and 3.6% inflow, while the United States has a net 
gain of 0.3 percentage point. Recent articles from the United 
Kingdom88 and The Netherlands89 highlight this effect. To better 
understand the impact of these effects, Figures 25-27 explore 
relative productivity and impact.

Figure 3.24 shows that China has a very high level of sedentary 
researchers with a rather low relative citation impact and 
relative productivity compared to migratory or transitory 
researchers. On top of the ~25% that come to the country, 17% 
are staying more than 2 years, but still bring productivity and 
impact benefits. Through researcher mobility, China is gaining 
in relative productivity and relative impact.

Figure 3.25 shows that migrating researchers increase 
research productivity in Europe. Europe is gaining impact and 
productivity from its migratory balance, even if 1 percentage 
point more people are flowing out of Europe than into it. 
Similar to China, sedentary researchers in the region show 
lower citation impact levels compared to migratory and 
transitory researchers.

As demonstrated by Figure 3.26 the United States attracts 
impactful researchers and holds the lowest share of sedentary 
researchers. Nevertheless, the high citation impact of sedentary 
researchers might indicate a reason for international inflow into 
the country. While outflowing and transitory researchers have 
lower relative citation impact, they also have higher relative 
productivity.

88  Sample, I. Big tech firms’ AI hiring frenzy leads to brain drain at UK 
universities. The Guardian. 2 Nov 2017. https://www.theguardian.com/
science/2017/nov/02/big-tech-firms-google-ai-hiring-frenzy-brain-drain-
uk-universities. 

89  Universiteit Leiden. Holger Hoos in NRC about AI brain drain. 28 August 

2018. https://www.universiteitleiden.nl/en/news/2018/08/holger-hoos-
about-ai-braindrain-in-nl. 

ARTIFICIAL INTELLIGENCE RESEARCH GROWTH  AND REGIONAL TRENDS

59

number of researchers (cid:18)(cid:17)(cid:17)(cid:16) – (cid:14)(cid:13)(cid:18)(cid:12) 
number of researchers (cid:18)(cid:17)(cid:16)(cid:15) – (cid:18)(cid:17)(cid:16)(cid:13)

China

International 

Industry

(cid:14)(cid:4)(cid:17) ((cid:127)(cid:1))

+(cid:14)(cid:16) (+(cid:1))

(cid:14)(cid:3)(cid:18) ((cid:127)(cid:17))

Academia

(cid:14)(cid:4)(cid:18) ((cid:16)(cid:17)(cid:17))

(cid:3)(cid:16)(cid:16) ((cid:16)(cid:143)(cid:17))

Industry

(cid:4)(cid:16) ((cid:18)(cid:1))

-(cid:18)(cid:1) (-(cid:16))

(cid:1)(cid:1) ((cid:18)(cid:2))

International 

Academia

figure 3.27 
Cross-sector moves of researchers between 
academia and industry, either domestically or 
internationally, for China, 1998-2017; source: Scopus.

Europe

International 

Industry

(cid:18),(cid:13)(cid:4)(cid:3) ((cid:4)(cid:16)(cid:17))

+(cid:14)(cid:14)(cid:16) (+(cid:143)(cid:127))

(cid:16)(cid:14)(cid:4) ((cid:15)(cid:18)(cid:16))

Academia

(cid:18),(cid:18)(cid:2)(cid:12) ((cid:4)(cid:15)(cid:13))

(cid:18),(cid:1)(cid:4)(cid:3) ((cid:2)(cid:18)(cid:2))

Industry

(cid:16)(cid:3)(cid:1) ((cid:18)(cid:2)(cid:17))

-(cid:18)(cid:2)(cid:2) (-(cid:15)(cid:143))

(cid:2)(cid:2)(cid:16) ((cid:18)(cid:16)(cid:18))

International 

Academia

figure 3.28 
Cross-sector moves of researchers between academia 
and industry, either domestically or internationally, 
for Europe, 1998-2017; source: Scopus.

United States

International 

Industry

(cid:12)(cid:2)(cid:16) ((cid:18)(cid:1)(cid:2))

+(cid:18)(cid:18)(cid:3) (-(cid:16)(cid:18))

(cid:2)(cid:4)(cid:4) ((cid:18)(cid:13)(cid:13))

Academia

(cid:14),(cid:13)(cid:12)(cid:1) ((cid:1)(cid:1)(cid:127))

(cid:14),(cid:17)(cid:13)(cid:14) ((cid:16)(cid:17)(cid:16)(cid:1))

Industry

(cid:18),(cid:14)(cid:16)(cid:3) ((cid:1)(cid:18)(cid:18))

-(cid:18)(cid:3)(cid:16) (-(cid:18)(cid:16)(cid:13))

(cid:17)(cid:2)(cid:4) ((cid:4)(cid:17)(cid:2))

International 

Academia

figure 3.29 
Cross-sector moves of researchers between academia 
and industry, either domestically or internationally, for 
the United States, 1998-2017; source: Scopus.

60

ARTIFICIAL INTELLIGENCE: HOW KNOWLEDGE IS CREATED, TRANSFERRED, AND USEDIndustry in the United 
States attracts by far 
the most AI talent from 
international academia.

Researcher mobility is not only constrained to geographical 
movements—researchers can also move between sectors. The 
analyses in Figures 3.27-3.29 provide insights into the cross-sector 
mobility of researchers between academia and industry, both 
within a country and internationally. Overall, there were more 
moves by researchers from academia to industry than vice versa 
across all regions in most of the 20 years. This might speak to 
the academic mandate to educate for societal impact. For the last 
five years (2013-2017), along the accelerated growth of research 
publications, the situation changes and speaks to the brain drain 
discussion, for instance in Europe, but the time frame is too short 
to confirm a full trend shift. Europe seems to be losing academic 
talent, while attracting AI talent for local industry. While Europe 
sees 38 more researcher movements from international academia 
to Europe than vice versa, it faces, in regional comparison, strong 
net outflow of academic talent to international industries.

The United States achieves a net inflow of AI talent, both in 
academia and industry. Industry in the United States has attracted 
by far the most AI talent in the last five years. Whether they are 
coming from the outflow of academics from Europe and China 
requires further investigation.

In summary, AI research is a global competition among established 
and emerging research regions. Research boundaries and formats 
are blurring around conferences, corporate contributions, 
competitions, and social media dialogue. Research collaboration 
and researcher mobility, both across geographies and sectors, 
contributes to knowledge transfer and yields citation impact 
benefits. Analyzing those data more systematically should provide 
further transparency into AI research dynamics and might also 
help unveil the impact of AI as a general-purpose technology.

ARTIFICIAL INTELLIGENCE RESEARCH GROWTH  AND REGIONAL TRENDS

61

Chapter 4

Artificial 
Intelligence 
education  

Educating enough AI talent, fast enough to satisfy corporate 
and research demand, is a key challenge. Digital education 
formats provide important support. They not only resonate 
with AI-interested audiences but also offer lower entry barriers 
for students across the globe. Next to Open Machine Learning 
platforms like AI competitions, there are many popular 
Massively Open Online Courses (MOOCs) offering self-
learning facilities. This chapter presents a brief overview of the 
online education space as well as a case study on AI education 
at the Institute of Automation, Chinese Academy of Sciences.

62

ARTIFICIAL INTELLIGENCE: HOW KNOWLEDGE IS CREATED, TRANSFERRED, AND USEDHighlights

As of December 2017, there were over 9,000 
MOOCs offered by over 800 universities worldwide.
 section 4.1 

Most graduates at the Institute of Automation, 
Chinese Academy of Science select applied 
programs such as Pattern Recognition and 
Intelligent Systems, Computer Application 
Technology, and Control Theory.
 section 4.2 

63

4.1 A brief overview of 
online AI education

As of December 2017, there were over 9,000 MOOCs offered 
by more than 800 universities worldwide.90 Additionally, private 
sector companies are increasingly partnering with MOOC platform 
providers to provide courses. A few rise to the top in terms of 
traction gained with number of learners, in particular, Coursera, 
edX, XuetangX, Udacity, and FutureLearn.91 Unfortunately, other 
than per-course anecdotes about participation and graduation 
rates, none of these platforms appear to provide detailed metrics 
about the number of AI courses provided or the number of 
learners over time in their AI courses. 

Coursera released the top 10 most popular courses on their 
platform for 2017; 3 of the top 10 relate to AI or machine learning.92 
Interestingly, all three courses are not produced by a university, 
but by a private company, whose founder has significant industry 
credentials.93 One of the most popular MOOC platforms, Udacity, 
delivers its courses with very little university involvement.94 

Google, Microsoft, and Nvidia have all launched their own online 
learning platforms relating to AI and machine learning to help 
democratize AI and ensure that their recruitment pipelines for 
engineers with these skills remains full, as well as to promote 
adoption of their hardware and cloud platforms.95 

90  Shah, D. By the numbers: MOOCs in 2017. Class Central. 18 January 2018. 

https://www.class-central.com/report/mooc-stats-2017/.

91  Ibid.
92  Sinha, N. Year in review: 10 most popular courses in 2017. Coursera Blog. 14 

December 2017.  
https://blog.coursera.org/year-review-10-popular-courses-2017.

93  Young, J.R. Andrew Ng is probably teaching more students than anyone else 

on the planet (without a university involved). EdSurge. 7 June 2018. https://
www.edsurge.com/news/2018-06-07-andrew-ng-is-probably-teaching-more-
students-than-anyone-else-on-the-planet-without-a-university-involved.

94  Paterson, J. Despite overall setbacks, one MOOC on AI gains ground. 

Education Dive. 15 June 2018. https://www.educationdive.com/news/despite-
overall-setbacks-one-moocon-ai-gains-ground/525812/.

95  Bhatia, R. What does Google, Microsoft stand to gain from launching free 

MOOCs in AI. Analytics India. 11 April 2018.  
https://www.analyticsindiamag.com/what-does-google-microsoft-stand-to-
gain-from-launching-free-moocs-in-ai/.

64

ARTIFICIAL INTELLIGENCE: HOW KNOWLEDGE IS CREATED, TRANSFERRED, AND USEDInterviews

Lynda Hardman 
Director, Amsterdam Data Science, 
Past President, Informatics Europe, and 
Manager Research & Strategy, Centrum 
Wiskunde & Informatica (CWI)

How can talent shortage in AI be addressed? 
Addressing the AI talent shortage is key to the success 
of AI, particularly in Europe where coordinated 
large-scale initiatives are currently lacking. We require 
more capacity for both teaching students and funding 
researchers. Additionally, coordinated funding should 
build on existing structures and networks rather than 
create new ones to avoid fragmentation of scarce 
expert resources. The principles of computing science 
and AI—in addition to the societal implications of 
automated decision-making based on data—must 
be taught in schools. We need to educate not only 
an elite group of AI experts, but also politicians 
and policy makers, so that they fully understand 
the implications of decisions made by data-driven 
algorithms.
 
A report like this is an invitation to explore facets of 
AI. What discussions and future research do you find 
most thought-provoking and would you like to see? 
Turning decisions over to automated algorithms 
requires an understanding of the implications beyond 
the technical, to also include the ethical, societal, and 
political. From a computer science perspective, we 
need to ensure that results are explainable, unbiased, 
and transparent. I strongly believe that “responsible 
AI” is an asset, particularly for Europe. Following the 
Informatics Europe recommendations on automated 
decision-making, this report offers a number of 
indicators to help us navigate the field. I am pleased 
to see Elsevier raising awareness of the AI field 
through this report, which reveals the richness of a 
discipline that goes beyond data-driven solutions.

Frank van Harmelen 
Professor, Knowledge Representation 
& Reasoning in the Computer Science 
department (Faculty of Science) at the Vrije 
Universiteit, Amsterdam, The Netherlands

Which perspectives particularly draws your 
attention?
The education perspective. It is interesting to realize 
that we include ethical aspects in today’s curriculum, 
not only because of government mandates, but 
also because it is seen as increasingly important by 
researchers themselves. I realized that I’m not aware 
of any specific AI ethics journals or sections. I also 
recognized that students’ expectations (towards an AI 
education) are strongly influenced by social media, 
whereas our curricula are based on proven scientific 
insights and practical case studies. This poses an 
interesting challenge that we are trying to address in 
our new cross-institute Amsterdam School of Data 
Science, which offers a broad and innovative set of 
data science courses. We also see AI massive online 
open courses (or MOOCs) as a great opportunity for 
education as well as their own research area within 
the field of education. AI MOOCs have evolved from 
a way to transfer knowledge to a method of research 
co-creation. In general, the question remains, “How 
can AI education keep pace with its fast evolution?”

A report like this is an invitation to explore facets of 
AI. What discussions and future research do you find 
most thought-provoking and would you like to see?
AI has a great potential in advancing science itself. 
Once we make AI concepts and processes transparent 
and explainable, it will not only accelerate the 
development of new scientific hypothesis, but also 
justify the testing of those hypotheses with the help 
of AI. I see a future where computers move from 
being simple tools used in science to becoming our 
“colleagues” in science. 

EDUCATION

65

4.2 Case study on AI graduates 
in China

To illustrate trends in AI education in China, we analyze data from 
the Institute of Automation, Chinese Academy of Sciences  
(IA, CAS). From 2013 to 2017, there were 140-160 students annually 
enrolled at IA, CAS to pursue postgraduate study. Most graduates 
at IA, CAS selected applied programs, such as Pattern Recognition 
and Intelligent Systems, Computer Application Technology, and 
Control Theory. School recommendation and dispatch plays a large 
role in the destination of graduates of AI higher education at  
IA, CAS.

At IA, CAS, there are five common subject areas related to AI: 
control engineering, control theory and control engineering, 
pattern recognition and intelligent systems, computer application 
technology, and computer technology. Figure 4.1 shows the subject 
area distribution of the graduate students at IA, CAS from 2013 to 
2017. Control engineering is the only subject area in which masters 
students study. Pattern recognition and intelligent systems has 
the largest number of graduate students followed by computer 
application technology and control theory and control engineering. 
From 2013 to 2017, control engineering is the only masters 
students’ subject area.

In China, university and research institutes are also responsible 
for contacting employers and/or creating job hunting plans for 
undergraduates and graduates. The options are: dispatch (by 
the university or research institute), postgraduate (which usually 
means pursuing a PhD degree), secondary dispatch, or going 
abroad (Figure 4.2). Most IA, CAS graduates benefit from primary 
or secondary dispatch, being sent by IA, CAS directly to work. It 
seems easy for graduates in AI to find a job in China. Only a few of 
them pursue a PhD degree, and few go abroad.

In summary, in AI, education can’t wait years until the knowledge 
consolidates. The demand for AI talent has now moved beyond 
existing capacities. Policy governance succeeds in some regions, 
while others build new online formats of education, exploration, 
and integrated research. While ethics are part of some AI curricula, 
it might need to receive much higher attention to educate 
responsible graduates and drive responsible innovation.

Prof. Zhenan Sun 
Institute of Automation, 
Chinese Academy of Sciences 
(CAS), China

“China's artificial intelligence research has 
developed very fast in recent years, increasing 
its global significance within the field. China 
has unique advantages in applied technology 
research and development, for example, in 
the area of face recognition. AI education has 
been receiving more and more attention in 
recent years, not only in universities, but also in 
vocational colleges, and even in secondary and 
primary schools. This growing AI talent base will 
result in even greater future development of the 
AI field in China.”

66

ARTIFICIAL INTELLIGENCE: HOW KNOWLEDGE IS CREATED, TRANSFERRED, AND USED(cid:2)

(cid:2) 

 

(cid:127)

(cid:127)(cid:141)

 

(cid:129) 

(cid:127) 

(cid:129)(cid:3)

(cid:144)

 

(cid:2) 

(cid:2)(cid:2)(cid:141)

(cid:2)(cid:3)(cid:2)

 (cid:144)

(cid:2)(cid:127)(cid:129)

 (cid:2)

(cid:2)(cid:3)(cid:3)%

 (cid:3)%

 (cid:3)%

(cid:157)(cid:3)%

(cid:144)(cid:3)%

(cid:143)(cid:3)%

(cid:141)(cid:3)%

(cid:129)(cid:3)%

(cid:127)(cid:3)%

(cid:2)(cid:3)%

(cid:3)

(cid:2)

(cid:2)(cid:3)(cid:3)%

(cid:144)(cid:127)

  

(cid:157)(cid:144)

(cid:143) 

(cid:143)(cid:144)

(cid:127)(cid:141)

 

(cid:127)(cid:3)

(cid:127) 

(cid:157)

(cid:127)(cid:127)

(cid:127) 

 

 

(cid:129)(cid:129)

(cid:127)(cid:3)

(cid:127)(cid:129)

(cid:141)(cid:2)

(cid:157)

(cid:2) 

(cid:2)(cid:129)

(cid:127) 

(cid:129)

(cid:2) 

(cid:127)(cid:3)

 (cid:3)%

 (cid:3)%

(cid:157)(cid:3)%

(cid:144)(cid:3)%

(cid:143)(cid:3)%

(cid:141)(cid:3)%

(cid:129)(cid:3)%

(cid:127)(cid:3)%

(cid:2)(cid:3)%

(cid:3)

(cid:127)(cid:3)(cid:2)(cid:129)

(cid:127)(cid:3)(cid:2)(cid:141)

(cid:127)(cid:3)(cid:2)(cid:143)

(cid:127)(cid:3)(cid:2)(cid:144)

(cid:127)(cid:3)(cid:2)(cid:157)

(cid:127)(cid:3)(cid:2)(cid:129)

(cid:127)(cid:3)(cid:2)(cid:141)

(cid:127)(cid:3)(cid:2)(cid:143)

(cid:127)(cid:3)(cid:2)(cid:144)

(cid:127)(cid:3)(cid:2)(cid:157)

Computer Application Technology

Control Engineering

Pattern recognition and Intelligent System

Computer Technology

Control Theory and Control Engineering

Social Computing

Dispatch

Postgraduate

Secondary Dispatch

Go abroad

figure 4.1 
Subject areas of IA, CAS graduate students, 
2013-2017; source: IA, CAS.

figure 4.2 
Types of graduate outcomes at IA, CAS, 
2013-2017; source: IA, CAS.

EDUCATION

67

Interview

Yuichiro Anzai 
Senior Advisor, Director, 
Center for Science Information 
Analysis, Japan Society for the 
Promotion of Science (JSPS), 
Chairman, Strategic Council for 
AI Technology 

What is your background in and relation to the 
AI field?
My PhD thesis was on systems theory and 
control theory and my first work in AI was on 
game-playing programs—writing computer 
programs and analyzing human behaviors so 
that the programs could eventually work as 
human players. I did a postdoc at Carnegie 
Mellon University starting in 1976, where I 
worked on human learning processes and 
machine learning. In the 1990s, during the so 
called “AI winter,” not many people talked about 
AI, but I continued to work in the area. Interest 
was really rekindled when we learned about Prof. 
Geoffrey Hinton at the University of Toronto and 
researchers at Google making breakthroughs in 
the use of artificial neural networks for image 
recognition. I have always been “chasing two 
rabbits at once”: AI and cognitive science. These 
two fields were separate in the late 1980s, but 
we are now at a time when we can integrate 
them again. Today, the Japanese government 
is planning to launch a project that could 
make breakthroughs for AI to be truly useful to 
humans—it’s a good time to integrate. But there 
is a lack of researchers who know both sides. 

As chair of the Japanese government’s AI 
strategy council, can you tell us about topics 
you address?
The Japanese AI strategy council was established 
in April 2016 by the Prime Minister. One 
of the first things we did was to publish an 
industrialization roadmap for what we here in 
Japan refer to as “Society 5.0.” This roadmap has 
four pillars: productivity, healthcare, mobility, 
and infrastructure. We are very concerned about 
how to grow AI talent. We need to think about 
education—from primary school to university to 
lifelong adult education.

Many countries form national AI strategies and 
see AI as part of competitiveness. Does there need 
to be a national strategy to bring together various 
players?
We see the increasing strength of the United States, 
China, and Europe. In Japan, we need to emphasize 
our own strengths, including manufacturing, the 
Internet of Things (IoT), robotics, and cyber-physical 
systems. We also need to put more emphasis on 
applied AI within the service industry, healthcare 
and other areas, and prioritize the use of AI in 
finance and cybersecurity. Agriculture is also an 
important field where supply chains can be further 
optimized.

In terms of AI research areas, where do you see 
underinvestment in the field?
The most underdeveloped area is the connection 
of deep learning with more contextual or symbolic 
processing. Human communication ability is far 
ahead of anything deep learning can do right now. 
From a cognitive science perspective, BDI (belief, 
desire, intention) is very difficult to infer externally. 
AI needs to integrate all of that information. 
Another crucial aspect is behavior justification, such 
as the ability of AI to explain its inference processes. 

Can you tell us about the talent need and how AI 
may change society from a job perspective?
Narrow-minded AI talent will not take us very 
far—we need people with diverse skills. Also, in 
terms of nurturing innovation more broadly, we 
need to change the structure of industries to make 
it easier for start-ups to grow. We also need to 
change the employment system, especially in Japan, 
as it traditionally has been quite rigid. It’s quite 
natural that job descriptions will change through 
technological innovation. It’s a lesson from history. 
Jobs will change, and some jobs will disappear, but 
new ones will appear. I am optimistic, but we need 
to change the educational system in response.

68

ARTIFICIAL INTELLIGENCE: HOW KNOWLEDGE IS CREATED, TRANSFERRED, AND USED69

Chapter 5

The imperative 
role of ethics  
in Artificial 
Intelligence   

Experts suggest that ethics and AI appear in the public debate 
in three ways: the purpose of AI, the ways to incorporate 
beliefs, desire, and intentions into AI, and the abuse of AI. This 
chapter strives to explore initial insights into existing data on 
ethics, and underscores the need for a deeper dialogue and 
investigation into ethical aspects of AI for a comprehensive 
view and understanding of the field.

70

ARTIFICIAL INTELLIGENCE: HOW KNOWLEDGE IS CREATED, TRANSFERRED, AND USEDHighlights
Ethics are not an explicit consideration in AI 
research.
 section 5.1 

Addressing the ethics of AI requires collaboration 
between technologists, policy makers, civil society, 
and other stakeholders.
 sections 5.2 

71

5.1  Ethics and AI

Within our keyword analysis and categorization in chapter 2, 
we found three rather general ethics-related keywords in the 
set of 797 (0.4%): “Ethical Values,” “Social Issues,” and “Social 
and Ethical Issues”—these only appeared in the perspectives of 
teaching and media. Given their importance in the comprehensive 
understanding of the field, we wondered and explored how to 
understand this. Are these actually non-AI terms, yielding non-AI 
publications, or are they relevant for the discussion and worth a 
separate thought? We pursued the latter question. 

Stahl96 and colleagues manually reviewed the ethics literature, also 
using “Ethics” as a keyword term, and identified further ethics 
categories, like “Privacy.” This corresponds to observations in calls 
for papers from leading 2018 AI conferences (following Stanford’s 
AI Index).97 

From those conference papers, we manually extracted 326 
additional keywords (>200 overlapped with the existing 797 
keywords list), of which 22 were ethics-related (~5%): 10 referred 
directly to ethics and AI keywords (e.g., “Trustable AI,” “Explainable 
AI,” or “Values in Multiagent Systems”); 7 referred indirectly to it 
(e.g., “Belief-Desire-Intention Models,” “Logics for Norms”); and 
5 used ethics-related keywords (e.g., “Human-aware Planning,” 
“Agents Competing Against Humans”). These terms were mostly 
spotted in multi-agent systems conference papers. Another 
indication for an increasing trend of ethics-related keywords 
and publications are the increasing publication numbers in the 
Scopus results for 2017/2018 on the identified keywords, such as 
“Explainable AI.” 

Most of the terms focus on ethics/value approaches from within 
(multi-agent) systems, in contrast to potential regulatory, external 
approaches to enforce ethics, like policies. Some terms describe 
research fields rather than specific solutions and might require 
further semantic clarification. It is interesting to note that the 
accepted papers from AAMAS987 (a multi-agent conference) refer 
to similar general terms, like those identified by Stahl et al in their 
review paper, such as “Value,” “Security,” “Privacy,” etc. This might 
suggest a base for further research. 

96  Stahl B.C., et al. The ethics of computing: a survey of the computing-oriented 

literature. ACM Computing Surveys. 2016;48(4). Article No. 55. doi:  
http://dx.doi.org/10.1145/2871196.

97   Artificial Intelligence Index. 2017 Annual Report.  

http://cdn.aiindex.org/2017-report.pdf.

98  AAMAS 2018 Stockholm. Accepted Papers: Main Track.  

http://celweb.vuse.vanderbilt.edu/aamas18/acceptedPapers/.

72

ARTIFICIAL INTELLIGENCE: HOW KNOWLEDGE IS CREATED, TRANSFERRED, AND USEDProf. Dame Wendy Hall 
Professor of Computer  
Science in Electronics and 
Computer Science, University  
of Southampton, Director  
of the Web Science Institute,  
United Kingdom 

technical solutions alone cannot solve. Human 
intervention is necessary to tackle the ethical 
and social issues that access to an open and free 
internet brings. Special attention is needed to 
guide AI to avoid perpetuating prejudice. For 
instance, training sets must be carefully selected 
to minimise bias in algorithms, whose future 
uses and applications cannot be predicted. A 
successful AI is an inclusive AI, accounting for 
diversity of gender, age, or origin. The good news 
is that people can come into AI from a variety of 
backgrounds -  interdisciplinarity is necessary for 
developing responsible and ethical AI.

Ethical concerns raise the issues of responsible 
innovation and regulation, and the challenge 
of finding the right balance between the two. 
Too little regulation may lead to unforeseen 
consequences, with potentially devastating 
impact given the growing presence of AI in our 
daily lives. Yet too much regulation can stifle 
innovation.

A successful AI strategy depends on data, 
computing capacity, education, talent, and 
diversity. Ethical considerations must also be 
embedded at the onset of any AI developments, 
to enable and ensure responsible innovations in 
the long term.

Ethics are crucial to AI

Since its conception in the 1950’s AI has 
experienced a seasonal cycle, with big spurts 
of funding when new AI technologies show 
potential for major breakthroughs, followed 
by the so-called AI winters due to the funding 
droughts that follow when the impact does 
not come through fast enough to sustain the 
funding. We are currently in a period of AI hype, 
driven by recent developments in computer 
processing power, the availability of big data, 
and the evolution of Deep Learning. These 
recent developments, however, build on research 
conducted a long time ago: expert systems 
were initially developed in the 80s, and work on 
multidimensional Neural Networks has been 
ongoing for a while. These peaks and troughs 
in AI funding are caused by the length of the 
AI development cycle: it overpromises and 
underdelivers within the short terms of funding 
cycles, as it depends on other advances to come 
to fruition. For these reasons, it is essential 
to continue to support long-term, blue-sky 
research in AI between the hype cycles.

The advent of the World Wide Web and 
subsequently the Semantic Web has helped 
advance research: anyone with access to the 
Internet can now use collaborative documents 
to work across geographies and time-zones,we 
have powerful search engines to help us find the 
information that we want when we want it,  and 
social media or other messaging applications to 
facilitiate communication between scientists. At 
the same time however, we have seen the growth 
of criminal and anti-social behaviour on  the 
Internet such as the dissemination of fake news, 
the promulgation of propaganda, and even the 
proliferation of terrorism. These are issues that 

THE IMPERATIVE ROLE OF ETHICS IN ARTIFICIAL INTELLIGENCE

73

Machine Ethics are 
both prominent and 
relevant for AI.

(cid:28)(cid:31)(cid:31)

(cid:29)(cid:30)(cid:31)

(cid:29)(cid:31)(cid:31)

(cid:30)(cid:31)

(cid:31)

(cid:29)(cid:30)„

(cid:29) 

(cid:29)„

(cid:28)(cid:31)%

(cid:29)(cid:30)%

(cid:29)(cid:31)%

(cid:30)%

(cid:31)%

(cid:29)‚.ƒ

(cid:29) .€

(cid:28).(cid:30)

„(cid:26). (cid:28)‚

‚ .„‚ 

(cid:29)‚.‚€ 

(cid:29)(cid:31)(cid:31)

(cid:26)(cid:30)

(cid:30)(cid:31)

(cid:28)(cid:30)

(cid:31)

AI Publications

AI Publication Share (%)

Prominence Percentile

Online Systems
E-learning
Introductory Ethics

Robots
Robotics
Machine Ethics

Technology
Information
Information Ethics

figure 5.1 
Ethics topics with relevant AI publication 
share, 2013-2017; source: SciVal.

Since ethics is an established research field, we explore the full 
range of Scopus data in form of SciVal Topics of Prominence 
for topics regarding ethics, and ethics in AI. The results include 
“Bioethics,” “Business Ethics,” “Ethics in Special Diseases,” 
“Machine Ethics,” “Ethics in Research,” and “Ethics in Social 
Science” aspects, such as cultures. Overall, we see that ethics-
related topics do not show a strong momentum (high prominence 
percentile). Only 22 topics include any of our AI papers and 
among those, 3 seem to be large enough and relevant for the AI 
discussion. Only one topic seems to be relevant and with sufficient 
momentum: “Machine Ethics.” 

Topic Prominence in Science 
SciVal Topics are a collection of documents with a 
common intellectual interest—a “research problem.” 
Topics can be large or small, new or old, and growing or 
declining, and can evolve. New topics can be born, and 
many topics are inherently multidisciplinary. Old topics 
may be dormant, but still exist. Across all of Scopus, SciVal 
clustered ~97,000 global research topics based on direct 
citation patterns. Overall, we find 33,671 topics with at 
least one AI publication (35.2%) and 4,212 topics with an 
AI publication share >10% (4.4%). Prominence is a new 
indicator that shows the current “momentum” of a topic 
by looking at very recent citations, views, and CiteScore 
values. It predicts and helps researchers and research 
managers identify topics that are likely to be well funded, 
given the correlation between prominence level and 
funding. 

74

ARTIFICIAL INTELLIGENCE: HOW KNOWLEDGE IS CREATED, TRANSFERRED, AND USEDBehavioral research

Human robot interaction

Intelligent systems

International Humanitarian Law

Publishing
Industry

Military
Intelligent agents
responsibility
Automation

Artiﬁcial intelligence
warfare

Design

Law Software agents

Vehicles

Robots Robotics

Anthropomorphic robots

Cognitive systems
Logic programming

morality

robot
weapon
Agents

Models
Military operations
Intelligent robots

Philosophical aspects

Laws and legislation

Railroad  cars

risk
Technology

war
moral philosophy

Risks

Health care

Animals
Decision making
system

Ontology

human rights

autonomy

machine

Multi agent systems

Research

Autonomous agents

Accidentprevention
Computation theory

Social sciences

figure 5.2 
Most relevant key phrases among the topics 
“Robots,” “Robotics,” and “Machine Ethics” 2013-
2017, with font size indicating relevance and color 
indicating growth (positive in yellow and negative 
in brown); source: SciVal.

Exploring this topic through its key phrases (Figure 5.2) reveals that 
it is predominantly concerned, and increasingly so, with “Robotics” 
and “Philosophy.” This seems to suggest a focus on human-
machine interactions and potential ethical, societal, and legal 
consequences of AI applications in robotics.

This short analysis supports initial findings on the disconnect 
between AI and ethics in joint research publications. The insights 
from conference papers indicate stronger interest in the question 
of how to integrate normative systems into AI. While the purpose 
and misuse of AI might be more of a political discussion, initial 
expert exchange invites exploration of reasons such as the 
acceptance guidelines of AI journals on ethics-related papers and 
corporate behavior in patenting, given the litigation risks with 
ethical topics.

THE IMPERATIVE ROLE OF ETHICS IN ARTIFICIAL INTELLIGENCE

75

5.2 AI for the good and 
AI doing good: questions 
on ethics and AI 

The steadily growing stream of policy-related publications on 
artificial intelligence (AI)99, 100, 101, 102 and continuing media interest 
highlight the importance of considering ethical and social issues 
in relation to AI. As the preceding section shows, the attention 
to ethics in the public discourse is not reflected in the research 
literature. There is growing attention to some specific concerns, 
notably privacy, trust, fairness, transparency, and accountability, 
but it is not clear whether addressing these individually can ensure 
that the socio-economic benefits of AI warrant the ethical costs. 

To address ethical issues of AI, it is important to understand the 
underlying concepts, both in terms of AI and in terms of ethics. An 
autonomous vehicle, a facial recognition system, or an insurance 
claim checking algorithm are all examples of AI, but they have 
very different technical capabilities and the ethical questions they 
raise differ greatly. In addition to a better understanding of what is 
meant by AI, which this analysis set out to do, it also must be clear 
what is meant by ethics. 

The current debate on the ethics of AI does not always provide 
the necessary depth and sometimes neglects the fact that there 
are millennia of ethical philosophical debate. The much-discussed 
question of the ethics of autonomous cars, frequently linked to 
the so-called trolley problem103, 104 where a vehicle must decide 
between two different options, all of which injure humans and 
raise ethical concerns, is an example of this problem. The ethical 
quality of a human driver is determined by the consequences of 
what they do, but also by their understanding of the situation 
and their disposition to act in certain ways. From a philosophical 
perspective, this constitutes a complex mix of different ethical 
positions that needs to be understood to come to an ethical 
evaluation of the action. It is unclear how this complexity, namely 
the difference between action, its justification, and internal states, 
can be reflected in AI. This points to the larger question of how the 
ethics of AI can be looked at in a way that is philosophically sound 
as well as practically relevant. 

ORBIT,105 the Observatory for Responsible Research and 
Innovation in Information and Communication Technologies 
(ICT) is a project funded by the UK Engineering and Physical 
Sciences Research Council (EPSRC). Members of the ORBIT 
team who have contributed to this text are listed.

Observatory for Responsible Research and Innovation in ICT 
(ORBIT):
Margherita Nulli (left), ORBIT Project Officer;  
Bernd Stahl, Investigator, Director of the Centre for Computing 
and Social Responsibility at De Montfort University; 
Martin De Heaver, Managing Director;
Marina Jirotka, Investigator, Professor of Human Centred 
Computing;
Carolyn Ten Holter (right), Marketing Officer; 
Paul Keene (not in photo), Online Director

76

ARTIFICIAL INTELLIGENCE: HOW KNOWLEDGE IS CREATED, TRANSFERRED, AND USEDAnother key question is the level at which the ethics of AI needs 
to be addressed. Much of the technical work that aims to address 
the ethics of AI looks at an ethical quality at the technical level 
(e.g., the algorithm behind an application) and the individual 
and organizational responsibilities in developing and deploying 
these.106 While this is no doubt important work, it may well be 
blind to key ethical issues related to ownership, intellectual 
property, economic distribution, and political power that AI also 
raises. The former tries to ensure that the consequences of AI use 
are ethically acceptable, i.e., that AI does good, while the latter 
focus on the broader socio-economic and political consequences. 
When addressing the ethics of AI, both aspects are important, 
but it is not clear whether and how they can be governed 
simultaneously. 

A final question we would like to raise is that of the novelty of 
the ethics of AI. The debate of ethical issues of computing goes 
back to the very beginnings of digital technology.107 108 The same 
is true about AI.109 This raises the question whether in the current 
discussion of AI one can draw on existing insights, tools, and 
methods, or whether AI poses ethical problems of a fundamentally 
novel nature that require radically new thought. 

While we have tried to highlight some open questions with 
regards to ethics and AI relevant to this report, we believe that the 
following key points require further attention:

•  The ethics of AI needs to be aware of and build on existing 

ethical thought. However, it also needs to work in partnership 
with technical and business communities to shape the ethical 
outcomes. This should involve existing processes, such as those 
developed in responsible research and innovation in ICT.110 

•  Ethics is not a fixed set of rules that determine good and 

bad but is thoroughly embedded in social context. To ensure 
the benefits of AI while addressing the pitfalls, appropriate 
governance mechanisms need to be developed.111 

•  AI is not just a technical tool. Due to its potentially enormous 

impact, addressing the ethics of AI requires collaboration 
between technologists, policy makers, civil society, and other 
stakeholders. 

Overall, identifying and addressing the ethics of AI will be a large 
task and societally driven. To do this, the clarification of concepts, 
as done in this study, is important. Further research could look at 
the temporal development of different types of AI research as well 
as ethical questions. The technical capabilities of AI are likely to 
develop rapidly, calling for constant reflection as well as empirical 
insights into social and ethical consequences. Research such 
as the present report should therefore be dynamic, open to all, 
and ethical questions should form a natural component of all AI 
research and education. 

99    European Group on Ethics in Science and New Technologies. Statement on 

Artificial Intelligence, Robotics and ‘Autonomous’ Systems. Luxembourg: 
Publications Office of the European Union; 2018.  
https://ec.europa.eu/research/ege/pdf/ege_ai_statement_2018.pdf.

100   Executive Office of the President National Science and Technology Council 

Committee on Technology. Preparing for the Future of Artificial Intelligence. 
October 2016. https://obamawhitehouse.archives.gov/sites/default/files/
whitehouse_files/microsites/ostp/NSTC/preparing_for_the_future_of_ai.pdf.

101   House of Lords Select Committee on Artificial Intelligence. Report of 

Session 2017–19. AI in the UK: ready, willing and able? HL Paper 100; 2018. 
https://publications.parliament.uk/pa/ld201719/ldselect/ldai/100/100.pdf.
102   House of Commons Science and Technology Committee. Robotics and 

artificial intelligence. Fifth Report of Session 2016-17. HC 145; 2016. https://
publications.parliament.uk/pa/cm201617/cmselect/cmsctech/145/145.pdf.

103   Foot, P. Virtues and Vices and Other Essays in Moral Philosophy. Oxford, UK: 

Oxford University Press; 2002.

104   Wolkenstein, A. What has the Trolley Dilemma ever done for us (and what 
will it do in the future)? On some recent debates about the ethics of self-
driving cars. Ethics Inf Technol. 2018;20(3):1–11.  
https://doi.org/10.1007/s10676-018-9456-6.

105   www.orbit-rri.org.
106   FAT/ML. Principles for Accountable Algorithms and a Social Impact 

Statement for Algorithms.  
https://www.fatml.org/resources/principles-for-accountable-algorithms.
107   Weizenbaum, J. Computer Power and Human Reason: From Judgement to 

Calculation. New York, NY: W. H. Freeman & Co Ltd; 1976.

108   Wiener, N. The Human Use of Human Beings. New York, NY: Da Capo Press; 

1954.

109   Dreyfus, H.L. What Computers Still Can’t Do: A Critique of Artificial Reason. 

Cambridge, MA: MIT Press; 1972.

110   Jirotka, M., et al. Responsible research and innovation in the digital age. 

Comm ACM. 2017;60(5):62-68. https://doi.org/10.1145/3064940.

111    Winfield, A.F., Jirotka, M. Ethical governance is essential to building trust in 

robotics and AI systems. Philos Transact A: Math Phys Eng Sci. 2018.  
http://eprints.uwe.ac.uk/37556.

THE IMPERATIVE ROLE OF ETHICS IN ARTIFICIAL INTELLIGENCE

77

78

ARTIFICIAL INTELLIGENCE: HOW KNOWLEDGE IS CREATED, TRANSFERRED, AND USEDConcluding remarks and 
future research 

Exploring a dynamic, emerging, complex, and changing field like 
AI is a fascinating endeavor, and we hope our report provides 
useful insights into the field as well as inspires further research 
and exploration of the field and its applications and implications. 

The exchange around this report has made it clear that innovation, 
driven by AI as a field of technological capabilities and applications, 
is not only a technological challenge, but is largely driven by data, 
computing infrastructure, and societal acceptance. In this, AI is 
probably not different to previous general-purpose technologies 
and might benefit from that experience (e.g., definition, evolution 
cycles, success factors, societal impact, ethics, etc.).

We hope that this report provides a glimpse into the multifaceted 
nature of AI to help knowledge exchange and dialogue among 
stakeholder groups. We also anticipate that these insights may 
inform research and funding strategies.

We understand that, given the evolving nature of the field, we 
need ways to stay up-to-date. The Elsevier AI Resource Center112  
offers a platform to provide further insights, connect to others’ 
work, and foster further research and discussion. We particularly 
look forward to engaging in efforts in the following directions. 

1   Scoping and structuring of the AI field
Other perspectives, data sources, and algorithms could help 
advance the scoping and structuring of the field and contribute to 
a broader approach to identify and shape emerging research fields.
→ 

 For this, we will continue our semantic research and 
innovation around AI ontologies.

2  Monitoring the emergence and dynamics of AI research 
A basket of relevant metrics will help to build trust in systematic 
analysis. Aligning and agreeing on appropriate ways to monitor the 
evolution and impact of the field will stay a core focus.
→ 

 We will continue our analytical efforts and help partners 
establish and run AI monitors.

3  Knowledge transfer and impact in other societal sectors
Different application sectors accelerate in different regions and 
require differentiated AI capabilities (e.g., “Computer Vision” 
versus “Search and Optimization”).
→ 

 We will provide examples of AI applications and illustrate their 
impact on societal challenges.

4  Facilitating the dialogue for responsible innovation
We gained awareness about the disconnect of ethical topics and 
AI. This includes the challenges of data bias and the need for more 
systematic dialogue.
→ 

 We will explore ways to support this dialogue, such as 
roundtables or in our journals.

112    Elsevier. Artificial Intelligence Resource Center.  

https://www.elsevier.com/connect/ai-resource-center.

79

Interview

Prof. Ingrid Ott, Karlsruhe 
Institute of Technology (KIT), 
Chair in Economic Policy, 
Member of the Commission 
of Experts for Research and 
Innovation (EFI) in 2014-2018, 
Germany

AI seems to lack a universally accepted definition. 
What is the best way to navigate such a field? 
Despite the abundance of AI research 
activity, the notion of AI is still fuzzy. To avoid 
misunderstandings in communication, a 
comprehensive conceptualization of AI is therefore 
indispensable. A good approach is to understand 
the field from the bottom up by integrating the 
perspectives of various disciplines and actors and 
being aware of the dynamics associated with the 
evolution of the technology field. 

AI connects sectors. What does this look like in 
practice? 
I see AI as a typical general-purpose technology 
(GPT), like the steam engine, electricity, or 
information and communication technologies 
(ICT). As such, it is characterized by pervasiveness, 
i.e., it will diffuse into almost any part of our 
economies and lives. Pervasiveness allows for 
linking to far more or less isolated fields such 
as nanotechnology, the most recent GPT since 
ICT. Nanotechnology is especially successful 
in designing new materials, nowadays used 
in completely heterogenous contexts, e.g., for 
coating prostheses, rotor blades of windmills, 
or outer walls of ocean giants. My point with 
this example is that GPTs like AI are the binding 
element between such diverse industries as the 
health and life sciences, green energy, logistics, 
or arts. Throughout the early stage of technology 
development and the associated strong potential 
for further improvement, efficiency gains can 
quickly be realized if the needs of the application 
sectors are coordinated. Platforms that bundle the 
needs of the different actors—and the platform 
design—are of special importance. 

What role does innovation play in the broader AI 
ecosystem, with strong industry influence on the 
one hand and huge societal impact on the other? 

I see the largest economic potential of AI in the 
complementarity of innovation processes between 
AI and downstream industries that perpetually and 
mutually fuel themselves (so-called innovational 
complementarity). The associated implications 
of future AI go far beyond mere technological 
or economic considerations. To get a grasp of 
this feeling, I find it helpful to look back at the 
implications of today’s well-established GPTs. 
Electricity has made value creation independent 
from access to daylight; the use of ICT allows 
for remote work. But the potential of GPTs may 
only be exploited if at the same time family life is 
re-organized accordingly. This also causes friction 
within the existing social security system. Both 
examples also highlight the necessity of secure 
and stable access to complementary infrastructure 
as essential conditions. Frictions on the level 
of complementary technologies thus affect 
productivity of the GPT.

A report like this is less of a conclusion, and 
more of an invitation to explore the facets of AI. 
What discussions and future research are most 
thought-provoking, and would you like to see? 
Like any key technology, AI also has the 
potential of being “Janus-faced.” Its further 
development and diffusion come with challenges 
and opportunities. The abovementioned 
complementarities make AI-enhanced production 
processes not only more complex but also more 
vulnerable to abuse. We thus must continuously 
develop the institutional settings under which 
the technology is developed and used, without 
being naïve or anxious. I strictly plead for extensive 
basic understanding of the functioning logic of 
AI not only for AI developers but also for those 
who apply AI. What I have in mind might be called 
“AI literacy,” which I see as an essential capacity 
even at the level of private users. The direction of 
technological change is shaped by us!

80

ARTIFICIAL INTELLIGENCE: HOW KNOWLEDGE IS CREATED, TRANSFERRED, AND USEDAppendices 
Artificial Intelligence experts

Alessandro Annoni
Head of Digital Economy Unit
Joint Research Centre
European Commission 

Dr. Roberto M. Cesar Jr.
Adjunct Coordinator
São Paulo Research Foundation 
(FAPESP)
Brazil

Prof. Frank van Harmelen
Professor, Knowledge 
Representation & Reasoning 
Vrije Universiteit Amsterdam (VU)
The Netherlands

Dr. Yuichiro Anzai
Senior Advisor, Director, Center for 
Science Information Analysis, Japan 
Society for the Promotion of Science 
(JSPS)
Chairman, Strategic Council for AI 
Technology 
Japan 

Prof. Dame Wendy Hall
Professor of Computer Science in 
Electronics and Computer Science
University of Southampton
Director of the Web Science 
Institute
United Kingdom 

Fredrick Heintz
Associate Professor of Computer 
Science
Linköping University
President Swedish AI Society
Expert Member High Level Expert 
Group on Artificial Intelligence
European Commission
Sweden

Prof. Lynda Hardman
Director, Amsterdam Data Science,
Past President, Informatics Europe,
Manager Research & Strategy, 
Centrum Wiskunde & Informatica 
(CWI)

81

Martin De Heaver
Managing Director 
Observatory for Responsible 
Research and Innovation in 
ICT (ORBIT)
United Kingdom

Marina Jirotka
Investigator Observatory for 
Responsible Research and 
Innovation in ICT (ORBIT), 
Professor of Human Centred 
Computing
United Kingdom

Margherita Nulli 
ORBIT Project Officer 
Observatory for Responsible 
Research and Innovation in ICT 
(ORBIT)
United Kingdom

Carolyn Ten Holter 
Marketing Officer Observatory 
for Responsible Research and 
Innovation in ICT (ORBIT)
United Kingdom

Paul Keene 
Online Director
Observatory for Responsible 
Research and Innovation in ICT 
(ORBIT)
United Kingdom

Prof. Ingrid Ott 
Chair in Economic Policy
Karlsruhe Institute of 
Technology (KIT)
Member of the German Expert 
Commission on Research and 
Innovation (EFI) 2014-2018
Germany

Prof. Enrico Motta
Professor of Knowledge 
Technologies
The Open University
United Kingdom 

82

ARTIFICIAL INTELLIGENCE: HOW KNOWLEDGE IS CREATED, TRANSFERRED, AND USEDDr. Raymond Perrault
Senior Technical Advisor
Artificial Intelligence Center at 
SRI International
United states

Bernd Stahl
Investigator Observatory for 
Responsible Research and 
Innovation in ICT (ORBIT),  
Director of the Centre for 
Computing and Social Responsibility 
at De Montfort University
United Kingdom

Prof. Chuan Tang
Associate Researcher
Chengdu Library and 
Information Center
Chinese Academy of Sciences 
(CAS)
China

Giuditta De Prato
Team leader / Scientific Officer 
Digital Economy Unit
Joint Research Centre
European Commission

Prof. Zhenan Sun
Institute of Automation (IAS)
Chinese Academy of Sciences  
(CAS)
China

Dr. Zhiyun Zhao
Director New Generation 
Artificial Intelligence 
Development Research Center
Party Committee Secretary
Institute of Scientific and 
Technical Information of China 
(ISTIC)
China

Prof. Tieniu Tan
Institute of Automation (IAS)
Chinese Academy of Sciences  
(CAS)
China

APPENDICES

83

Appendices

Elsevier and other contributors

Communications
Marianne Parkhill 
Sacha Boucherie
Taylor Stang

Writer
Stacey Tobin

Design
Edenspiekermann

Program Directors
Maria de Kleijn
Nick Fowler

Program Manager
Clive Bastin

Content & Analytics
Sarah Huggett 
Mark Siebert
Jorg Hellwig
Polly Allen
Amrita Purkayastha
Basak Candemir
Jeroen Baas
Jeroen Geertzen
Kyle Defrancesco
Milan Splinter
Stephanie Faulkner
Thomas Gurney
Wei Wang
Yu Hsuan Chou

Subject matter experts
Dan Olley
Ron Daniel
Paul Groth
Anthony Scerry
Jessica Coxs
Curt Kohler
Sweitze Roffel
Rinke Hoekstra
George Tsatsaronis

Engagement
Dante Cid 
Anders Karlsson
Stephane Berghmans
Ann Gabriel
Xiaoling Kang
Karina Lott
Federica Rosetta
Lesley Thompson
Max Voegler

84

ARTIFICIAL INTELLIGENCE: HOW KNOWLEDGE IS CREATED, TRANSFERRED, AND USEDAppendices

Methodology 

Methodology and rationale
Our methodology is based on the theoretical principles and 
best practices developed in the field of quantitative science 
and technology studies, particularly in science and technology 
indicators research. The Handbook of Quantitative Science and 
Technology Research: The Use of Publication and Patent Statistics 
in Studies of S&T Systems (Moed, Glänzel and Schmoch, 2004)113 
gives a good overview of this field and is based on the pioneering 
work of Derek de Solla Price (1978),114 Eugene Garfield (1979),115 
and Francis Narin (1976)116 in the United States, and Christopher 
Freeman, Ben Martin, and John Irvine in the UK (1981, 1987),117 and 
in several European institutions including the Centre for Science 
and Technology Studies at Leiden University, The Netherlands, and 
the Library of the Academy of Sciences in Budapest, Hungary. 

The analyses of bibliometric data in this report are based upon 
recognized advanced indicators (e.g., the concept of relative 
citation impact rates). Our base assumption is that such indicators 
are useful and valid, though imperfect and partial measures, in 
the sense that their numerical values are determined by research 
performance and related concepts, but also by other, influencing 
factors that may cause systematic biases. In the past decade, the 
field of indicators research has developed best practices that state 
how indicator results should be interpreted and which influencing 
factors should be taken into account. Our methodology builds on 
these practices.

A body of literature is available on the limitations and caveats in 
the use of such bibliometric data, such as the accumulation of 
citations over time, the skewed distribution of citations across 
articles, and differences in publication and citation practices 
between fields of research, different languages, and applicability to 
social sciences and humanities research.118

Document types
We use all document types to provide a comprehensive view of the 
field, including articles and conference paper breakdowns when 
needed:
•  Research Article
•  Book Chapter
•  Newspaper Article

•  Report
•  Review
•  Conference Paper

Comparators
The report focuses on China, Europe, and the United States to 
provide regional insights from large entities with comparable 
research output. Recognizing that research performance is often 
tied to funding levels, we define Europe as the 28 countries in the 
European Union (EU: Austria, Belgium, Bulgaria, Croatia, Cyprus, 
Czech Republic, Denmark, Estonia, Finland, France, Germany, 
Greece, Hungary, Ireland, Italy, Latvia, Lithuania, Luxembourg, 
Malta, Netherlands, Poland, Portugal, Romania, Slovakia, Slovenia, 
Spain, Sweden, and the United Kingdom) and an additional 16 that 
are eligible for Horizon 2020 funding (Albania, Armenia, Bosnia 
and Herzegovina, Faroe Islands, Georgia, Iceland, Israel, Moldova, 
Montenegro, Norway, Serbia, Switzerland, the former Yugoslav 
Republic of Macedonia, Tunisia, Turkey, and Ukraine).

Counting
All analyses make use of whole counting rather than fractional 
counting. For example, if a publication has been co-authored by 
one author from China and one author from the United States, 
then that publication counts towards both the publication count of 
China, as well as the publication count of the United States. Total 
counts for each country are the unique count of publications.

113    Moed H., et al. Handbook of Quantitative Science and Technology Research. 

Dordrecht, Germany: Kluwer; 2004.

114   de Solla Price, D.J. (1977–1978). “Foreword,” Essays of an Information Scientist, 

Vol. 3, v–ix.

115   Garfield, E. Is citation analysis a legitimate evaluation tool? Scientometrics. 

1979;1(4):359-375.

116   Pinski, G., Narin, F. Citation influence for journal aggregates of scientific 
publications: theory with application to literature of physics. Information 
Processing & Management. 1976;12(5):297-312.

117    Irvine, J., et al. Assessing basic research: Reappraisal and update of an 

evaluation of four radio astronomy observatories. Research Policy.  
1987;16(2-4):213-227.

118   Elsevier. Research Metrics Guidebook. 2018. https://www.elsevier.com/

research-intelligence/resource-library/scival-metrics-guidebook.

APPENDICES

85

Fingerprinting
We use the Elsevier Fingerprint Engine®119 based on Natural 
Language Processing (NLP) techniques to identify the main topics 
and concepts from unstructured text. This includes scientific 
articles, abstracts, funding announcements and awards, project 
summaries, patents, proposals, applications, and other sources. 
The unstructured text is mapped to a ranked set of standardized, 
domain-specific concepts that define the text, known as a 
Fingerprint. By aggregating and comparing fingerprints, the 
engine looks beyond metadata.

Identifying preprints in artificial intelligence (AI)
The arXiv preprint metadata corpus is available via their public API 
using metadata queries, or by OAI-PMH for bulk download. For 
this analysis, it was downloaded via OAI-PHM on August 20, 2018 
and included 1,424,193 documents. Of those records, 1,129 were 
found to be invalid (missing data, including unassigned primary 
keyword or year). This is less than 0.08% of records. For our 
keyword search, we used case-sensitive search that was mindful of 
word boundaries for abbreviations like “AI,” but a case-insensitive 
search that ignores word boundaries for full terms. While not a full 
solution for word stemming, this allows us to find pluralization of 
these terms. 

The first arXiv pre-prints that match the “core AI” keyword list were 
added in 1992 in the field of high-energy physics (subject codes 
hep-ph and hep-th). However, few documents match these terms 
prior to 1998: the 36,708 matching documents from 1998 forward 
represent more than 99% of all matching documents in arXiv. Our 
analysis focuses on submissions to arXiv 1998-2018, which includes 
1,354,190 documents.

We ranked all arXiv subject areas based on the percentage of 
documents with the primary subject area that matched at least one 
keyword. Separately, we asked subject matter experts to indicate 
which arXiv categories they would consider to be highly related to 
core AI fields. The experts returned a list of 15 arXiv subject areas.
Of the top 12 subject areas ranked, 11 were included in the list 
provided by the AI subject matter experts. The one subject area 
that was not included, cs.SD or “Computer Science – Sound,” has 
a cryptically short name. In 2017, an Engineering subject area for 

“Audio and Speech Processing” was added; prior to that time, 
all audio processing computer science articles would have been 
included in cs.SD. We believe this was an easy category for our 
team of experts to miss without this information.

The 13th arXiv subject area on our ranked list was from Biology, 
“Neurons and Cognition.” This research area is known to have 
many false positive results because of non-AI discussions of 
neural networks. Beyond that result, broader fields like “Human 
Computer Interaction” and “Emerging Technologies” appeared on 
the list, and while our 12th ranked subject area, “Robotics,” had 
19.9% matching documents, all other categories had fewer than 
15.1%.

The three remaining categories that experts determined to be 
aligned with AI, but that had less than 15.1% matching documents, 
included “Social and Information Networks,” “Computer Science 
and Game Theory,” and “Condensed Matter - Disordered Systems 
and Neural Networks.” These categories are possibly broader than 
others, which dilutes any focus on core AI research. Our team of 
experts might have interpreted these subject names differently 
than they are being used by the arXiv research community. 
Alternatively, it is possible that the list of 142 keywords is skewed 
away from research in these fields. Future research plans include 
establishing more robust methods for identifying AI research from 
titles and abstracts.

Inclusion of hypercollaborative articles
While hypercollaborative articles may represent extreme outliers 
in co-authorship data, they are included in all the analyses since 
they remain proportionally few and because they are counted only 
as a single internationally co-authored article for each country 
contributing to the article, and for each country pairing.

Measuring cross-sector researcher mobility
The approach presented here uses Scopus author profile data to 
derive a history of cross-sector mobility of active author affiliations 
recorded in their publications and to assign them to mobility 
classes defined by the type and duration of observed moves.

119   https://www.elsevier.com/solutions/elsevier-fingerprint-engine.

86

ARTIFICIAL INTELLIGENCE: HOW KNOWLEDGE IS CREATED, TRANSFERRED, AND USEDHow are individual researchers unambiguously identified in Scopus?
Scopus uses a sophisticated author-matching algorithm to 
precisely identify articles by the same author. The Scopus 
Author Identifier gives each author a unique ID and groups 
together all the documents published by that author, matching 
alternate spellings and variations of the author’s last name and 
distinguishing between authors with the same surname by 
differentiating on data elements associated with the article (such 
as affiliation, subject area, co-authors, and so on). This is enriched 
with manual, author-supplied feedback, both directly through 
Scopus and via Scopus’ direct links with ORCID.

How are mobility classes defined?
For any given researcher, the publications of that researcher 
during the period are categorized as either Arrivals, Departures, 
or Domestic based on the author’s affiliation during the period. 
Separately, publications are also categorized as either Academic 
or Industry depending on the type/sector of their institutional 
affiliation. We track researcher movement across sectors by 
analysing changes in the researchers’ affiliations over time.

For comprehensiveness, although we do not start “counting” 
researcher movements prior to the period, if a researcher’s 
portfolio predates the period of analysis, his or her initial category 
(e.g., Domestic Academic) is determined by the latest publication 
prior to the period. For example, if Researcher A publishes 
under an academic affiliation in 2016 and then publishes under 
a corporate affiliation in 2017, we count that as an academic-
to-industry move for 2017. Moreover, if a researcher moves 
multiple times between academia and industry during the 
period, each move is counted separately toward that year’s total 
cross-sector movement, with the limitation that a researcher 
can move a maximum of once in each direction per year. For 
instance, returning to our previous example, suppose Researcher 
A ping-pongs between the sectors frequently, publishing under 
an academic affiliation in 1999, a corporate affiliation in 2005, an 
academic affiliation in 2007, and then another corporate affiliation 
later in 2017. For this series of publications, we would count 1 
move of academic to corporate in 2005 and 2017 each and 1 move 
of corporate to academic in 2007. 

One complicating factor for such analyses is that some authors 
publish with two or more different affiliations, revealing their 
attachment to both academia and industry. These individuals could 
possibly publish with either or both affiliations, depending on the 
specific studies on which they are working. Therefore, the most 
important aspect to analyse is the net movement of researchers 
between the sectors in one direction after subtracting those that 
move in the other direction. This minimizes the influence of the 
fluctuations due to co-affiliation.

Measuring International Researcher Mobility
The approach presented here uses Scopus author profile data to 
derive a history of active regional authors. Based on the affiliations 
recorded in each author’s publications over time, authors are 
assigned to a mobility class defined by the type and duration of 
observed moves.

How are mobility classes defined and measured?
The measurement of international researcher mobility by co-
authorship in the published literature is complicated by the 
difficulties involved in teasing out long-term mobility (resulting 
from attainment of faculty positions, for example) from short-
term mobility (such as doctoral research visits, sabbaticals, 
secondments, etc.), which might be deemed instead to reflect a 
form of collaboration. In this study, active researchers are broadly 
divided into three groups: 

•   Sedentary: active researchers whose Scopus author data for the 
period indicates that they have not published outside the region.
•   Transitory: active researchers whose Scopus author data for the 
period indicates that they have remained abroad or in the region 
for less than two years.

•   Migratory: active researchers whose Scopus author data for the 

period indicates that they have published outside the region.

•  Inflow: researchers whose publication history indicates that they 
first published outside of the region and then published inside 
of the region. 

•   Outflow: researchers whose publication history indicates that 

they first published inside the region and then published 
outside of the region. 

APPENDICES

87

How do we characterize the mobility groups?
To better understand each mobility group, three aggregate 
indicators are calculated for each to provide insight into the 
scholarly productivity, impact, and seniority of the researchers 
within each group: the average field-weighted citation impact 
of the publications by authors in the group, the average relative 
productivity of authors in the group, and the average relative 
seniority of authors in the group. Field-weighted citation impact 
(FWCI) is a measure of publication impact based on citations and 
normalized against the average for publications of a similar age, 
type, and subject. Relative productivity is a measurement of the 
number of publications per year since the first appearance of each 
researcher as an author during the period, relative to all regional 
researchers in the same period. Relative seniority represents years 
since the first appearance of each researcher as an author during 
the period, relative to all regional researchers in the same period. 
All three indicators are calculated for each author’s entire output in 
the period (i.e., not just those articles listing a regional address for 
that author).

Topic Prominence in Science
Through topics analyses, it is possible to identify emerging topics 
with high momentum and how these topics are related to a 
selected entity or group’s research portfolio. Topics can be large 
or small, new or old, and growing or declining. The granularity of 
topics allows us to define the problem-level structure of science. 
Due to the way it is structured, topics do not need field weighting 
to be coherent collections and topics in social science and 
humanities are just as valid as in STEM areas, although they may 
be smaller and less prominent. 

88

ARTIFICIAL INTELLIGENCE: HOW KNOWLEDGE IS CREATED, TRANSFERRED, AND USEDAppendices

Glossary of terms

Adaptive algorithm
An adaptive algorithm is an algorithm that changes its behavior at 
the time it is run, based on information available and an a priori 
defined reward mechanism.

Agent-based system technology
Agents are sophisticated computer programs that act 
autonomously on behalf of their users, across open and distributed 
environments, to solve a growing number of complex problems.

Compound Annual Growth Rate
CAGR is defined as the year-over-year constant growth rate over a 
specified period of time. Starting with the first value in any series 
and applying this rate for each of the time intervals yields the 
amount in the final value of the series. 

1

CAGR(to , tn ) = (V(tn ) /V(to )) tn– to – 1
V(to ) : start value, V(tn ) : finish value,  tn– to : number of years.

Fingerprint
A ranked set of standardized, domain-specific concepts that define 
the text.

FWCI
Field-weighted citation impact (FWCI) is an indicator of mean 
citation impact and compares the actual number of citations 
received by a publication with the expected number of citations 
for publications of the same document type (article, review, or 
conference proceeding paper), publication year, and subject field. 
When a publication is classified in two or more subject fields, 
the harmonic mean of the actual and expected citation rates is 
used. The indicator is therefore always defined with reference to a 
global baseline of 1.0 and intrinsically accounts for differences in 
citation accrual over time, differences in citation rates for different 
document types (reviews typically attract more citations than 
research articles, for example) as well as subject-specific differences 
in citation frequencies overall and over time and document types. 

FWDI
Field-weighted download impact (FWDI) is a replication of the 
FWCI calculation for downloads.

APPENDICES

Machine learning
The process by which an AI uses algorithms to perform functions. 
It is the result of applying rules to create outcomes through an AI.

Natural language processing
Natural language processing (NLP) is a field of computer science, 
AI, and computational linguistics concerned with the interactions 
between computers and human (natural) languages, and, in 
particular, concerned with programming computers to process 
large natural language corpora.

Neural networks
A computational approach based on a large collection of neural 
units, loosely modeling the way a biological brain solves problems 
with large clusters of neurons connected by axons.

Optimization algorithms
A group of mathematical algorithms used in machine learning to 
find the best available alternative under the given constraints.

Pattern recognition
A branch of machine learning that focuses on the recognition 
of patterns and regularities in data, although it is in some cases 
considered to be nearly synonymous with machine learning.

Relative Activity Index
The relative activity index (RAI) approximates the specialization 
of a region in comparison to the global research activity in the AI 
field. RAI is defined as the share of a country’s publication output 
in AI relative to the global share of publications in AI. A value of 1.0 
indicates that a country’s research activity in AI corresponds exactly 
with the global research activity in AI; higher than 1.0 implies a 
greater emphasis while lower than 1.0 suggests a lower emphasis 
compared to global activity.

Supervised learning
The machine learning task of inferring a function from labelled 
training data.

Text mining
The process of examining large collections of written resources to 
generate new information, and to transform the unstructured text 
into structured data for use in further analysis.

89

Appendices

Sources

arXiv120 is an e-print service in the fields of physics, mathematics, 
computer science, quantitative biology, quantitative finance, 
statistics, electrical engineering and systems science, and 
economics that is owned and operated by Cornell University, 
a private not-for-profit educational institution. arXiv is funded 
by Cornell University Library,121 the Simons Foundation,122 and 
member institutions.123 

SciVal 129 offers quick and easy access to the research performance 
of over 10,000 research institutions and 230 regions and countries. 
Using advanced data analytics technology, SciVal processes 
enormous amounts of data to generate powerful visualizations 
in seconds. The 170 trillion metrics in SciVal are calculated from 
46 million publication records published in the 21,915 journals of 
5,000 publishers worldwide.

dblp computer science bibliography124 is an online reference for 
bibliographic information on major computer science publications. 
It has evolved from an early small experimental web server to a 
popular open-data service for the computer science community. 
DBLP’s mission is to support computer science researchers in their 
daily efforts by providing free access to high-quality bibliographic 
metadata and links to the electronic editions of publications.

As of May 2016, DBLP indexes over 3.3 million publications, 
published by more than 1.7 million authors. To this end, DBLP 
indexes more than 32,000 journal volumes, more than 31,000 
conference or workshop proceedings, and more than 23,000 
monographs.

Kaggle 125 is a crowd-sourced platform to attract and train data 
scientists. It is the world’s largest community of data scientists and 
machine learners. Kaggle got its start by offering machine learning 
competitions and now also offers a public data platform, a cloud-
based workbench for data science, and short-form AI education. 
On 8 March 2017, Google announced that they were acquiring 
Kaggle.

Plum Analytics 126 is dedicated to measuring the influence of 
scientific research with the vision of bringing modern ways of 
measuring research impact to individuals and organizations that 
use and analyze research.

ScienceDirect® 127 is Elsevier’s full-text scientific journal platform. 
With an invaluable and incomparable customer base, the use 
of scientific research on ScienceDirect.com provides a different 
look at performance measurement. ScienceDirect.com has more 
than 14 million active users, with over 900 million full-text article 
downloads in 2018.128 

Scopus® 130 is Elsevier’s abstract and citation database of peer-
reviewed literature, covering 71 million documents from more than 
23,700 active journals, book series, and conference proceeding 
papers by 5,000 publishers. 

Scopus coverage is multilingual and global: approximately 46% 
of titles in Scopus are published in languages other than English 
(or published in both English and another language). In addition, 
more than half of Scopus content originates from outside North 
America, representing many countries in Europe, Latin America, 
Africa, and the Asia-Pacific region.

For this report, a static version of the Scopus database covering the 
period 1996-2017 inclusive was aggregated by country, region, and 
subject defined by FORD subject areas.131  

TotalPatent 132 offers the most patent content available from a 
single source and the tools to search, compare, and analyze results.

120   https://arxiv.org/.
121   https://www.library.cornell.edu/about.
122   https://simonsfoundation.org/.
123   https://confluence.cornell.edu/x/ALlRF.
124   https://dblp.uni-trier.de/.
125   https://www.kaggle.com/.
126   https://plumanalytics.com.
127   https://www.elsevier.com/solutions/sciencedirect.
128   https://www.elsevier.com/about/this-is-elsevier.
129   https://www.elsevier.com/solutions/scival.
130   https://www.elsevier.com/solutions/scopus.
131    Frascati Manual 2015. OECD Library. https://read.oecd-ilibrary.org/science-

and-technology/frascati-manual-2015_9789264239012-en#page60.

132   https://www.lexisnexis.com/totalpatent/.

90

ARTIFICIAL INTELLIGENCE: HOW KNOWLEDGE IS CREATED, TRANSFERRED, AND USED(cid:1)(cid:2)(cid:3)(cid:4)(cid:5)(cid:6)(cid:7)(cid:8)(cid:2)
(cid:1)(cid:2)(cid:3)(cid:2)(cid:4)(cid:5)(cid:6)(cid:7)(cid:8)(cid:9)(cid:6)(cid:8)

 

Elsevier is a registered trademark of 
Elsevier B.V. | RELX Group and the  
RE symbol are trademarks of RELX 
Intellectual Properties SA, used under 
license. © 2018 Elsevier B.V.

Mapping Intelligence: Requirements

and Possibilities

Sankalp Bhatnagar1,2, Anna Alexandrova1,4, Shahar Avin3, Stephen Cave1,

Lucy Cheke1,11, Matthew Crosby1,7, Jan Feyereisl8,9, Marta Halina1,4,
Bao Sheng Loe5, Se´an ´O h´Eigeartaigh1,3, Fernando Mart´ınez-Plumed6,

Huw Price1,3, Henry Shevlin1, Adrian Weller1,12, Alan Winﬁeld1,10,

and Jos´e Hern´andez-Orallo1,6(B)

1 Leverhulme Centre for the Future of Intelligence, Cambridge, UK

2 The New School, New York, USA

3 Centre for the study of Existential Risk, University of Cambridge, Cambridge, UK

4 Department of History and Philosophy of Science,

University of Cambridge, Cambridge, UK

5 Psychometrics Centre, University of Cambridge, Cambridge, UK

6 Universitat Polit`ecnica de Val`encia, Val`encia, Spain

jorallo@dsic.upv.es

7 Imperial College, London, UK

8 AI Roadmap Institute, Prague, Czech Republic

9 GoodAI, Prague, Czech Republic

10 Bristol Robotics Laboratory, UWE Bristol, Bristol, UK

11 Department of Psychology, University of Cambridge, Cambridge, UK

12 Alan Turing Institute, London, UK

Abstract. New types of artiﬁcial intelligence (AI), from cognitive assis-
tants to social robots, are challenging meaningful comparison with other
kinds of intelligence. How can such intelligent systems be catalogued,
evaluated, and contrasted, with representations and projections that
oﬀer meaningful insights? To catalyse the research in AI and the future
of cognition, we present the motivation, requirements and possibilities
for an atlas of intelligence: an integrated framework and collaborative
open repository for collecting and exhibiting information of all kinds of
intelligence, including humans, non-human animals, AI systems, hybrids
and collectives thereof. After presenting this initiative, we review related
eﬀorts and present the requirements of such a framework. We survey
existing visualisations and representations, and discuss which criteria of
inclusion should be used to conﬁgure an atlas of intelligence.

1 Introduction

Despite signiﬁcant AI progress, its pace and direction are largely unassessed and
hard to extrapolate. The main reason for this is that we lack the tools to properly
evaluate, compare and classify AI systems, and thus determine the future of the
ﬁeld. The comparison of AI systems with human and non-human intelligence is
c(cid:2) Springer Nature Switzerland AG 2018
V. C. M¨uller (Ed.): PT-AI 2017, SAPERE 44, pp. 117–135, 2018.
https://doi.org/10.1007/978-3-319-96448-5_13

118

S. Bhatnagar et al.

typically performed in an informal and subjective way, often leading to contra-
dicting assessments, especially in hindsight (Hayles 1996; Brooks 1997; Pfeifer
2001; Shah et al. 2016). The comparison between non-human animals and AI
ranges from setting the goal of designing artiﬁcial agents with the behaviour of
“an earwig” (Kirsh 1991) to the “intelligence of a rat” (Cadman 2014; Shead
2017), without further speciﬁcation of what these capabilities or dimensions for
comparison should be. The comparison with humans is not much more precise.
For instance, two decades ago it was cognitive functions related to perception
and action that seemed unattainable – “the gardeners, receptionists, and cooks
are secure in the decades to come” said Steven Pinker in 1994. Now, these are
the functions that look easier to be automated (Frey and Osborne 2017) – “if
a typical person can do a mental task with less than one second of thought, we
can probably automate it using AI either now or in the near future” (Ng 2016).
Today, it is higher-level cognition (causal reasoning, compositionality, theory of
mind, meta-cognition, etc.) that seems more out of reach (Marcus 2018).

The assessment is especially diﬃcult as academia and industry in AI are rush-
ing to achieve breakthroughs for speciﬁc problems, which often require massive
data, computation power, embedded heuristics, strong bias, etc., undermining
generality, autonomy and eﬃciency. For instance, AI can now play most video
games (Hessel et al. 2017) and board games (Silver et al. 2017) better than
humans, but the immediate training data and computational power that are
needed are – as for today – orders of magnitude higher than those used by a
human. As a result, it is diﬃcult for policy makers to assess what AI systems
will be able to do in the near future, and how the ﬁeld may get there. There is no
common framework to determine which kinds of AI systems are even desirable.
This contrasts with empirical science, where measurements, comparisons,
representations and taxonomies are widespread. These characterisations can be
theory-driven, such that a prior conceptual framework is used to categorise sys-
tem features, or can be data-driven, which is increasingly important in many
scientiﬁc disciplines (Marx 2013; Landhuis 2017; Einav and Levin 2014). Con-
ceptual progress partly relies on ﬁnding and testing hypotheses through the
computational analysis of large amounts of shared data (Gewin 2002), using
open data science tools (Lowndes et al. 2017). In AI, we would like to analyse
the state and progress of artiﬁcial systems based on data-grounded investiga-
tions. Research priorities and safety concerns depend on this analysis. We need
to assess whether new AI systems and techniques are simply an incremental
improvement for a narrow collection of applications or a real breakthrough rep-
resenting a more general cognitive ability, which can be established in relation
to comparable abilities in humans and other animals.

This wider view of AI, in the context of all kinds of intelligence, dates back
to Sloman’s “space of possible minds” (Sloman 1984). Figure 1 compares (a) a
ﬁgurative plot (Shanahan 2016), covering a wide range of systems (also see
(Yampolskiy 2014, Fig. 3b), (Arsiwalla et al. 2017, Fig. 3c), and (Sol´e 2017,
Fig. 3d)), with (b) a plot depicting precise experimental results for several ape
species on a battery of tests (Herrmann et al. 2007). The ﬁgure illustrates a

Mapping Intelligence: Requirements and Possibilities

119

i

)
n
a
m
o
d

 
l

i

a
c
o
s
(
 
s

l
l
i

 

k
S
e
v
i
t
i

n
g
o
C

● human children

chimpanzees
orangutans

●

0
1

.

8
0

.

6
0

.

4
0

.

2
0

.

(a) Human-likeness vs Conscious-
ness.

(b) Social vs physical dimensions
for three ape species.

0.5

0.6

0.7

0.8

0.9

1.0

Cognitive Skills (physical domain)

Fig. 1. Diﬀerent kinds of minds represented according to several dimensions. Left: Fig-
urative “human-likeness” vs consciousness (from Shanahan 2016). Right: Two dimen-
sions of cognitive skills (social vs physical domain) according to the results of a test
battery on three diﬀerent groups of apes (adapted from Herrmann et al. 2007).

visible trade-oﬀ between completeness and empirical grounding. What we need is
to leverage the best of both worlds: a data-based representation of very diﬀerent
cognitive systems, including humans, non-human animals, AI systems, hybrids
and collectives, where actual measurements can be aggregated and combined.

This requires a novel platform, an ‘atlas of intelligence’, that integrates an
extensive inventory of cognitive systems, a behavioural test catalogue (with test
batteries that could be aggregated into dimensions) and an experimentation
repository (results from measurements). The platform would be populated col-
lectively, facilitating cross-comparison and reproducibility (Aarts et al. 2015;
Vanschoren et al. 2015). The atlas would represent a new cartographical endeav-
our for a better understanding of the geography of the space of intelligence.

This paper explores the motivations, the requirements and the possibilities
of such an atlas. Section 2 explores in more depth why the atlas is needed in
terms of four lists of items specifying the motivations, applications, dimension
manipulations and entities to be covered in the atlas. Section 3 focuses on the
idea of an atlas as a set of maps, and conﬁgures a partial speciﬁcation in terms
of the maps we would like it to have. This section includes a collection of maps
and graphical representations, some of them already proposed in the literature
(but most without real data) and some desired representations. We close the
paper with a discussion about future work. Finally, Appendix A gives a short
overview of similar initiatives in other areas, and how these relate to the atlas.

2 Motivations, Applications, Dimensions and Kinds

This section presents a series of lists of items covering the motivations and appli-
cations of the atlas (why, and for what, an atlas is needed), and the potential
dimensions and kinds of systems to be included (what the contents should be).
The lists are not meant to be exhaustive and free from overlaps (some ideas are

120

S. Bhatnagar et al.

represented by several items with diﬀerent perspectives), but rather to serve as
initial items for discussion and reﬁnement.

Motivations

The motivations are meant to highlight the needs for an atlas of intelligence.
We identify them following scientiﬁc, technological and societal needs that are
recognised at present or in the near future. Most of them focus on better under-
standing, representing and cataloguing what we know about diﬀerent kinds of
intelligence. Still, we do not exclude the needs for anticipation, so we also cover
those motivations that are related to having better predictions about the existing
and future changes of human and artiﬁcial intelligence.

– Milestones and Pathways: Unlike most non-human biological cognition,
human cognition is changing: the average IQ in many countries is increasing
(the Flynn eﬀect), our memory (Sparrow et al. 2011) is changing due to the
Google eﬀect (digital amnesia), navigation abilities (McKinlay 2016; Milner
2016) atrophied because satnavs, cognitive rewards mechanisms are changing
because of gamiﬁcation, etc. This is a process that is accelerated by technol-
ogy, and will be magniﬁed by the use of cognitive assistants and cognitive
prosthetics, especially for the elderly. AI itself and human-machine hybrids
(either as individual cyborgs or as mixed collectives) are progressing in direc-
tions that we are not able to compare with the past or extrapolate, in order
to understand where all this is leading, and the associated opportunities and
risks (research priorities and safety concerns).

– Laypeople Understanding: In those cases where comparisons can be made
by looking at a set of traits, it is usually too complex for non-experts to
understand what the key diﬀerences are between two cognitive systems, espe-
cially when one is natural and the other is artiﬁcial. Visual representations
are appropriate, as humans are good at understanding geographical analogies
(e.g., the 1948 book “the map that came to life” helped children understand
the countryside where a trajectory and a story were accompanied by maps).
– Crossover Measuring: Data-driven comparison is usually based on mea-
surement instruments, reporting a series of measured values that can be rep-
resented. But we do not have many test batteries that can be applied across
species or even AI systems. The generalisation of representations where diﬀer-
ent natural species and AI technologies are put together would encourage the
adoption and deﬁnition of more universal tests having better measurement
invariance across diﬀerent entities.

– Behavioral Taxonomies: If we go beyond life in our comparisons, espe-
cially if they are based on similarity, the dominant genotypic approach can-
not be used broadly. Taxonomies and models must be mostly informed by
behavioural analyses, in contrast to phenotypic, ethological, genotypic or neu-
rological approaches (Cattell and Coulter 1966; Miller, 1967). But we contem-
plate cladistic principles (using hierarchies or dendrograms) and we consider
morphological or functional similarities as far as they aﬀect behaviour.

Mapping Intelligence: Requirements and Possibilities

121

– Testing New Intelligence: The progress in AI suggests that task-oriented
evaluation (i.e., the performance of an AI system for a particular task) may be
insuﬃcient. Other ways of characterising and measuring AI are needed. While
some capabilities and tests can be inherited or extended from psychometrics
or animal cognition, there may be some other capabilities or skills that are
completely new, especially when we analyse the cognitive proﬁle of human-
machine hybrids or collectives.

– Critical Perspective: There is an urgent need for better understanding the
way the intelligence landscape is changing, for both humans and AI systems,
in areas such as automation, education and ethics. It is hard to regulate or
incentivise some actions not knowing how they aﬀect the intelligence land-
scape.

– Beyond Anthropocentrism: While it is generally accepted that intelligence
is the product of evolution, it is still hard to recognise intelligence in other
species or in AI systems, and compare it without using humans as a yardstick.
– Grand Goals: While interdisciplinarity in the study of intelligence has
increased, there are still many attributes and behaviours that are not prop-
erly mapped between disciplines, and there is no wide recognition of a shared
space. The geographical analogy of an intelligence landscape as an oppor-
tunity for exploration and discovery can help inspire the next generation of
researchers in areas such as comparative cognition, psychology, philosophy
and artiﬁcial intelligence, and, most especially, in multidisciplinary domains.
– Replicability and Reuse: New research procedures and visualisations for
the analysis of cognitive systems are diﬃcult to apply to other systems or
in other contexts. This limitation is more blatant when we see similar ideas,
representations or experimental protocols appear in diﬀerent disciplines.

– Data-driven and Hypothesis-driven: When cognition is analysed in one
species or a particular AI technology, there is a lack of a suﬃciently wide
sample to infer and reject hypotheses. The recent trend of a more collaborative
data science approach should encourage initiatives where data from diﬀerent
disciplines can be put together to test hypotheses about cognition.

Some of the motivations above have deep roots in cognitive science, comparative
psychology, philosophy and AI (Macphail 1987; Thagard 2009; Gentner 2010),
but others are more speciﬁc to some particular areas or emphasise the need of
better representations and comparisons.

Applications
Moving from what is needed to the things an atlas will make possible leads
us to the identiﬁcation of new possibilities and transformations. The criteria
for inclusion are such that the list covers potential applications for scientists,
philosophers, educators, policy-makers and the general public, directly using the
platform or as an indirect result of its use:

– (Re-)Education: Traditionally, children and adults used animals as models
of diﬀerent personalities and capabilities, interacting with them regularly.

122

S. Bhatnagar et al.

Today, in urban societies with less contact with animals, it is becoming easier
to portray and transmit some concepts using robots as models, as cinema and
advertising (especially when targeting children) have already understood. An
atlas covering animals and robots could be used in museums, schools and
universities as a way of articulating over this intelligence landscape.

– Eﬀective Navigation: An atlas, with diﬀerent representations, would help
us locate where we are (humans and AI), the trajectories taken in the past
years and the destinations we are heading to, helping to visualise whether
some targets or trajectories can take us to dangerous areas.

– Ethical Assessments: Visual representations make some ethical dilemmas
about moral agency and patiency more explicit, as we can see whether the way
we look at animals and artiﬁcial agents is diﬀerent from the way measured
traits put them on some representations. This will make some ethical issues
more conspicuous (animal, robot or human suﬀering, uncanny valleys, etc.).
– Consequences: Not only the locations but also the distributions and densi-
ties would help us analyse (especially in advance) the population of creatures
aﬀected by research, law, environment, technology, etc., in a critical way. In
other words, the maps could also be used to represent the areas and entities
(and how many) would be aﬀected by a phenomenon.

– De/Re-Centre Humans: Humans, as a species, groups and individuals
could be located at diﬀerent locations depending on the representation, mak-
ing more explicit that there is a Copernican revolution in the way intelligence
is seen today, sustained in the progress of comparative cognition, evolutionary
psychology and, increasingly, artiﬁcial intelligence.

– Metaphors and Narratives: An atlas would build upon the perception
we have about animal behaviour. This would help us better understand and
locate where we are in AI, in a more meaningful way than just saying “AI is
at the level of the rat”. Instead we would like to align the cognitive proﬁle of a
rat with the cognitive proﬁle of a particular AI system, and see the diﬀerences
in a less monolithic way.

– Archival Exploration: An atlas of intelligence would also help to see a
“history of intelligence”, where we would go from extinct animals and past
computer/AI systems to the present day, seeing the directions their evolution
has taken according to diﬀerent dimensions.

– Morgan’s Canon: C. Lloyd Morgan stated: “In no case is an animal activity
to be interpreted in terms of higher psychological processes if it can be fairly
interpreted in terms of processes which stand lower in the scale of psychologi-
cal evolution and development” (Morgan 1903). An atlas would help interpret,
extend or overhaul this canon for artiﬁcial systems, hybrids or collectives.

– Uniﬁcation: An atlas would require and hence would encourage the def-
inition of more general tests and metrics, embracing natural and artiﬁcial
systems, and would aim at more uniﬁed theories of cognition, going beyond
human psychology and evolution to consider every possible cognitive system,
especially looking at those places in the maps where there are gaps, whether
it is possible to have entities there and how they would be interpreted.

Mapping Intelligence: Requirements and Possibilities

123

Some of the applications clearly derive from the motivations (e.g., beyond anthro-
pocentrism and de/re-centre humans) but others represent possibilities that per-
haps were not even recognised as a necessity, such as the use of the atlas for
archival exploration, which may lead to unforeseen purposes. Concerning the
needs and possibilities introduced above, represented by the motivations and
applications, we add the dimensions and the kinds of systems we want to cover,
which specify the atlas in general terms.

Dimensions

We are aware of the lack of consensus about the most relevant attributes for
the analysis of cognition – not to mention general theories. Because of this dis-
agreement, we want the atlas to be able to integrate diﬀerent perspectives and
attributes of the interest. Consequently,
rather than enumerating the speciﬁc
dimensions of representation that could be used, which could ultimately be cre-
ated and reﬁned by the users, we clarify how these dimensions operate in general
terms.

– Observation-Based: the dimensions of representation should be agnostic to
particular hypotheses, so that the users could do their theories from the values
observed. Of course, there are always some underlying assumptions (and the
inﬂuence of underlying theories) whenever an observation or measurement is
made, but this should be as explicit as possible.

– Multiple Interface: the atlas should allow users to project or aggregate the
data and derive some maps and other representations from these transforma-
tions, as usual in other visualisation frameworks.

– Interactive Querying: the atlas could be interrogated through queries,
including ﬁlters and joins across diﬀerent data sources, in an interactive way,
as in tools of analytical processing.

– Creative and Constructive: the atlas should allow users to combine ele-
ments, creating new features (and hence new spaces) and creating new enti-
ties, such as populations or individuals, combining their cognitive entities
under some speciﬁed models.

– Populational/Theoretical: the elements to represent could correspond to
actual populations or subgroups but also to theoretical elements and groups.
– Bottom-Up/Top-Down: the dimensions could correspond to basic psycho-
logical mechanisms or to more abstract, integrated skills. The atlas should
allow users to aggregate and disaggregate these dimensions.

– Transversal Connections: the atlas would allow users to combine
behavioural traits (skills, functions, capabilities) with non-behavioural traits
(physical traits, computational eﬀort, evolutionary traits, etc.).

– Topographical/Geographical Visualisation: the atlas should combine
as many elements of visualisation and representation (colours, contours, tex-
tures) as may be found useful to show the information in insightful ways.

Despite the intended ﬂexibility, some of these dimensional operations give a more
precise account at the speciﬁcation level for the atlas on how data, hypotheses

124

S. Bhatnagar et al.

and visualisations must be connected. For instance, the multiple interface, the
interactive querying and the topographical and geographical representations very
much resemble some common retrieval and representational systems powered by
data visualisation tools. On the other hand, the other dimensional characteristics
are more aligned with the management of conceptual ontologies and taxonomies.

Kinds of systems

Finally, regarding the kinds of cognitive systems to be represented, we want to
cover all possible ranges, according to several criteria: integration, nature, time,
distribution and existence. This comprehensive view of cognitive systems would
ultimately allow us to put very diﬀerent types of entities into comparison.

– General and Narrow: speciﬁc systems aiming at a single task or species
in a narrow environment could be covered, as well as those systems that are
ﬂexible in a broad range of environments.

– Individual and Collective: individual entities could be located as well as

collectives (along with their components).

– Biological and Artiﬁcial: living beings, including plants and animals, and

artiﬁcial systems, including autonomous agents, robots, corporations, etc.

– Hybrid (Extended/Enhanced Minds): humans improved by technology,
either internally (enhanced, as cyborgs or through nootropics) or externally
(extended by assistants), as well as AI systems using human computation.

– Novel and Old: covering current living beings and AI systems, but also

extinct species and AI systems of the past.

– Distributed and Centralised: systems that are identiﬁed by a single body,
but also natural and artiﬁcial swarms as well as distributed intelligence,
including societies.

– Alien and Fictional: even for speculation or theorisation, the atlas could

also show some imaginary entities.

Apart from the scientiﬁc questions needed to build such a platform, its success
depends on the engagement of the (research) community and other stakeholders.
It is crucial then to identify whether the needs, dimensions and elements repre-
sented are well aligned with the potential users and contributors. Consequently,
we conducted a preliminary survey to get feedback from researchers and other
potential users in many diﬀerent areas, using the items described in this section.
We targeted diﬀerent communities: artiﬁcial intelligence, animal cognition, psy-
chology, philosophy, design and some others. The results of the questionnaire
were positive in general. This was not taken as a justiﬁcation or validation of
the categories presented here but, more on the contrary, as a way of recognising
omissions, duplications or desiderata nobody is asking for. We focused especially
on the open comments from some respondents who were more critical1.

1 A detailed analysis of the questionnaire can be found in (Bhatnagar et al. 2017).

Mapping Intelligence: Requirements and Possibilities

125

We considered the previous motivations, intended applications, dimensions
to consider, and entities to cover to be a suﬃcient reason for starting the con-
struction of an atlas, with the necessary caution about potential pitfalls and the
need of selecting pieces of the atlas that could be chosen as more low-hanging
fruits of the whole project. The previous lists are preliminary, and the priorities
for selecting which categories are most important to start with—e.g., prototypes
or ﬁrst cornerstones of the project – are still subject to debate.

Next, we reﬁne this ﬁrst conception of the atlas by considering existing rep-

resentations and maps.

3 Collections of Maps: Representational Possibilities

As an atlas is a set of maps, in this section we collect and recreate some of the
maps that have been proposed in the past, most of them at a ﬁgurative level,
and discuss representations that we would like to include in the future. Figure 1
contained examples of a classical multidimensional representation (although two
dimensions are especially ﬁtted for paper and screens). The axes represent dimen-
sions of interest and the points represent the entities (the cognitive systems) we
want to compare. We will see many others of these, being diﬀerent because of the
dimensions that are chosen or the elements that are represented. In other cases,
the representations detach from this multidimensional view but still remain
meaningful in geographical or topological terms.

Fig. 2. Left: Scala naturae, as depicted in the 16th century (de Valad´es 1579). Mid-
dle: a representation of Dennett’s Tower of Generate and Test, which depicts crea-
tures according to when and how they adapt (Dennett 1995), Right: Godfrey-Smith’s
reﬁnement of the bottom part of Dennett’s tower (the part corresponding to cognitive
evolution) in the form of a tree (Godfrey-Smith 2015, Fig. 2).

We start with the oldest and simplest representations, those inspired in the
scala naturae, which are monolithic, or at most, arboreal (see Fig. 2), where
membership to a species is replaced by other criteria for classiﬁcation. At some
point the categorical representations (monolithic or hierarchical) led to more
quantitative and multidimensional representations, as we see in Fig. 3.

126

S. Bhatnagar et al.

(a) Comparison of hardware be-
tween several living and inanimate
objects (Moravec, 1998, Fig. 1)

(b) Figurative space of minds (Yam-
polskiy, 2014, Fig. 1)

(c) “Morphospace of consciousness”
from (Arsiwalla et al., 2017, Fig. 3)

(d) “Biological computational mor-
phospace” (Sol´e & Macia, 2011, Fig.
7)

(e) Cognitive space of human-robot
interactions (Sol´e, 2017, Fig. 2)

(f) Illustration of Hans Moravec’s
“landscape of human competence”
(Tegmark, 2017, Fig. 2.2)

Fig. 3. A collection of ﬁgurative maps of intelligence.

Moravec was not the ﬁrst one to compare animals and computers according
to several dimensions, but some of his plots had an important eﬀect on the nar-
ratives about how far AI had come in the 1990 s. For instance, Fig. 3a compares
computational power (speed and storage capacity) for a wide range of entities.

Mapping Intelligence: Requirements and Possibilities

127

Some other representations have tried to compare animals and artiﬁcial sys-
tems for other dimensions. For instance, computational eﬃciency can be replaced
by an estimation of energy consumption (Winﬁeld 2014), which is a physical
property that can be used as a dimension alongside some other more behavioural
traits. One common representation is based on Venn diagrams, where the sizes
and locations are completely arbitrary, and the only purpose is to show a diver-
sity and inclusions/overlaps between sets, such as Fig. 3b from Yampolskiy
(2014). Some other plots are more speculative, especially when the goal is to
represent consciousness, such as the one from Arsiwalla et al. (2017) in Fig. 3c.
Other comparisons are at a much more physical (or implementational) level,
such as the one from Sol´e (2017), representing the “morphospace” in terms of
“embedding”, “diversity” and “parallelism”, shown in Fig. 3d, or represent some
aspects of human-robot interaction, again ﬁgurative (Fig. 3e). An interesting
twist is given when the space represents the tasks or abilities (without any clear
criterion for proximity), but the Z-dimension (height) is represented by time
(or progress in AI). According to this, we have a ﬁgurative plot like Tegmark’s
representation (Fig. 3f) of Moravec’s landscape (Tegmark 2017).

A more thoughtful analysis of dimensions may lead to more than three ele-
ments, whose representation (if all of them are quantitative) is more cumber-
some. Star (cobweb) plots are a practical option here, although they can get too
messy if too many individuals are shown. Also, trajectories are more diﬃcult to
represent in these plots. Figure 4 shows how four dimensions are used to compare
the intelligence of several organisms.

Fig. 4. Comparison of diﬀerent systems on a space of four dimensions, using star plots
(Winﬁeld 2017, Figs. 2 and 3).

Following the comments of some of the respondents of the questionnaire, we
are also interested in representations of ‘collective intelligence’, even if ﬁgurative.
For instance, Fig. 5 represents a proﬁle of members of a team and tries to derive
aggregate values (minima, maxima and means) for the group.

So far, all the previous representations were ﬁgurative, in the sense that there
was no measured data or observations from which the maps were represented, but

128

S. Bhatnagar et al.

Fig. 5. Collective diversity in terms of psychometric proﬁles for two ﬁgurative groups
of ﬁve agents, shown with circles. For each plot, the x dimension represents IQ score
and the y dimension represents social sensitivity. The mean point is shown with the
cross and the maximum and minimum envelopes are represented with a triangle and a
square respectively (Hern´andez-Orallo 2017, Fig. 15.3).

just some general knowledge and intuitions of these magnitudes. In what follows,
we include some representations that are using real data. For instance, the easiest
way of comparing two systems or species is by comparing their results for the
same task, as in Fig. 6a and b. But we can also compare abstract or aggregated
traits or skills, as we showed in Fig. 1. A representation that is becoming very
common in AI is to show the results normalised by human performance (Figs. 6c
and d), even in cases where many tasks are aggregated.

While these representations are common and useful, they do not ﬁt the geo-
graphical representation of the atlas well. In other words, these plots are not
meant to compare AI systems and humans. They are just meant to compare AI
systems, where human data is just used to make the results for several games
somewhat commensurate when aggregated. This means that the space is anthro-
pocentric, where humans would always be at 100% – a Ptolemaic model. Indeed,
for both plots one of the dimensions does not apply to humans. For instance,
in Fig. 6c, human accuracy is achieved with a number of frames that is at most
in the small millions, and also in Fig. 6d we cannot properly compare the year
humans were introduced with the year a ML technique was introduced.

Trajectories can also be compared over time, as shown in Fig. 6e. Here, time
is applied to the same entity, so we see how the entity (a population in this case)
changes with time. But a trajectory is better seen when the dimensions of the
plot are not time – time is not usually represented in a static map. Instead, one
can see how an individual or group moves in a space of dimensions chronologically
(learning episodes, cognitive decline or enhancement, etc.), illustrated in Fig. 6f.
Actual data can also be obtained and processed from subjective perception.
For instance, Gray et al. (2007) extract two principal components: agency and
experience (what we could also refer to as ‘patiency’) in order to quantify how
much mind people ascribe to diﬀerent kinds of cognitive systems, from robots
to dead people, as illustrated in Fig. 7.

Mapping Intelligence: Requirements and Possibilities

129

Fig. 6. A collection of existing empirically-grounded maps.

After all these graphical representations, the question is how these can help
us conﬁgure a set of relevant “maps” we would like the atlas to have. First,
we can look at the elements: many are multidimensional and it is just the

130

S. Bhatnagar et al.

Fig. 7. Diﬀerent cognitive systems according to the perception by people (from a sur-
vey, where the dimensions have been reduced to two dimensions by PCA). (Gray et al.
2007; Wegner and Gray 2017)

dimensions and the elements portrayed which make them really distinctive. This
is an advantage, as many of these plots could be generated with a standard tool
and interface if we had the data and we could choose the dimensions and ele-
ments. An interactive interface could be used as in other exploration tools (e.g.,
analytical processing or visualisation tools). Second, it is appropriate to look at
the purpose of each of these representations and see whether they correspond
to the needs and applications we identiﬁed in previous sections. For instance,
Figs. 1, 2, 3b, c, d, e, 4, 6b, c, e, and f are mostly explanatory or diﬀerential
in purpose, while Figs. 3a, d, f, 5, 6a and d seem to have a more forecasting
intention. Some have a broader coverage of kinds of intelligence (Figs. 3a, b, c,
4 and especially 7) and others are more speciﬁc.

4 Conclusions

This paper has presented the ﬁrst steps of an atlas of intelligence, which at
this stage must focus on the elicitation of needs (in terms of motivations and
requirements) and possibilities (applications, representations and kinds of enti-
ties covered). After this analysis, we now have a much better account of how
wide the initiative is. The next steps should focus on recognising the applica-
tions that might have more impact and are more feasible in the short term. This
assessment would allow us to establish the speciﬁcation of the atlas in a progres-
sive way, so that an essential part of it can be designed and enriched over time.
For such an ambitious approach, it is important to think big, as we have done
here, while starting small, and grow incrementally.

Apart from the instrumental purpose of this paper as a ﬁrst step in the devel-
opment of an atlas of intelligence, this work (independently of how far the atlas
develops in the future) brings attention to methodological issues (and related
philosophical and theoretical) issues in all disciplines related to intelligence and
cognition. Scientists in these disciplines usually see themselves as explorers, but
exploration involves much more than discovering and inventing. Scientists also

Mapping Intelligence: Requirements and Possibilities

131

need (to be) cartographers, curators and taxonomists in order to structure, facil-
itate and disseminate what is known, and assess their unknowns, prioritise their
goals and see their progress in perspective. In the same way Linnaeus changed
the way living beings were described, catalogued and named, motivating new
lines of research, this initiative will help to establish the parameters and the
instruments to properly handle and understand the space of existing and future
cognitive systems, and exploit its research possibilities.

Acknowledgements. The initiative was supported by the Leverhulme Trust via the
Leverhulme Centre for the Future of Intelligence. J. H-Orallo and F. M-Plumed were
supported by EU (FEDER) and the Spanish MINECO under grant TIN 2015-69175-
C4-1-R and by GVA under grant PROMETEOII/ 2015/013 and by the Air Force Oﬃce
of Scientiﬁc Research under award number FA9550-17-1-0287. J. H-Orallo also received
a Salvador de Madariaga grant (PRX17/00467) from the Spanish MECD for a research
stay at the CFI, Cambridge, and a BEST grant (BEST/2017/045) from the GVA for
another research stay also at the CFI. F. M-Plumed was also supported by INCIBE
(Ayudas para la excelencia de los equipos de investigaci´on avanzada en ciberseguridad ).
A. Weller acknowledges support from the David MacKay Newton research fellowship
at Darwin College, the Alan Turing Institute under EPSRC grant EP/N510129/1 &
TU/B/000074, and the Leverhulme Trust via the CFI.

A Appendix: Why is an atlas needed? Similar initiatives

While identifying the need for an atlas, we look at how it ﬁts in cognitive science
as a whole and also whether there are initiatives in other ﬁelds that could be
inspirational.

Regarding cognitive science, it is true that its goal is to cover all possible
cognitive systems, understand their behaviour and mechanisms, and establish
meaningful comparisons. However, the ﬁeld has not yet been able to portray
a systematic representation covering both natural and artiﬁcial systems. But if
we do not ﬁnd this systematic representation in cognitive science, do we ﬁnd
it in related subdisciplines? The answer is that some similar initiatives in other
disciplines do exist2:

– Life forms: Examples are Wikispecies (Leslie 2005), the All Species Founda-
tion (Gewin 2002), the Catalogue of Life and the Encyclopedia of Life (Roskov
et al. 2018; Hayles 1996; Parr et al. 2014; Stuart et al. 2010).

– Neuroscience: the Cognitive Atlas3 and related repositories for neuro-
science4 include an ontology of human cognitive functions and related tasks,
and the pathologies aﬀected. The Allen brain observatory5 (Allen Institute

2 Some of these initiatives are in genomics and brain imaging (Midford 2004; Boero

and Bernardi 2014).

3 http://www.cognitiveatlas.org.
4 https://poldracklab.stanford.edu/.
5 http://observatory.brain-map.org/visualcoding/.

132

S. Bhatnagar et al.

for Brain Science 2016) is a more visually-oriented platform that maps per-
ception and cognition to parts of the human brain (National Research Council
2011).

– Psychometrics: There are several initiatives bringing together test batter-
ies and repositories: the mental Measurement yearbook6, and with a more
open character, the International Personality Item Pool7 and the Interna-
tional Cognitive Ability Resource8.

– Machine learning and data science research: Kaggle9, OpenML10 (Van-
schoren et al. 2013) and many other platforms (e.g., gitxiv.com) provide
benchmarks for ML. OpenML also includes experimental results that can
be compared, aggregated and represented with powerful analytical packages.
– Artiﬁcial intelligence: there are many collections of benchmarks and asso-
ciated results, such as ALE11, OpenAI universe/gym12, Microsoft Malmo13,
Facebook’s CommAI-env14, DeepMind Lab 15 (see Hern´andez-Orallo et al.
2017 for a summary) and meta-views, such as a recent EFF analysis16 and
the AI index report17. This is a sign that AI is looking in this direction
(Castelvecchi 2016; Hern´andez-Orallo 2017). The tasks are rarely arranged
into abilities and the data usually compares specialised AI systems against
average humans.

A partially overlapping initiative is the AI Roadmap Institute18, which encour-
ages, compares and studies various AI and general AI roadmaps. It focuses on
the future and on AI primarily, with representations that are usually ﬂowcharts
and pathway comparisons. Besides identifying where the ﬁeld of AI stands as
a whole, it also aims to identify dead-ends and open research problems on the
path to the development of general AI systems.

The data and conceptual framing of the above projects can be used to inform
an atlas of intelligence. Still, no repositories or taxonomies exist focusing mostly
on behaviour, encompassing natural and artiﬁcial systems, as we are undertak-
ing. Of course, the fact that something does not exist yet is not a suﬃcient
reason that it should. The need for an atlas has to be supported by a series of
motivations and applications, which we do in Sect. 2.

6 http://buros.org/mental-measurements-yearbook.
7 http://ipip.ori.org.
8 http://icar-project.com.
9 http://www.kaggle.com.
10 http://www.openml.org.
11 http://www.arcadelearningenvironment.org/.
12 https://gym.openai.com/.
13 https://www.microsoft.com/en-us/research/project/project-malmo/.
14 https://research.fb.com/projects/commai/.
15 https://deepmind.com/blog/open-sourcing-deepmind-lab/.
16 http://www.eﬀ.org/ai/metrics.
17 http://aiindex.org.
18 http://www.roadmapinstitute.org.

Mapping Intelligence: Requirements and Possibilities

133

References

Aarts, A., Anderson, J., Anderson, C., Attridge, P., Attwood, A., Fedor, A.: Estimating

the reproducibility of psychological science. Science 349(6251), 1–8 (2015)

Allen Institute for Brain Science: Allen brain observatory (2016). http://observatory.

brain-map.org/visualcoding

Arsiwalla, X.D., Moulin-Frier, C., Herreros, I., Sanchez-Fibla, M., Verschure, P.: The

morphospace of consciousness. arXiv preprint arXiv:1705.11190 (2017)

Balakhonov, D., Rose, J.: Crows rival monkeys in cognitive capacity. Sci. Rep. 7(1),

8809 (2017)

Bhatnagar, S., et al.: A First Survey on an Atlas of Intelligence (2017). http://www.

dsic.upv.es/∼ﬂip/papers/Bhatnagar18 SurveyAtlas.pdf

Boero, F., Bernardi, G.: Phenotypic vs genotypic approaches to biodiversity, from con-

ict to alliance. Mar. Genomics 17, 63–64 (2014)

Brooks, R.A.: From earwigs to humans. Robot. Auton. Syst. 20(2–4), 291–304 (1997)
Cadman, E.: AI not just a game for DeepMind’s Demis Hassabis. Financial Times

(2014). https://www.ft.com/content/1c9d5410-8739

Castelvecchi, D.: Tech giants open virtual worlds to bevy of AI programs. Nature

540(7633), 323–324 (2016)

Cattell, R.B., Coulter, M.A.: Principles of behavioural taxonomy and the mathematical
basis of the taxonome computer program. Br. J. Math. Stat. Psychol. 19(2), 237–269
(1966)

Dennett, D.C.: Darwin’s dangerous idea. Sciences 35(3), 34–40 (1995)
de Valad´es, D.: Rhetorica christiana (1579)
Eckersley, P., Nasser, Y., et al.: EFF AI Progress Measurement Project (2017). https://

www.eﬀ.org/es/ai/metrics. Accessed 10 Jan 2017

Einav, L., Levin, J.: Economics in the age of big data. Science 346(6210), 1243089

(2014)

Frey, C.B., Osborne, M.A.: The future of employment: how susceptible are jobs to

computerisation? Technol. Forecast. Soc. Chang. 114, 254–280 (2017)

Gentner, D.: Psychology in cognitive science: 1978–2038. Top. Cogn. Sci. 2(3), 328–344

(2010)

Gewin, V.: Taxonomy: all living things, online. Nature 418(6896), 362–363 (2002)
Godfrey-Smith, P.: Towers and trees in cognitive evolution. In: Huebner, B. (ed.) The

Philosophy of Daniel Dennett (Chap. 8.1). Oxford University Press (2015)

Gray, H.M., Gray, K., Wegner, D.M.: Dimensions of mind perception. Science

315(5812), 619–619 (2007)

Hayles, N.K.: Narratives of artiﬁcial life. In: Future Natural: Nature, Science, Culture,

pp. 146–164. Routledge, London (1996)

Hern´andez-Orallo, J., et al.: A new AI evaluation cosmos: ready to play the game?
AI Mag. 38(3), 66–69 (2017). https://www.aaai.org/ojs/index.php/aimagazine/
article/view/2748

Hern´andez-Orallo, J.: The Measure of All Minds: Evaluating Natural and Artiﬁcial

Intelligence. Cambridge University Press, Cambridge (2017)

Herrmann, E., Call, J., Hern´andez-Lloreda, M.V., Hare, B., Tomasello, M.: Humans
have evolved specialized skills of social cognition: the cultural intelligence hypothesis.
Science 317(5843), 1360–1366 (2007)

Hessel, M., et al.: Rainbow: combining improvements in deep reinforcement learning.

arXiv preprint arXiv:1710.02298 (2017)

Kirsh, D.: Today the earwig, tomorrow man? Artif. Intell. 47(1–3), 161–184 (1991)

134

S. Bhatnagar et al.

Landhuis, E.: Neuroscience: big brain, big data. Nature 541(7638), 559–561 (2017)
Leslie, M.: Calling all taxonomists. Science 307(5712), 1021–1022 (2005)
Lowndes, J.S.S., Best, B.D., Scarborough, C., Aﬄerbach, J.C., Frazier, M.R., O’Hara,
C.C., Halpern, B.S.: Our path to better science in less time using open data science
tools. Nat. Ecol. Evol. 1, 0160 (2017)

Macphail, E.M.: The comparative psychology of intelligence. Behav. Brain Sci. 10(4),

645–656 (1987)

Marcus, G.: Deep learning: a critical appraisal. arXiv preprint arXiv:1801.00631 (2018)
Marx, V.: Biology: the big challenges of big data. Nature 498(7453), 255–260 (2013)
McKinlay, R.: Use or lose our navigation skills: automatic wayﬁnding is eroding natural

abilities, warns roger mckinlay. Nature 531(7596), 573–576 (2016)

Midford, P.E.: Ontologies for behavior. Bioinformatics 20(18), 3700–3701 (2004)
Miller, R.: Task taxonomy: science or technology? Ergonomics 10(2), 167–176 (1967)
Milner, G.: Pinpoint: How GPS is Changing Technology, Culture, and Our Minds. WW

Norton & Company (2016)

Moravec, H.: When will computer hardware match the human brain. J. Evol. Technol.

1(1), 10 (1998)

National Research Council: Toward Precision Medicine: Building a Knowledge Network
for Biomedical Research and a New Taxonomy of Disease. National Academies Press
(2011)

Ng, A.: What artiﬁcial intelligence can and can’t do right now. Harvard Business

Review, November 2016

Parr, C.S., et al.: The encyclopedia of life v2: Providing global access to knowledge

about life on earth, vol. 2 (2014). http://www.eol.org/

Pfeifer, R.: Embodied artiﬁcial intelligence 10 years back, 10 years forward. In: Infor-

matics, pp. 294–310 (2001)

Pinker, S.: The Language Instinct: How the Mind Creates Language. William Morrow

and Company (1994)

Roskov, Y., et al.: Species 2000 ITIS catalogue of

life. Aeon (2018). http://

catalogueoﬂife.org/col

Schaie, K.W.: Intellectual development in adulthood. In: Birren, J.E., Schaie, K.W.
(eds.) Handbook of the Psychology of Aging, vol. 4, pp. 266–286. Academic Press
Inc. (1996)

Shah, H., Warwick, K., Vallverd´u, J., Wu, D.: Can machines talk? Comparison of eliza

with modern dialogue systems. Comput. Hum. Behav. 58, 278–295 (2016)

Shanahan, M.: Conscious exotica. from algorithms to aliens, could humans ever under-
stand minds that are radically unlike our own? Aeon (2016). https://aeon.co/essays/
beyond-humans-what-other-kinds-of-minds-might-be-out-there

Shead, S.: Facebook’s AI boss: in terms of general intelligence, we’re not even close to
a rat. Business Insider (2017). http://uk.businessinsider.com/facebooks-ai-boss-in-
terms-of-general-intelligence-were-not-even-close-to-a-rat-2017-10

Silver, D., et al.: Mastering chess and shogi by self-play with a general reinforcement

learning algorithm. arXiv preprint arXiv:1712.01815 (2017)

Sloman, A.: The Structure and Space of Possible Minds. University of Sussex, School

of Cognitive Sciences (1984)

Sol´e, R.: Rise of the humanbot. arXiv preprint arXiv:1705.05935 (2017)
Sol´e, R.V., Macia, J.: Synthetic biocomputation: the possible and the actual. In: ECAL,

pp. 29–36 (2011)

Sparrow, B., Liu, J., Wegner, D.M.: Google eﬀects on memory: cognitive consequences

of having information at our ﬁngertips. Science, p. 1207745 (2011)

Mapping Intelligence: Requirements and Possibilities

135

Stuart, S., Wilson, E., McNeely, J., Mittermeier, R., Rodr´ıguez, J.: The barometer of

life. Science 328(5975), 177–177 (2010)

Tegmark, M.: Life 3.0: Being human in the age of artiﬁcial intelligence. Knopf (2017)
Thagard, P.: Why cognitive science needs philosophy and vice versa. Top. Cogn. Sci.

1(2), 237–254 (2009)

Vanschoren, J., et al.: Towards a data science collaboratory. Lecture Notes in Computer

Science (IDA 2015), vol. 9385 (2015)

Vanschoren, J., van Rijn, J.N., Bischl, B., Torgo, L.: OpenML: networked science in
machine learning. SIGKDD Explor. 15(2), 49–60 (2013). https://doi.org/10.1145/
2641190.2641198

Wegner, D.M., Gray, K.: The Mind Club: Who Thinks, What Feels, and Why It Mat-

ters. Penguin (2017)

Winﬁeld, A.F.: Estimating the energy cost of (artiﬁcial) evolution. In: Sayama, H.,
Rieﬀel, J., Risi, S., Doursat, R., Lipson, H. (eds.) Proceedings of 14th International
Conference on the Synthesis and Simulation of Living Systems (ALife), pp. 872–875.
MIT Press (2014)

Winﬁeld, A.F.: How intelligent

is your

intelligent

robot?

arXiv preprint

arXiv:1712.08878 (2017)

Yampolskiy, R.V.: The universe of minds. arXiv preprint arXiv:1410.0369 (2014)

Deep Learning, Deep Change
Mapping the development of the Artificial Intelligence General 
Purpose Technology

Joel Klinger, Juan Mateos-Garcia and Konstantinos Stathoulopoulos

SPRU Friday Seminar
16 November 2018

The news this week: more than Brexit

Artificial Intelligence is a powerful technology with widespread 

applicability… but is it a General Purpose Technology?

The global picture

Countries across the world are putting in place national strategies to 

develop their AI sectors… but what is its geography?

The local picture

Geographical proximity could help coordinate the development of 

complex AI technologies... What local factors matter?

Structure

1. Theory
2. Defining AI
3. Method and data
4. Findings

a. Is AI a GPT?
b. How is it geography changing?
c. What drives these changes?

5. Conclusions and next steps

Theory. General Purpose Technologies as engines of growth

Technologies ‘characterized by the 
potential for pervasive use in a wide 
range of sectors and by their 
technological dynamism’
[Bresnahan and Trajtenberg, 1995]
● Novelty
● Disruption
● Require complementary 

investments

● Generate externalities (risk of 

coordination failures)

Literature. Geography

GPT → change in drivers of advantage → New 
geographies of production and innovation 
[Rosenberg and Trajtenberg, 2004]

https://fineartamerica.com/featured/3-
corliss-steam-engine-1876-granger.html

GPT discontinuity → early product life-cycle → 
windows of opportunity
Followed by maturity and consolidation.
[Abernathy and Utterback, 1977, Anderson and Tushman 1990, Klepper, 1996, 
Scott and Storper 2003]

Literature. Relatedness

National (regional, local) economies 
develop by diversifying into related 
sectors / disciplines. 
[Delgado et al, 2018]
Co-location with relevant sectors 
could be important/necessary for 
complex GPTs that require 
coordination in deployment.
[Balland and Rigby, 2017]

https://phys.org/news/2007-08-nation-position-product-space-
economic.html

Defining AI. History

A long dream of 

machines that ‘think’

And a long journey of disappointing 

implementations

https://hackernoon.com/ai-in-medicine-a-beginners-guide-a3b34b1dd5d7

Defining AI. A modern approach

More data

More processing power

Software innovations

Deep learning

https://www.quora.com/How-do-I-learn-Neural-Network-by-myself

http://cdn.aiindex.org/2017-report.pdf

Defining AI. Policy questions

AI is being described as the latest GPT
[Cockburn et al, 2017, Agrawal et al, 2018]
But is it so? Brittle, narrow, opaque. Maybe not 
so general.
[Marcus, 2018]

A global race in AI is afoot with dozens of 
national strategies being launched. But what 
is their economic rationale?
[Stix, 2018, Goldfarb et al, 2018]

https://www.theatlantic.com/technology/archive/201
8/03/can-you-sue-a-robocar/556007/

http://lifeinvestasset.com/noticias/reporte-lifeinvest-
15-06-18/

Method and data. Research questions

Q2. Is its geography 
being transformed?

Geographical 

change

Q3. What is the role of 

regional 

complements?

GPT

Q1. Does AI behave 

like a GPT?

Driven by presence 

of complements

Method and data. Data pipeline

Filtering

Geocoding

Topic 

modelling

arXIv

CrunchBase

Q1

Deep Learning 

papers

Co-occurrence 

with DL

Semantic 

proximity to DL

Q2

Deep Learning 

clusters

Related research 

clusters

Related industry 

clusters

Q3

Method and data. arXiv

Popular pre-prints website in physics, engineering and computer science. 
1.3m papers. Very popular in the AI community

Method and data. arXiv processing

We fuzzy-match 
ArXiv with Microsoft 
Academic Graph to 
retrieve citations 
(for QA) and 
institutions (90% 
match rate)

arXIv

Filtering

Geocoding

Topic 

modelling

We measure cosine distance
between DL and other computer 
science sub-disciplines based on 
co-occurrence in papers 

We fuzzy-match institutions with Global Research Identifier 
(GRID) to extract institution locations. We then bin those into 
countries / regions using a point on polygon approach and 
Natural Earth shapefiles

We use CorEx, a topic modelling algorithm to identify 2 
topics related to Deep Learning. CorEX looks for clusters of 
words in the data that maximise correlations in the data

Deep Learning 

papers

Similarity with DL

Deep Learning 

clusters

Related research 

clusters

Method and data. Anchored correlation explanation (CorEX)

Identify topics in 
corpora of text. Looks for 
topics that maximally 
explains dependencies 
between words in 
documents. 
Does not require 
selection of k (number 
of topics) like LDA.
Can be seeded with 
anchor words
[Gallagher et al 2017]

Method and data. Computer science subject proximities with DL

Disciplines such as 
computer vision, 
learning, machine 
learning, neural 
nets and AI 
appear closer to 
DL

Method and data. arXiv content

We end with 130k unique papers and 250k paper-institution pairs. We identify 
15k papers as Deep learning.
This is what the data look like

Method and data. CrunchBase

Global startup-up directory with ~ 450,000 entries (257,000 organisations). 
Includes sectors and descriptions. Increasingly used in economics and 
management research.
[Dalle et al, 2017, Menon et al 2018]

CrunchBase

Semantic 

proximity to DL

Related industry 

clusters

Train a machine learning model 
on the CrunchBase data and 
out-of-sample predict to what 
sectors do arXiv papers relate.

Method and data. Sector relatedness with DL

Sectors such as data, 
AI, software, 
hardware, science 
and engineering, 
education and ICT 
are more 
semantically related 
to DL

Findings. Q1: Is DL a GPT?

Test 1: Dynamism
DL is rapidly gaining 
importance in 
absolute and 
relative terms in the 
arXiv corpus

Findings. Q1: Is DL a GPT?

Test 2: Generality

[We compare pre and post 2012 because 
2012 is generally considered a watershed 
moment for DL with the publication of 
Krizhevsky et al, 2012.]

DL is being 
increasingly applied 
in more computer 
science disciplines

Findings. Q1: Is DL a GPT?
Test 3: spin out impact. DL papers are over-represented in 
the high citation groups in most CS sub-disciplines.

Findings. Q2: How is the geography of DL evolving?

National specialisation
[Based on Revealed Comparative Indices, focusing on high activity 
places and higher quality papers]
Change is afoot. China, Singapore and Canada ascending, US 
keeps up, Europe (excepting Switzerland and UK) fall behind.

Findings. Q2: How is the geography of DL evolving?

Regional picture
We see some leading digital/creative/ 
defence clusters amongst the most DL 
specialised regions.

Findings. Q2: How is the geography of DL evolving?

Volatility and concentration
After an initial period of volatility (fat 
tailed distribution of specialisation), 
we see an apparent shake-up, 
increasing concentration in a small 
number of regions (nations).

Findings. Q3: What are the drivers of regional specialisation?

[All totals logged, all variables normalised, focusing on the top 
quartile of locations by arXiv activity]
Persistence +
Research specialisation ~
Industry specialisation ~
Complementarities ++
China ++

Findings. Q3: What are the drivers of regional specialisation?

Complementarities are more important for DL / other data CS disciplines.

Conclusions. Wrap up of findings

1. DL looks like a General Purpose Technology
■ Widespread exploration of opportunities

2. Evidence of discontinuity in its geography

■ But things seem to be settling down

3. Presence of relevant industries linked to DL cluster 

development.
■ Although also some evidence suggestive of 

unexpected spillovers

Conclusions. Policy implications

1. Further evidence of localised knowledge spillovers 

from AI research activity: might justify activist DL 
policies.

2. But is the window of opportunity for DL closed now?
3. DL spreading widely despite some concerns about its 

narrow / brittle nature. What is the role of R&I funders in 
diversifying the AI science/technology trajectory?
4. And what about getting DL applied in less related 

sectors (in missions)?

Conclusions. Limitations and next steps

1. Data caveats: Triangulate with other data (traditional 

publications, patents)

2. Causality:

a. Look for natural experiments / exogenous shocks
b. Explore mechanisms for research - industry 
complementarities (networks, labour flows?)

3. Directionality

a. Further analyse text descriptions to understand sub-
branches of modern DL research and their drivers.

Appendix. GitHub code and data

https://github.com/nestauk/arxiv_ai

nesta.org.uk

@nesta_uk

juan.mateos-garcia@nesta.org.uk

Geiger, R.Stuart (2019), ArXiV Archive, UC Berkeley Dash, ...

doi:10.6078/D1708G

ht t ps://o rc id. o rg /0 0 0 0 - 0 0 0 1 - 721 5 - 0 5 3 2
ht t ps://o rc id. o rg /0 0 0 0 - 0 0 0 1 - 721 5 - 0 5 3 2

ArXiV Archive

U C- Be rke l e y ,  ,  

Ge ig e r,  R. S t uart
Ge ig e r,  R. S t uart ,  ,   U C- Be rke l e y
sg e ig e r@ g mail . c o m
sg e ig e r@ g mail . c o m
Publication date: January 4, 2019
Publisher: UC Berkeley
https://doi.org/10.6078/D1708G

Citation

Geiger, R.Stuart (2019), ArXiV Archive, Dash, Dataset, https://doi.org/10.6078/D1708G

Abstract

This is a full archive of metadata about papers on arxiv.org from 1993-2018, including abstracts. Data is tidy and packed in TSV files, in two different
collections of the total dataset: per year (all categories) and per primary category (all years). This archive also includes Jupyter notebooks for unpacking
and analyzing it in python. See the README.md file and https://github.com/staeiou/arxiv_archive for more information.

Methods

St ep 0: Quer y f r om  ar x iv .or g
St ep 0: Quer y f r om  ar x iv .or g

Arxiv's main permitted means of bulk downloading article metadata is through its OAI-PMH API. I used the oai-harvest program to download this, which
stores the records in one XML file per paper, for a total of about 1.4 million files. These files are too large to be uploaded here.

St ep 1 : Pr oces s  X ML f il es
St ep 1 : Pr oces s  X ML f il es

In the Jupyter notebook 1-process-xml-files.ipynb, the individual XML files are processed into a single large Pandas DataFrame, which is stored in
TSV and pickle formats. These files are too large to be uploaded here.

St ep 2: Pr oces s  cat eg or ies  and out put  t o per _ year  and per _ cat eg or y T SV s
St ep 2: Pr oces s  cat eg or ies  and out put  t o per _ year  and per _ cat eg or y T SV s

In the Jupyter notebook 2-process-categories-out.ipynb, the large TSV file created in step 1 is parsed and separated into two different batched
outputs. The processed_data/per_year folder contains one TSV file per year, compressed in .zip format.
The processed_data/per_category contains one TSV file per Arxiv category, compressed in .xz format. Arxiv papers have primary and secondary
categories (posting and cross-posting), and papers are in a category's dataset if they were either posted or cross-posted to that category.

St ep 3 : Ex por t  r aw t it l es  and abs t r act s
St ep 3 : Ex por t  r aw t it l es  and abs t r act s

In the Jupyter notebook 3-abstracts-export.ipynb, the per_year datasets are unpacked and merged, then two sets of files are created for 1) just
abstracts and 2) just titles, with one title or abstract per line. This creates zipped files for all items (too large to upload on GitHub) and a random sample
of 250k items, which can be found in processed_data/DUMP_DATE/arxiv-abstracts-
250k.txt.zip and processed_data/DUMP_DATE/arxiv-titles-250k.txt.zip.

Usage Notes

Ex am pl e us ag e Jupyt er  not ebook
Ex am pl e us ag e Jupyt er  not ebook

In the Jupyter notebook 4-analysis-examples.ipynb, the per_year datasets are unpacked and merged to one large dataframe, which is then
analyzed in various ways. If you are looking to use this data to do an analysis on the entire Arxiv, you may find this notebook useful to start.

D at a dict ionar y f or  f ul l  m et adat a f il es
D at a dict ionar y f or  f ul l  m et adat a f il es

These files are
in processed_data/DUMP_DATE/per_year/YEAR.tsv.zip and processed_data/DUMP_DATE/per_category/CATEGORY_NAME.tsv.zip
with one row per line and tab-separated.

Text of the abstract, may include LaTeX formatting.

Definition
Definition

Variable
Variable

name
name

abstract
acm_class

UC Berkeley

Example
Example

We find the natural embedding of the (R+R^2)-
i...
 

Page 1 of 2

Geiger, R.Stuart (2019), ArXiV Archive, UC Berkeley Dash, ...

doi:10.6078/D1708G

Definition
Definition

ACM Classification (manually entered by authors, if exists)
Arxiv internal ID. Can get to PDF by appending "https://arxiv.org/pdf/" + arxiv_id + ".pdf"
Comma-separated list of authors
Comma-separated list of all categories the paper was submitted to (posted and cross-
posted)
Author comments
Date created (YYYY-MM-DD)
DOI (manually entered by authors, if exists)

Variable
Variable
arxiv_id
name
name
author_text
categories
comments
created
doi
num_authors Number of authors
num_categoriesNumber of categories
primary_cat
title
updated
created_ym
Funding

Primary category the paper was submitted to
Paper title, may include LaTeX
Date last updated (YYYY-MM-DD)
Year and month created

Example
Example

1011.0240
Sergei V. Ketov, Alexei A. Starobinsky
hep-th,astro-ph.CO,gr-qc
4 pages, revtex, no figures (very minor additi...
2010-10-31
10.1103/PhysRevD.83.063512
2
3
hep-th
Embedding (R+R^2)-Inflation into Supergravity
2011-02-28
2010-10

Alfred P. Sloan Foundation, Award: 2013-10-27

Gordon and Betty Moore Foundation, Award: GBMF3834

References

This dataset cites https://github.com/staeiou/arxiv_archive

Versions

January 4, 2019

Files

1 files for this dataset

arxiv_archive_20190101.zip

1.46 GB

application/zip

License

This work is licensed under a Creative Commons Attribution 4.0 International (CC BY 4.0) license.

This license lets others distribute, modify, and build upon your work, even commercially, as long as they credit you for the original
creation.

UC Berkeley

Page 2 of 2

8
1
0
2

 

g
u
A
0
2

 

 
 
]

Y
C
.
s
c
[
 
 

1
v
5
5
3
6
0

.

8
0
8
1
:
v
i
X
r
a

Deep learning, deep change? Mapping the development of

the Artiﬁcial Intelligence General Purpose Technology

J. Klinger, J. Mateos-Garcia, and K. Stathoulopoulos

Nesta, 58 Victoria Embankment, London, EC4Y 0DS, United Kingdom

Abstract

General Purpose Technologies (GPTs) that can be applied in many industries are an im-
portant driver of economic growth and national and regional competitiveness.
In spite of
this, the geography of their development and diﬀusion has not received signiﬁcant attention
in the literature. We address this with an analysis of Deep Learning (DL), a core technique
in Artiﬁcial Intelligence (AI) increasingly being recognized as the latest GPT. We identify DL
papers in a novel dataset from ArXiv, a popular preprints website, and use CrunchBase, a
technology business directory to measure industrial capabilities related to it. After showing
that DL conforms with the deﬁnition of a GPT, having experienced rapid growth and diﬀusion
into new ﬁelds where it has generated an impact, we describe changes in its geography. Our
analysis shows China’s rise in AI rankings and relative decline in several European countries.
We also ﬁnd that initial volatility in the geography of DL has been followed by consolidation,
suggesting that the window of opportunity for new entrants might be closing down as new DL
research hubs become dominant. Finally, we study the regional drivers of DL clustering. We
ﬁnd that competitive DL clusters tend to be based in regions combining research and indus-
trial activities related to it. This could be because GPT developers and adopters located close
to each other can collaborate and share knowledge more easily, thus overcoming coordination
failures in GPT deployment. Our analysis also reveals a Chinese comparative advantage in
DL after we control for other explanatory factors, perhaps underscoring the importance of ac-
cess to data and supportive policies for the successful development of this complex, ‘omni-use’
technology.

Contents
1 Introduction

1.1 General Purpose Technologies as engines of growth . . . . . . . . . . . . . . . . . .
1.2 Towards a geography of GPTs . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
1.3 Empirical setting: Artiﬁcial Intelligence and Deep Learning . . . . . . . . . . . . .

2 Data collection and classiﬁcation

2.1

Identifying and mapping DL papers in arXiv data . . . . . . . . . . . . . . . . . .
2.1.1
arXiv . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
2.1.2 Microsoft Academic Graph (MAG) . . . . . . . . . . . . . . . . . . . . . . . .
2.1.3 Global Research Identiﬁer Database (GRID) . . . . . . . . . . . . . . . . . .
2.1.4 Topic modeling . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
2.1.5 Research relatedness . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
. . . . . . . . . . . . . . . . . . . . . . . . . . . . .
2.2.1
CrunchBase . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
2.2.2 Research-industry relatedness . . . . . . . . . . . . . . . . . . . . . . . . . .

2.2 Building the industrial dataset

3 Analysis

3.1.1
3.1.2

3.1 Descriptives . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
arXiv . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
CrunchBase data . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
3.2 GPT aspects of DL research in arXiv . . . . . . . . . . . . . . . . . . . . . . . . .
3.2.1 Rapid growth . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

1

2
3
3
4

5
5
6
6
6
7
8
8
8
8

9
9
9
11
13
13

3.2.2 Generality . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
3.3
Impact in other ﬁelds
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
3.4 Evolution in the Geography of DL research . . . . . . . . . . . . . . . . . . . . . .
3.5 Drivers of DL cluster emergence
. . . . . . . . . . . . . . . . . . . . . . . . . . . .

4 Conclusion

4.1 Discussion and implications . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
4.2 Limitations and issues for further research . . . . . . . . . . . . . . . . . . . . . . .

13
13
16
18

22
22
23

1

Introduction

What do the steam engine, the electric motor and the microprocessor have in common? They are
all powerful General Purpose Technologies (GPTs) that can be applied in multiple sectors creating
waves of change that ripple across the economy [1]. It is not a coincidence that economic eras
are often named after their ‘core’ GPTs: the Steam Age, the Age of Electricity, the Information
Revolution and today, a ‘Second Machine Age’ driven by advances in Artiﬁcial Intelligence (AI)
[2, 3].
The emergence of a GPT can also change the economic fortunes of nations and regions: it is hard
to disentangle Britain’s ascendancy from the steam engine, or the USA’s from electriﬁcation and
the combustion engine. The arrival of microelectronics and the Internet shifted economic power
from the East Coast of the US to Silicon Valley in the West. Today, the rhetoric of an AI ‘global
race’ implies that those countries that develop strong AI industries will be able to dominate more
markets and industries. Governments across the world are responding with national strategies to
grow their AI sectors [4] .
But where do GPTs such as AI appear and why, and how do they transform geographies of
innovation and production? We still lack good answers to these questions. Although economic
geographers and regional scientists have studied disruptive GPT-like innovations that create new
opportunities for countries and regions, they rarely consider their links with the rest of the economy
[5, 6]. Yet it is precisely this connectivity that deﬁnes GPTs, and could also explain where they
emerge, and their geographical impact [7].
In this paper we seek to address this gap in the literature with an analysis of the geography of
Deep Learning (DL) research, one of the technologies driving recent advances in AI systems that
are increasingly being recognized as the latest GPT [8, 9, 10]. We consider how the geography
of DL has evolved since its emergence in the early 2010s, and study its link with local research
and industrial capabilities. Our analysis draws on the literature on technological discontinuities
and a recent body of research on economic complexity and related diversity that looks at how the
industrial and knowledge composition of regions and countries drive their diversiﬁcation into new
products and technologies [11, 12]. In doing this, we provide new evidence about the geography of
AI research, a question of great interest for policymakers.
Our analysis draws on a novel combination of data sources and methods: we obtain our principal
dataset from arXiv, a preprints site widely used by scientists and engineers, and identify DL papers
in its computer science section with CorEX, an information theory algorithm that can detect clusters
of related words in corpora of text. We also use data from CrunchBase, a technology business
directory, to identify and map industries that are related to DL and might spur its development.
Our data analysis pipeline illustrates the opportunities that novel data science methods create for
the analysis of emerging technologies such as DL.1
The rest of this section reviews relevant literatures in economics, economic geography and AI.
Section 2 describes how we collected and enriched the data and classiﬁed papers from arXiv
computer science corpus into the DL category. Section 3 presents our ﬁndings in three steps.
First, we consider whether DL displays three deﬁning features of a GPT (rapid growth, rapid
diﬀusion into new ﬁelds, and impact in new ﬁelds). Second, we study the geographical aspects of
its diﬀusion. Third, we model the link between regional specialization in DL research and activity

1The code we have used in our analysis is available for review in https://github.com/nestauk/arxiv_ai.

2

in related knowledge and industrial bases. Section 4 discusses the ﬁndings and its limitations, and
outlines issues for further research.

1.1 General Purpose Technologies as engines of growth

GPTs are technologies or clusters of related technologies ‘characterized by the potential for per-
vasive use in a wide range of sectors and by their technological dynamism’ [1, 13]. They enable
productivity improvements in multiple industries by automating or greatly improving the eﬃciency
of key production tasks such as the use of energy for work, or the transfer and processing of infor-
mation. The steam engine replaced human, animal and natural motor power in mining, textiles
and transport [3]. Electricity cheaply illuminated homes and workplaces, and the combustion
engine detached energy from a ﬁxed grid, making production and transport more ﬂexible [14].
Micro-electronics transformed the speed and scale of computation across the economy.
If we imagine the technology system as a network of ideas being constantly recombined, then we
will ﬁnd GPTs sitting near its center [15]. GPTs induce cascades of complementary innovations
in the sectors that deploy them, some of which may also be widely applicable. For example,
Information and Communication Technologies (ICTs) based on cheap microchips gave birth to the
video-games industry, which subsequently spurred the development of Graphical Processing Units
(GPUs) now used for parallel processing of information in other sectors. This exploration of new
GPT opportunities requires trial-and-error and can take time. For example, US factories did not
start to realize the beneﬁts of electric power until they reorganized their layout to harness the
ﬂexibility of small electric motors, decades after the introduction of electricity [14].
The networked nature of GPTs creates the risk of coordination failures in its deployment: rapid
change makes their evolution hard to predict, and might encourage a ‘wait-and-see’ strategy among
potential adopters and providers of complementary skills, infrastructures and standards. This
can hinder the exploration of the new opportunities the GPT oﬀers, and delay or halt follow-on
innovations [16].

1.2 Towards a geography of GPTs

When they arrive, GPTs transform the economic conditions and production processes of many
industries. Consider for example the changes brought about by the advent of steam to textiles
and transport in Britain, or more recently, the impact of the Internet in media or retail. Since
industries tend to cluster in speciﬁc locations to access dense talent pools, reduce transaction costs
and learn from each other, the impact of GPTs will also be unequally distributed in space [17].
If a GPT is ‘competence-destroying’ for an industry (that is, if it eliminates previous sources of
comparative advantage like the Internet did with control over physical distribution channels in the
music industry), then those locations where the industry concentrates will experience a negative
shock. At the same time, a GPT can create windows of opportunity to enter a sector, like the
Internet did with new media clusters.
Economic geographers have studied similar discontinuities through the lens of the product life-
cycle. The idea is that the technologies used by an industry follow a trajectory with distinct
phases, and that each of these phases has a diﬀerent geography. Early in the life-cycle, when a
new market or technological opportunity is revealed, there is a phase of experimentation when
entrepreneurs explore diﬀerent designs to harness this opportunity [18, 19]2. In this phase of the
product life-cycle, there is uncertainty about the technologies and capabilities required to succeed
in the market, lowering barriers to entry for new entrepreneurs and regions [21]. Eventually,
this experimentation yields a standard or dominant design and the industry moves from product
to process innovation. Economies of scale become more important, leading to industrial and
geographical consolidation.3 We would expect something similar to happen when a GPT arrives,
2(the beginning of the automobile industry is a paradigmatic example of this phase, with inventors and en-
trepreneurs exploring in parallel various energy sources for the automobile, from the combustion engine to electrical
and steam-powered motors, [20])

3At the same time, there might be some dislocation of activity as standardized parts of the production process

are outsourced or oﬀ-shored to other locations with cheaper costs.

3

with an initial phase of geographical volatility when new entrants come into the market, followed
by a shake-out and increasing concentration once a dominant design is established.
What factors determine whether a region is able to enter and successfully compete in the devel-
opment of the GPT in the ﬁrst place? A growing body of literature on Economic Complexity
and Economic Relatedness suggests that a region’s ability to enter a new market or technology
depends on the presence of related capabilities that can be re-purposed or recombined to explore
new opportunities. This is referred to as the Principle of Relatedness [11, 12, 20, 22]. Building
on this idea, GPTs that can be applied in multiple industries could beneﬁt from the co-location of
R&D sectors that develop the technology and industrial sectors where it can be applied. Proximity
between developers, adopters and suppliers of skills and infrastructure facilitates communication
and reduces the risk of coordination failures, improving the prospects for GPT deployment and
helping the location gain a comparative advantage in the technology [23].

1.3 Empirical setting: Artiﬁcial Intelligence and Deep Learning

Having discussed the concept of GPTs, we now turn our attention to the empirical setting for our
analysis: Artiﬁcial Intelligence, and more speciﬁcally the Deep Learning techniques underpinning
it.
Artiﬁcial Intelligence (AI) systems have been deﬁned as ‘self-training structures of Machine Learn-
ing predictors that automate and accelerate human tasks’ [24]. In turn Machine Learning (ML) is
‘the ﬁeld that thinks about how to automatically build robust predictions from complex data’ [24].
ML emerged in the 1970s in response to the failure of rule-based approaches where human experts
hard-coded knowledge in Artiﬁcial Intelligence systems [25]. ML’s approach is to instead develop
algorithms that can recognize patterns in labeled data with less need for human intervention, and
use the resulting models to make predictions about new observations. Economic analyses of AI
focus on its ability to reduce the costs of prediction, an important task in many industries [26].
Deep Learning (DL) is a new ML technique that processes large and complex datasets it through
networks of synthetic neurons where subsequent layers learn increasingly abstract representations
of the data that eventually become an input into prediction [27]. Although the neural network
literature goes back to the 1950s, this approach only became feasible in recent years thanks to the
availability of large, labeled datasets from the web, and powerful GPUs. Since the early 2010s,
Deep Learning has been proven to be ‘unreasonably eﬀective’ in many applications, from image
and video recognition to translation and gaming, fueling a surge of interest and investment in AI
[28].
Ultimately, AI researchers strive for generality: developing algorithms that can transfer their
predictive prowess across domains, and respond eﬀectively to new situations. Sustained progress
towards that goal has led a growing number of economists to declare DL-driven AI a new GPT that
will revolutionize the economy [2]. DL also represents an ‘invention in the methods of invention’
that could transform how new ideas are discovered, improving productivity of R&D in ﬁelds such
as drug discovery, genomics or material sciences [9, 29]. Publication, patenting and venture capital
trends support this view, with rapid growth in DL activity and diﬀusion into other disciplines and
industries [9].
The GPT nature of AI would also explain stagnant productivity growth despite rapid technological
progress: businesses still need to reorganize their operations [2], the education system needs to
address skills shortages, and suitable digital and regulatory infrastructures have to be developed
to create value from AI-driven growth.
What about the geography if AI? A recent review of its international trade aspects argues that
the localized nature of AI knowledge spillovers (the fact that organizations need to be based in
the locations where investments on R&D take place to beneﬁt from them) could justify national
policies to support its development [30]. Governments across the world appear to share this view,
and many have announced national strategies to compete in the ‘AI global race’. There is a growing
belief that China, with its large STEM workforce, powerful Internet platforms and vast amounts of
data is ‘winning’ this race [31]. Meanwhile, European researchers and policymakers fear that the
EU falling behind for lack of talent and leading AI-driven businesses [32]. These perceptions imply

4

that AI GPT is disrupting the geography of digital production and innovation. As AI researcher
Andrew Ng points out ‘Since AI changes the foundation of many technology systems - everything
ranging from web search to autonomous driving to customer service chatbots - it also gives many
countries the opportunity to ‘leapfrog’ the incumbents in some application areas’ [33]. In the rest of
this paper, we monitor these geographical changes and study their drivers using a novel preprints
dataset and state-of-the-art Natural Language Processing (NLP) methods.

2 Data collection and classiﬁcation

Our analysis relies on several data sources and preprocessing activities:

1. We combine data from arXiv, GRID (Global Research Identiﬁer) and MAG (Microsoft Academic
Graph) to create a geocoded dataset of research activity in computer science disciplines
where we identify DL papers with CorEx, a topic modeling algorithm. We also measure the
relatedness between computer science subjects based on their co-occurrence in arXiv papers.
2. We use CrunchBase, a business directory, to map industrial activities that might be relevant
for the development of DL clusters. We measure relatedness between those industries and DL
using a machine learning model that predicts industrial sectors with company descriptions.

We go through these two streams of data collection and classiﬁcation in turn.

2.1

Identifying and mapping DL papers in arXiv data

We generate the DL dataset for our analysis by matching three non-proprietary open data sources;
arXiv, Microsoft Academic Graph (MAG), and the Global Research Identiﬁer Database (GRID).
The data sources are matched in the following order, according to the procedure described in
Sections 3.1.1- 2.1.3:

{arXiv matched to

−−−−−−−→ MAG} matched to

−−−−−−−→ GRID

By following this pipeline of data collection, we create a dataset with the features described in
Table 1 for further processing as described in Section 2.1.4.

Data source Comments

Feature
Article title

Article abstract text

Subject classiﬁcation
Is article published?

Publication date

Citation count

arXiv

arXiv

arXiv

MAG

MAG

MAG

Assured to be consistent with MAG title
after matching procedure.
To be used for topic modeling (Sec-
tion 2.1.4).
Assigned by the author.
Always true, as implicitly assured by
match to MAG.
Publication date in MAG, rather than
arXiv submission date.
Used for cross-check by selecting ’high
quality’ publications (Section 3).
This replaces the potentially incom-
plete set of authors from arXiv.

Institute aﬃliation (all authors)

MAG

Institute location

GRID

Table 1: Features extracted in the data collection procedure.

5

2.1.1 arXiv

arXiv is a ‘real-time’ open archive of academic preprints widely used by researchers in quantitative,
physical and computational science ﬁelds. Data from each of over 1.3 million papers can be accessed
programmatically via the arXiv API. As arXiv papers are self-registered, we ensure that papers
are not simply ‘junk’ articles by requiring that all papers are matched to a journal publication or
conference proceeding, as presented in Section 2.1.2. We also have anecdotal evidence that the
archive contains many high quality papers, since a short study of conference proceeding from the
prestigious AI Conference on Neural Information Processing Systems in 2017 reveals that over 55%
of these were published on arXiv.
Is arXiv a suitable data source for the analysis of industrial R&D? We believe that this is the
case. The AI research community has a strong culture of openness in its publication of research
ﬁndings, software and benchmark datasets, which are perceived as a way to attract scientiﬁc talent
[34]. Some of the most active DL institutions in our corpus include corporations such as Google,
Microsoft, IBM, Baidu or Huawei.
From the initial set of over 1.3 million papers, approximately 134,000 have been selected for anal-
ysis as they fall under the broad category of ‘Computer Science’ (cs) or the speciﬁc category of
‘Statistics - Machine Learning’ (stat.ML).

2.1.2 Microsoft Academic Graph (MAG)

Microsoft Academic Graph (MAG) is an open API oﬀering access to 140 million academic papers
and documents compiled by Microsoft and available as part of its ‘Cognitive Services’. For the
purpose of this paper, MAG helps to ensure that article retrieved from arXiv have been published
in a journal or conference proceeding, as well as providing citation counts, publication date and
author aﬃliations. The matching of the arXiv dataset described in Section 3.1.1 is performed in
two steps.
We begin by matching the publication title from arXiv to the MAG database. The database can
be queried by paper title, although fuzzy-matching4 or near-matches are not possible with this
service. Furthermore, since paper titles in MAG have been preprocessed, one is required to apply a
similar preprocessing prior to querying the MAG database. There is no public formula for achieving
this, so we explicitly describe the following steps to emulate the MAG preprocessing:

1. Identify any ‘foreign’ characters (for example, Greek or accented letters) as non-symbolic;
2. Replace all symbolic characters with spaces; and
3. Ensure no more than one space separates characters.

This procedure leads to a match rate of 90%, for the set of arXiv articles used in this paper. We
speculate that papers could be missing for several reasons: the titles on arXiv could signiﬁcantly
diﬀerent from those on MAG; the latter procedure may be insuﬃcient for some titles; the arXiv
paper may not be published in a journal; and MAG may not otherwise contain the publication. It
may be possible to recuperate some of these papers, however this is currently not a limiting factor
in our analysis.

2.1.3 Global Research Identiﬁer Database (GRID)

We use the Global Research Identiﬁer Database (GRID) to enrich the dataset with geographical
information, speciﬁcally a latitude and longitude coordinate for each aﬃliation that we can then
geocode into countries and regions.5. The GRID data is particularly useful since it provides institute
names and aliases (for example, the institute name in foreign languages). Each institute name from
MAG is matched to the comprehensive list from GRID as follows:

4‘Fuzzy-matching’ refers to the process of ﬁnding a likely match for a set of text (such as a word or sentence)
amongst a choice of texts. A naive example would be comparing the ratio of the number of characters between
texts, and identifying the texts with the highest ratio as a match.

5We do this with a point-in-polygon approach using boundary (shapeﬁle) data from the Natural Earth public

map dataset.

6

1. If there is an exact match amongst the institute names or aliases, then extract the coordinates

of this match. Assign a ‘score’ of 1 to this match (see step 3. for the deﬁnition of ‘score’).

2. Otherwise, check whether a match has previously been found. If so, extract the coordinates

and score of this previous match.

3. Otherwise, ﬁnd the GRID institute name with the highest matching score, by convoluting the

scores from various fuzzy-matching algorithms in the following manner:

(cid:118)(cid:117)(cid:117)(cid:116) N(cid:88)

n=0

1√
N

Fn(mMAG, MGRID)2

(1)

where N is the number of fuzzy-matching algorithms to use, Fn returns a fuzzy-matching
score (in the range 0 → 1) from the nth algorithm, mMAG is the name from MAG to be matched
and MGRID is the comprehensive list of institutes in the GRID data.

The form of Equation 1 ensures that eﬀect of a single poor fuzzy-matching score is to vastly reduce
the preference for a given match. Therefore, good matches are deﬁned according to Equation 1 as
having multiple good fuzzy-matching scores, as measured according to diﬀerent algorithms. We use
a prepackaged set of fuzzy-matching algorithms implementing the Levenshtein Distance metric [35],
and speciﬁcally, two algorithms applying a token-sort-ratio and a partial-ratio respectively.
After this stage of data matching, we are left with approximately 240,000 unique institute-publication
matches with at least one computer science subject in their arXiv categories.

2.1.4 Topic modeling

We analyze the abstracts in our corpus using Natural Language Processing to identify papers
related to DL. This involves tokenizing the text of the abstracts and removing common stop-
words, very rare words and punctuation. We lemmatize the tokens based on their part-of-speech
tag, and create bi-grams and tri-grams. Documents with less than twenty tokens are removed from
the sample. After these steps, there are over 168,000 features (unique ‘words’) in the dataset.
There are diﬀerent approaches to identify DL papers in this preprocessed corpus. Previous work
has used a keyword-search approach based on a predeﬁned vocabulary of terms [9]. Here, we
follow an alternative topic modeling strategy which identiﬁes clusters of words in the data without
an initial vocabulary, and provides a score for each topic in a document, simplifying the labeling
process.
More speciﬁcally, we use the Correlation Explanation (CorEx [36]) algorithm, which takes an
information-theoretic approach to generate n combinations of features in the data which maximally
describe correlations in the dataset. Using a one-hot bag-of-words representation, we optimally
ﬁnd n = 28 topics by tuning n with respect to the ‘total correlation’ variable, as advised by the
CorEx authors. The generated topics contain words which are sorted in terms of their contribution
of each feature to total correlation. We assign a score Sj for each topic j (containing N j words wi
with topic weights T j

i ) to each document W such that:

Sj =

where:

T j
i δ(wi, W )

δ(wi, W ) =

1 if wi ∈ W
0 otherwise

N j(cid:88)
(cid:40)

i=0

Topics are then assigned to each document only if the following condition is satisﬁed:

Sj ≥ γ T j

max

7

(2)

(3)

(4)

where γ is a threshold parameter that we assign below, and T j
max is the maximum topic weight.
The form of the above asserts that documents must contain a suﬃcient number of components
of topics to be assigned to the topic. Clearly, a larger choice of γ leads to a lower frequency of
documents assigned to the topic whilst improving the overall recall.
After inspecting the model outputs, we identify two topics related to DL, containing keywords
such as neural_network, deep_learning, or convolutional_neural_networks. We label as
‘Deep Learning’ those papers where either of these topics is present with a γ above 0.5, giving us
a set of 15,062 DL papers (11% of the total unique papers).6.

2.1.5 Research relatedness

In Section 3.5, we study the link between DL specialization in a region and the presence of related
research and industrial activities. We proxy research relevance using the relatedness between
research subjects based on their co-occurrence in arXiv papers.7 To measure this relatedness, we
calculate the cosine similarity between vectors representing the subjects that appear in diﬀerent
papers in the corpus. Sub-section 3.1 presents the results.

2.2 Building the industrial dataset

2.2.1 CrunchBase

We use CrunchBase, a commercial directory of technology companies, to measure industrial activity
in a region. The version of CrunchBase we use contains information about 257,000 organizations,
including a short description of their activities, the sectors where they operate, the year when they
were founded and their geographical coordinates.8
Recent analyses of technology clusters in CrunchBase suggest that it correlates well with other
measures of regional technological activity, and it is increasingly being used in economics and
management research [37, 38]. CrunchBase presents two important advantages for our analysis:
ﬁrst, it has global coverage (like our arXiv corpus) and individual organization locations, so it
is easy to merge with our arXiv data at a suitable geographical level. Second, it contains text
descriptions of company activities and labels for the sectors where they operate, which we can use
to generate measures of similarity between these sectors and DL papers in the arXiv data using
the strategy we describe below.

2.2.2 Research-industry relatedness

We estimate the relatedness between industrial activities in CrunchBase and research in arXiv
by training a supervised machine learning model that predicts the sector where a company in
CrunchBase operates based on its description9.
This model is then used for out-of-sample prediction of the CrunchBase categories of arXiv pa-
pers, based on the text in their abstract. Speciﬁcally, we assign categories where the prediction
probability is at least 0.99.10 We then calculate the share of papers by arXiv subject predicted to
be in a CrunchBase category to measure their relatedness. Subsection 3.1 presents the results.

6We also create a more restrictive DL category containing only those papers either topic is present with a γ
above 0.5, resulting in a total of 1,604 papers. A visual inspection of a random sample of papers in both groups
suggests that their outputs are similarly relevant so we opt to focus on the larger set. This is further motivated by
our interest in understanding the diﬀusion of DL methods in various computer subjects.

7Researchers who submit their papers to arXiv label them with a set of relevant research categories. We focus

our analysis in Computer Science (cs) subjects as well as those in the stat.ML subject.

8As before, we geocode CrunchBase companies using a point-in-polygon approach with boundaries from Natural

9We focus on those observations with the longest and more informative descriptions, comprising around 115,000
companies. We perform a grid-search to select the best performing model, a logistic regression classiﬁer with L1
regularization.

10By setting a high threshold for classiﬁcation of arXiv papers into CrunchBase categories we seek to remove noise

in the transference of the model across corpora with potential diﬀerences in their languages.

Earth.

8

3 Analysis

3.1 Descriptives

3.1.1 arXiv

Table 2 presents some descriptive statistics for papers classiﬁed as DL and the rest of the corpus.
DL papers have, on average, been published more recently, they tend to contain fewer arXiv
subjects, and involve collaborations with a somewhat higher number of institutions. They also
tend to receive more citations , specially after we control for the number of years since publication.
This suggests that DL is a relatively recent topic, and that DL papers are, on average, more
inﬂuential than the rest.

dl_cat

dl

non_dl

total
year_average
ﬁeld_average
institute_average
citation_average
citation_p_year_average

15602
2015.937
2.798
1.754
25.627
6.182

115587
2013.572
2.930
1.705
18.003
2.505

Table 2: Descriptive statistics for DL / non-DL papers in arXiv
dataset

Figures 1, 2 and 3 present the distribution of DL and non-DL activity over arXiv computer science
subjects, countries and regions for the top categories in each variable.

Figure 1: Distribution of DL/non DL papers by arXiv category

Some observations:

1. DL papers are highly concentrated in a small number of arXiv subjects: Computer Vision
(cs.CV), Computer Learning (cs.LG), Machine Learning (stat.ML), Artiﬁcial Intelligence (
cs.AI) and Neural Networks (cs.NE). The set of DL-intensive subjects includes some that
rely on unstructured datasets where DL has achieved important breakthroughs, and in ﬁelds
that specialize in the development of ML and AI methods.

2. The US has the biggest share of DL and non-DL papers, with around a third of all publications
in both categories. China is overrepresented in DL: its share of DL papers is more than double

9

cs.CVcs.LGstat.MLcs.AIcs.CLcs.NEcs.ITcs.IRcs.ROcs.DCcs.CRcs.SIcs.DScs.NIcs.DBcs.SDcs.MMcs.SEcs.SYcs.HC010203040% of papers  in categoryCategorydlnon_dlFigure 2: Distribution of DL/non DL papers by country (top 20 coun-
tries)

Figure 3: Distribution of DL/non DL papers by region (top 35 regions)

its share of non-DL papers. By contrast, France is underrepresented in DL.

3. North American regions dominate the global rankings of DL activity. California, Mas-
sachusetts, New York, Maryland, Illinois and Texas rank highly by volume of DL activity.
Ontario and Quebec in Canada also have high levels of activity, consistent with Canada’s
strong research base on AI. Beijing, the South West Development Corporation in Singapore,
Maryland and Quebec are over-represented in DL, with substantially higher shares of activity
in DL than in the rest of the corpus). Notably, only one EU region (Bavaria) appears in the
top ten of global DL research in arXiv.

Figure 4 displays a heatmap of the proximities between diﬀerent arXiv subjects (as well as the DL
category) based on their co-occurrence on papers, sorted by their proximity to the DL category.
Consistent with Figure 1, DL papers are closer to computer science subjects involving unstructured

10

United States of AmericaChinaUnited KingdomGermanyCanadaFranceAustraliaItalySwitzerlandSingaporeSpainIndiaNetherlandsJapanIsraelAustriaSouth KoreaSwedenBrazilBelgium0102030Percentage of papers in countrydl_catdlnon_dlCaliforniaBeijingMassachusettsNew YorkSWCDC SingaporeMarylandOntarioBavariaIllinoisTexasQuebecNew JerseyCanton of ZÃ¼richParisNew South WalesPennsylvaniaOxfordshireShanghaiWashingtonBaden-WÃ¼rttembergYvelinesTokyoLondon Borough of CamdenMichiganNorth Carolina02468Percentage of papers  in regiondl_catdlnon_dldata and subjects that research ML, AI and neural networks. These subjects also tend to to co-
occur with each other, forming a ‘cluster’ of data analytics research in arXiv. Our analysis also
reveals intuitive connections between other arXiv subjects such as Computers and Society (cs.CY)
and Human Computer Interaction (cs.HC) or between Logic (cs.LO) and Programming Languages
(cs.PL), supporting the idea that these proximities are a meaningful measure of relatedness between
computer science subjects in arXiv.

Figure 4: Proximities between arXiv subjects based on co-occurrence
in papers

3.1.2 CrunchBase data

Figure 5 presents the regional distribution of activity in CrunchBase. California is again the
top region by number of organizations. Technology company activity in CrunchBase is more
concentrated than research in arXiv (California accounted for 15% of all activity in CrunchBase,
while it only captured 7% of the activity in arXiv). US States and Indian regions have a stronger
presence here than they did in arXiv. Chinese provinces are, by contrast, less visible.
Figure 6 compares levels of activity in arXiv and CrunchBase. Although there is a strong corre-
lation between both datasets (ρ=0.67), we note some divergences. For example, there are several
UK counties around London with a strong presence in CrunchBase but low activity in arXiv.
Conversely, some Japanese prefectures display high levels of arXiv activity but few organizations
in CrunchBase11.
We end our descriptive analysis by considering the proximity between arXiv categories (includ-
ing DL) and CrunchBase sectors based on the machine learning analysis outlined in 2.2.1. The
heatmap in 7 presents the share of all papers in an arXiv subject (and DL) that were labeled in
a CrunchBase category. It shows that DL papers were classiﬁed more often in Data Analytics,
Artiﬁcial Intelligences and Software CrunchBase sectors. We also detect intuitive relations between
other arXiv categories and CrunchBase sectors: for example, Robotics (cs.RO) is related to Sci-
ence and Engineering, Sound (cs.SO) is related to Music and Audio, and Cryptography (cs.CR)
is related to Privacy and Security.
It is however worth noting that some of the similarities we

11These results underscore the importance of triangulating our results against other data sources in future research.

11

dlcs.CVcs.LGstat.MLcs.CLcs.NEcs.AIcs.IRcs.SDcs.ROcs.MMcs.DCcs.CRcs.DBcs.SIcs.DScs.ITcs.GRcs.NIcs.HCcs.NAcs.SEcs.ARcs.ETcs.SYcs.CEcs.PLcs.CYcs.PFcs.MScs.LOcs.MAcs.CGcs.OHcs.GTcs.DLcs.DMcs.SCcs.OScs.CCcs.FLcs.GLdlcs.CVcs.LGstat.MLcs.CLcs.NEcs.AIcs.IRcs.SDcs.ROcs.MMcs.DCcs.CRcs.DBcs.SIcs.DScs.ITcs.GRcs.NIcs.HCcs.NAcs.SEcs.ARcs.ETcs.SYcs.CEcs.PLcs.CYcs.PFcs.MScs.LOcs.MAcs.CGcs.OHcs.GTcs.DLcs.DMcs.SCcs.OScs.CCcs.FLcs.GL0.00.20.40.60.81.0Figure 5: Share of CrunchBase activity by region

Figure 6: Relationship between arXiv and CrunchBase activity
(logged)

12

CaliforniaNew YorkTexasCity of WestminsterMassachusettsIllinoisFloridaWashingtonOntarioPennsylvaniaColoradoNew JerseyVirginiaGeorgiaMaharashtraParisNorth CarolinaKarnatakaOhioNew South WalesBritish ColumbiaArizonaMichiganDelhiMarylandMinnesotaOregonSWCDC SingaporeCounty DublinTennesseeConnecticutBerlinVictoriaQuebecUtah0.02.55.07.510.012.515.0% of all companies  in CrunchBase0246810arxiv_log0246810cb_logidentify could be linguistic rather than semantic (for example, our model detects a strong similar-
ity between Game Theory - cs.GT and Gaming, which could be partly explained by their use of
similar language rather than a shared knowledge base).

3.2 GPT aspects of DL research in arXiv

We now move into our ﬁrst question: Is DL a GPT? In answering this, we seek to ensure that
our interpretation of further results is valid, and contribute to the literature on the GPT nature
of AI using a new dataset and classiﬁcation method [9]. Previous analyses of patent data in [13]
have looked for GPTs using patent class growth and citations, while more recently, [9] measure
growth in DL publishing and patenting with a keyword-based approach. They also consider levels
of publishing in application ﬁelds outside of Computer Science to measure the generality of DL12.
Our analysis builds on all this work.
Inspired by the original deﬁnition of a GPT, we have devised the following three GPT tests for
DL:

3.2.1 Rapid growth

The ﬁrst component of the deﬁnition of a GPT is ‘technological dynamism’, which we measure,
like [9], by looking at growth in activity. If DL is a GPT with broad applicability, we should see
an increase in the number of DL papers in arXiv as more researchers explore its potential.
Figure 8 presents the evolution of DL and non-DL publishing in arXiv. It shows that arXiv is
becoming an increasingly popular venue for computer science research, and that DL is gaining
relative importance in it. The share of DL papers in the total has grown ﬁvefold, from 3% before
2012, to 15% afterwards 13.

3.2.2 Generality

The second GPT test for a technology is rapid diﬀusion in new ﬁelds:
is DL being adopted in
multiple domains or restricted to a small number of areas? To assess this, we measure the number
of DL papers in diﬀerent arXiv subjects 14.
Figure 9 presents the results. The top panel displays yearly changes in the shares of DL by arXiv
subject (based on 3 year moving averages), and the bottom panel compares shares of DL activity
in a category before and after 2012, focusing on the top 35 computer science subjects in arXiv by
total levels of activity.
DL also fulﬁlls the second GPT test, with a visible upward trend in the relative importance of
DL in many computer science subjects, specially since 2012, the year of publication for [39], a
landmark paper in the use of DL in computer vision. Further, the bottom panel of 9, shows that
virtually all computer science subjects in our corpus have experienced an increase in the relative
importance of DL research since 2012. As before, this is particularly visible in subjects that use
unstructured data (e.g. Computer Vision) or specialize in the development of AI and ML methods
(Neural Networks, Computer Learning etc.) [27].

3.3

Impact in other ﬁelds

The third GPT test is impact in new ﬁelds: does DL generate follow-on innovations in the ﬁelds
that adopt it? Following convention, we use citations as a proxy for that impact.

12It is interesting to note that they classify computer vision papers and patents outside of DL. This contrasts with
our ﬁnding that Computer Vision is one of the main application areas for DL, underscoring the value of unsupervised
approaches for the analysis of fast moving technology ﬁelds.

13The results are similar if we focus on the most highly cited papers every year.
14As mentioned, most papers are labeled with multiple arXiv subjects. We allocate a paper to a subject if it

appears in it at least once.

13

Figure 7: Proximity between arXiv disciplines and CrunchBase sectors

Figure 8: Publication activity in arXiv (2008-2012)

14

Data and AnalyticsArtificial IntelligenceSoftwareHardwareScience and EngineeringEducationInformation TechnologyConsumer ElectronicsMedia and EntertainmentBiotechnologyPrivacy and SecurityContent and PublishingHealth CareInternet ServicesVideoNavigation and MappingEnergyDesignReal EstateSustainabilityManufacturingClothing and ApparelMobileMessaging and TelecommunicationsMusic and AudioGovernment and MilitaryProfessional ServicesTransportationNatural ResourcesGamingAppsEventsSportsPlatformsSales and MarketingCommunity and LifestyleConsumer GoodsAdministrative ServicesFinancial ServicesAdvertisingCommerce and ShoppingAgriculture and FarmingTravel and TourismFood and BeveragePaymentsLending and Investmentsdlcs.CVcs.LGstat.MLcs.CLcs.NEcs.AIcs.IRcs.SDcs.ROcs.MMcs.DCcs.CRcs.DBcs.SIcs.DScs.ITcs.GRcs.NIcs.HCcs.NAcs.SEcs.ARcs.ETcs.SYcs.CEcs.PLcs.CYcs.PFcs.MScs.LOcs.MAcs.CGcs.OHcs.GTcs.DLcs.DMcs.SCcs.OScs.CCcs.FLcs.GL0.000.040.080.120.160.2005000100001500020000Papers in arXivis_dldlnot_dl20052006200720082009201020112012201320142015201620172018020406080100Papers in arXiv   (% of total)Figure 9: DL as a share of activity in diﬀerent arXiv subjects. Top
panel shows yearly trends for all subjects in the arXiv data. Bottom
panel compares shares of DL activity in a subject before and after 2012.

Figure 10 compares the shares of DL papers in a arXiv subjects with their share of highly cited
papers in that same subject over diﬀerent periods 15. In all cases, most arXiv subjects are above
the diagonal (this is, DL papers are overrepresented among the highly cited ones in the subject).
This pattern becomes more apparent over time, supporting the idea that DL is becoming more
inﬂuential in the ﬁelds where it is applied.

Figure 10: DL papers as a share of all papers in an arXiv category,
and as a share of all highly cited papers for papers published after 2009
(left panel), 2012 (center panel) and 2015 (right panel).

Together, these results support the idea that DL is a GPT: its levels of activity are growing rapidly,
it is spreading into more ﬁelds, and it is generating an impact (or at least attracting attention, in
terms of the number of citations it receives) in the ﬁelds where it is applied.

15Highly cited papers are those in the top citation quartile for each year.

15

200820102012201420162018year01020304050DL as % of all papers  in each categorycs.DMcs.CCcs.FLcs.GTcs.DLcs.CGcs.SCcs.LOcs.ITcs.SYcs.CYcs.NIcs.MAcs.DScs.OHcs.OScs.CEcs.SIcs.SEcs.GLcs.MScs.PFcs.HCcs.NAcs.ETcs.CRcs.DCcs.DBcs.ARcs.GRcs.ROcs.AIcs.IRcs.MMstat.MLcs.SDcs.CLcs.LGcs.NEcs.CV010203040DL as % of all papers  in each categoryBefore 2012After 20120102030405060Share of all papers0102030405060Share of all  highly cited paperscs.FLcs.CVcs.DScs.MScs.ROcs.GRcs.HCcs.SCcs.OHcs.SIcs.AIcs.SEcs.CGcs.SDcs.NIcs.LOcs.IRcs.DBcs.SYcs.ITcs.ETcs.LGcs.CYstat.MLcs.DLcs.GTcs.MMcs.NAcs.CRcs.CCcs.CLcs.MAcs.DMcs.DCcs.NEcs.CEcs.ARcs.PFcs.OSPublished after 20090102030405060Share of all paperscs.FLcs.CVcs.DScs.MScs.ROcs.GRcs.HCcs.SCcs.OHcs.SIcs.AIcs.SEcs.CGcs.SDcs.NIcs.LOcs.IRcs.DBcs.SYcs.ITcs.ETcs.LGcs.CYstat.MLcs.DLcs.GTcs.MMcs.NAcs.CRcs.CCcs.CLcs.MAcs.DMcs.DCcs.NEcs.CEcs.ARcs.PFcs.OSPublished after 20120102030405060Share of all paperscs.FLcs.CVcs.DScs.MScs.ROcs.GRcs.HCcs.SCcs.SIcs.AIcs.SEcs.CGcs.SDcs.NIcs.LOcs.IRcs.DBcs.SYcs.ITcs.ETcs.LGcs.CYstat.MLcs.DLcs.GTcs.MMcs.NAcs.CRcs.CCcs.CLcs.MAcs.DMcs.DCcs.NEcs.ARcs.PFPublished after 20153.4 Evolution in the Geography of DL research

We now turn to the analysis of the geography of DL research, considering whether its evolution
follows the cycle of volatility and consolidation we would expect based on the literatures reviewed
in Section 1.2. To do this, we analyze changes in national and regional DL specialization using
relative comparative advantage (RCA) indices. We deﬁne the RCAdl of a location (country or
region) i as:

RCAdl,i =

(

(

Adl,i
Ac,i
Adl,n
Ac,n

)

)

(5)

Where Adl,i and Ac,i are the research activity of the location in DL and in all arXiv categories,
and Adl,n and Ac,n are the totals of DL activity and activity in all arXiv categories in all locations.
A RCAdl,i above 1 implies that the country is relatively specialized in DL, while the opposite is
true if the RCAdl,i is below 1. RCAs allow us to measure changes in DL research while controlling
for rapid growth in computer science activity, and for diﬀerences in size between locations. Since
RCAs tend to lose robustness in observations with low levels of activity, we focus our analysis on
the larger countries and regions. We also remove low quality papers from the data by focusing on
those above the median of citations for the year when they were published.
Figure 11 presents DL specialization by country after 2012 (map in the right panel) and changes in
DL specialization since 2012 for the most active countries. It shows that China has the strongest
comparative advantage in DL R&D. Interestingly, this has not changed signiﬁcantly since 2012,
suggesting that the development of advanced AI capabilities in China predate the recent explosion
of interest in DL. We also see rapid growth in the specialization of other Asian countries such
as Singapore and Korea. By contrast, all European countries in the chart with the exception of
the United Kingdom and France have become less competitive in DL research (and France has, in
any case, low levels of specialization in the DL). Canada and the US have also increased their DL
specialization since 2012.
These changes are consistent with the idea of volatility in the early stages of GPT development,
with some countries climbing up in the research rankings rapidly while others fall behind. It is
also interesting to note, qualitatively, that the trends we observe echo popular narratives about the
current state of the ‘AI race’, with China in the ascendant while European countries fall behind in
relative terms. After an initial slow response to the emergence of DL, the US is catching up [9].
Figure 12 presents similar ﬁgures but this time focusing on regions. The map shows high levels of
activity in a small number of regions in the East and West coast of the US, Canada, China and
East Asia, Central Europe, France, Britain and Adelaide in Australia (which hosts the Australian
Institute for Machine Learning Research). The right-hand panel shows US states such as Mary-
land, California and New York becoming more specialized in DL since 2012. Perhaps the most
notable change is in Oxfordshire in the UK, which has multiplied its RCAdl more than seven-fold
since 2012. Interestingly, we see that most of the largest regions in DL activity have also gained
specialization in DL, suggesting potential advantages to scale in developing a DL research cluster.
One potential explanation we explore in 3.5 is that these larger regions have suﬃcient scale to host
the combination of research and industrial capabilities required to develop the DL GPT.
We conclude by considering changes in the dispersion and concentration of DL activity since 2009.
Does the geography of DL research follow the cycle of volatility and consolidation we expect from
the product life-cycle literature?
Figure 13 shows the recent evolution in volatility and concentration of DL activity in the largest
nations and regions, focusing again on highly cited papers.
The patterns in the violin-plots in the top panel are consistent with the idea that DL experienced an
initial phase of volatility (high dispersion and a ﬂatter distribution in RCAs) followed by growing
stability (less dispersion and a normal distribution with fewer locations displaying high RCAs).
Also in line with what we expected, the bottom panels show a sudden decline in the shares of
activity accounted for by the top countries / regions around 2012, followed by an increase in

16

Figure 11: The map in the left panel shows RCAdl by nation for papers
published after 2012, focusing on papers above the median of citations
in their publication year, and countries in the top 90 percentile for total
level of activity. The ﬁgure in the right panel compares changes in RCAdl
between the period before 2012 and afterwards, focusing on the top 20
countries by total level of DL activity.

Figure 12: The map in the left panel shows RCAdl by region for papers
published after 2012, focusing on papers above the median of citations for
papers in their publication year, and region in the top 99 percentile for
total level of DL activity. The ﬁgure in the right panel compares changes
in RCAdl between the period before 2012 and afterwards, focusing on the
top 20 regions by total level of DL activity.

concentration afterwards. Having said this, the pattern of dis-location in DL is also present in
the broader arXiv corpus, suggesting that changes in concentration could be inﬂuenced by other
factors, such as growing use of arXiv or lower barriers to entry at the beginning of the period, with
open resources such as arXiv allowing more locations to participate in computer science research.
These are all interesting questions to explore in further work.
Our analysis also shows that DL research is more geographically concentrated than computer

17

Deep Learning specialisation after 2012Location quotient0.00 - 0.000.00 - 0.710.71 - 0.920.92 - 1.351.35 - 1.73ChinaHong KongSingaporeSwitzerlandCanadaAustraliaSouth KoreaUnited States of AmericaUnited KingdomBrazilGermanyItalySpainNetherlandsAustriaFranceIsraelJapanSwedenIndia0.60.81.01.21.41.61.8Relative comparative advantageChanges in specialisation before / after 2012pre_2012post_2012Figure 13: The top panel shows the evolution in the dispersion of
RCAdl by country between 2009 and 2017 only considering papers above
the citation median for the year, and the top 50 countries by level of
activity in arXiv. The bottom panel shows the percentage of highly cited
papers that concentrate in the top 10 countries

science overall. One potential explanation is that DL research is more complex, requiring proximity
for successful collaboration ([40] ﬁnd something similar in their analysis of complex technologies
using patent data). This is what we would expect in a GPT that relies on coordination between
developers and adopters. We focus on that interaction for the remainder of this section.

3.5 Drivers of DL cluster emergence

After showing that DL behaves like a GPT in its growth, diﬀusion, impact and geography, we turn
to the analysis of the local drivers associated with its development. As we said, GPTs beneﬁt from
coordination between developers and adopters: developers aware of market needs can customize
and promote their technologies to new industries. Adopters aware of GPT opportunities can
ﬁnd new ways to apply these technologies to their own situation. We would expect this mutual
awareness to be higher when developers and adopters are close to each other, making it easier to
collaborate, network and share knowledge. This means that regions where developer and adopter

18

02468101214RCA200920102011201220132014201520162017year50.052.555.057.560.062.565.067.570.0% of activity  in top 10 countriesDeep LearningAllFigure 14: The top panel shows the evolution in the dispersion of
RCAdl by region between 2009 and 2017 only considering papers above
the citation median for the year, and the top 150 regions by level of
activity in arXiv. The bottom panel shows the percentage of highly cited
papers that concentrate in the top 30 regions

sectors co-locate should be more competitive in the development of a GPT.
We test this hypothesis with the following model speciﬁcation:

RCAdl,t1 =β0 + β1RCAdl,t0 + β2arXivsp + β3CrunchBasesp+

β4arXivspCrunchBasesp + β5arxivsp ∗ CrunchBasetot+
β6arXivtot + β7 × is_China + 

(6)

In it, we estimate the link between DL specialization after 2012 (RCAdl,t1) and the presence
of related research and industrial capabilities (arXivsp and CrunchBasesp) and their interaction
(arXivsp × CrunchBasesp) before 2012, capturing the idea of GPT complementarities between
research and industry.16 We also include an interaction between relevant research capabilities and
16The measures of related activity weight levels of regional specialization in research subjects and industrial

activities by the DL similarity vectors described in 2 and 3.1.

19

02468101214RCA200920102011201220132014201520162017year303540455055606570% of activity  in top 30 regionsDeep LearningAlltotal CrunchBase activity (arXivsp×CrunchBasetot) to capture the beneﬁts from deploying a GPT
in industries less directly related to it.
We control for the levels of specialization in DL before 2012, total arXiv activity, and a dummy
for whether a region is Chinese or not (is_China). We take the logarithm of all totals, calculate
z-scores for all variables and focus our analysis on regions in the highest level of arXiv activity
(i.e. the top quartile) to reduce noise in the RCAs and remove a long tail of regions with little or
no DL activity.17
The correlation matrix in Figure 15 shows an association between DLt1 and several independent
variables and controls, including China. The correlation between between arxivsp and CrunchBasesp
is low, suggesting that locations with high specialization in research subjects relevant for DL do not
always specialize in relevant industries. Strong correlations between some independent variables
suggest the presence of multicolinearity 18.
Table 3 presents the results of our regression analysis with diﬀerent speciﬁcations. Model 4 is the
speciﬁcation in 6. We review some key results:

1. There is a robust link between a region’s specialization in DL before 2012 and afterwards.
This suggests that the volatility in the geography of DL we described above is not absolute,
with some DL specialization persisting over time.

2. There is a signiﬁcant link between the interactions of arXivsp with CrunchBasesp and with
CrunchBasetot, and DLt1. This supports the hypothesis that GPT development beneﬁts from
the co-location of developers and adopters. Interestingly, once we consider this complemen-
tarity, the link between related research activity and a region’s comparative advantage in
DL loses signiﬁcance. This suggests that the presence of relevant industries is an important
ingredient in the development of a DL cluster.

3. The link between the is_China dummy and the development of a DL cluster after 2012 is
strong and signiﬁcant after we control for other explanatory factors such as regional research
and industrial levels of activity. Together with the low R2 of our models, this suggests that
we our model is missing important national and regional factors that play a role in the
development of DL clusters such as access to skills and data, infrastructure, regulation and
supportive policies [41]. We plan to bring them into the analysis in future work.

We conclude by comparing model outputs for DL with other computer science subjects using
the same speciﬁcation (while focusing in the relevant research and industrial activities for each
subject). One could think of these other subjects as quasi-controls allowing us to explore whether
the patterns we detect in DL are also present in other ﬁelds, or DL is unique in some way. Through
this, we also attempt to control for other trends which could be driving our results, such as secular
changes in the usage of arXiv.
The results in Figure 16 shows that, in general, the interactions between arXiv and CrunchBase
activity that we have detected in DL are not pervasive amongst other DL subjects. Interestingly,
complementarities between research and industry are more important for data-related subjects
such as Computer Vision, Computer Learning, Machine Learning or Computer Learning. Other
subjects such as Data Structures (cs.DS), Network architecture (cs.NI), Social and Information
Networks or Logic (cs.LO) seem less reliant on these complementarities, perhaps because they
are more mature (reducing the need for coordination between developers and adopters).19 It is
also worth noting that DL and Computer Vision are the main subjects with a strong and positive
association between the is_China dummy and subject specialization, suggesting that China has
speciﬁc endowments that facilitate the development of these subjects, such as large unstructured
datasets and targeted policies .20

17Our results are robust to changes in these thresholds
18During our robustness tests we have removed some of these interaction terms without signiﬁcant changes in the

results.

19The exception to this, Information Theory (cs.IT) appears to be a catch-all subject present in almost 20% of

the computer science arXiv corpus

20This result will also be driven by the overlaps between DL and Computer Vision outlined in 3.2

20

Figure 15: Correlation matrix between key variables in our model. All
variables have been normalized.

Model 1 Model 2 Model 3 Model 4

y
RCAt0

arXivsp

CrunchBasesp

arXivsp×CrunchBasesp

arXivsp×CrunchBasetot

arXivtot

is_China

R2
n

0.121***
(0.044)
0.156***
(0.044)
0.023
(0.044)

0.124***
(0.044)
-0.012
(0.084)
-0.162*
(0.09)
0.261**
(0.111)

RCA_t1 RCA_t1 RCA_t1 RCA_t1
0.126***
0.12***
(0.044)
(0.043)
0.006
0.155***
(0.084)
(0.044)
-0.135
(0.09)
0.229**
(0.111)
0.207**
(0.08)
-0.083
(0.081)
1.586***
(0.212)
0.165
451

0.092**
(0.044)
1.549***
(0.212)
0.154
451

0.086*
(0.044)
1.545***
(0.213)
0.146
451

0.09**
(0.044)
1.54***
(0.213)
0.147
451

Table 3: Dependent variable is RCAdl,t1. Standard errors in brackets
are clustered by country. *** p<0.01, ** p<0.05, * p<0.10.

21

RCA_t1RCA_t0arXiv_spCrunchBase_sparXiv_sp*CrunchBase_sparXiv_sp*CrunchBase_totarXiv_totis_chinaRCA_t1RCA_t0arXiv_spCrunchBase_sparXiv_sp*CrunchBase_sparXiv_sp*CrunchBase_totarXiv_totis_china10.160.150.00140.130.120.0840.340.1610.024-0.052-0.0340.0240.0440.110.150.0241-0.0740.59-0.052-0.080.00570.0014-0.052-0.07410.660.10.14-0.0510.13-0.0340.590.6610.0450.026-0.0370.120.024-0.0520.10.04510.84-0.0360.0840.044-0.080.140.0260.8410.00310.340.110.0057-0.051-0.037-0.0360.003110.00.20.40.60.81.0Figure 16: Regression coeﬃcients and conﬁdence intervals for models
using the speciﬁcation in 6 in arXiv subjects with the highest levels of
activity

4 Conclusion

4.1 Discussion and implications

We have studied the geography DL, a new paradigm for AI. Our analysis of arXiv, a popular
preprints website used by researchers in academia and industry supports the idea that DL has the
features of a GPT technology: it has experienced rapid growth and is being applied in an increasing
number of computer science subjects where it generates high-impact work (which we proxy with
citations). This conﬁrms the conclusions of previous studies such as [9], and also suggests that in
spite of recent criticisms of the DL paradigm, and in particular the lack of robustness stemming
from its reliance on large datasets for training [42]), researchers in multiple domains of computer
science who are perhaps less likely to be swayed by hype than policymakers and entrepreneurs, are
applying it in ways that their peers ﬁnd interesting and useful.
If DL is a GPT, what are the geographical dimensions of its development? Our review of the
literature suggested that the emergence of a GPT might involve an initial shift in the geography of
research as new ‘entrants’ come into the scene, followed by consolidation as central hubs of activity
emerge. Our analysis at the national and regional level support this idea: we see international
shifts in activity since 2012, when DL started to gain visibility, followed by growing geographical
concentration. We also note that DL is at all points more geographically concentrated than com-
puter science research, lending support to the hypothesis in [30] that knowledge spillovers in AI
research are localized, justifying national and sub-national policies to support its development.
This higher geographical concentration also suggests that DL researchers beneﬁt from co-location.
We have further studied this idea with a model that estimates the link between co-location of
relevant research and industrial capabilities and DL development. The results of the analysis,
considering DL on its own and comparing it with other computer science subjects, supports the
idea that the co-location of researchers able to develop a GPT and adopters who can explore its
application favors the development of stronger DL research clusters. This result is also present
in other data analytics subjects, highlighting the link between AI and broader trends towards
‘dataﬁcation’ in the economy and society [43].
In terms of policy, our ﬁndings suggest that the attention that DL is attracting from national
and regional policymakers is warranted by its GPT nature and evidence of localized knowledge
spillovewrs. What is less clear is the extent to which the ‘window of opportunity’ to enter the
ﬁeld remains open given the growing concentration of DL research activity that we identify. Our
ﬁndings also echo the public narrative about the emergence of China as a global AI leader (together
with the USA, Canada and Asian countries such as Singapore and Korea and, perhaps to a lesser
extent, the UK), while EU countries lag behind.

22

dlcs.ITcs.LGcs.CVstat.MLcs.AIcs.DScs.NIcs.SIcs.CLcs.LO1.00.50.00.51.01.52.02.53.0Categoryarx_spsp_intabs_intis_chinaOur analysis of the drivers of DL cluster development support the idea that co-location and col-
laboration in dense ecosystems of research and industrial activity oﬀers a fertile ground for the
development of GPTs that rely on new combinations of ideas from various ﬁelds and applicable in
multiple sectors. Proximity between researchers and businesses could address some of the coordina-
tion failures between GPT developers and adopters identiﬁed in the literature [1]. One important
challenge for policymakers is how to enhance these complementarities without exacerbating regional
inequalities. While a geographical diversity of needs could justify dispersing research geographi-
cally so as to explore DL opportunities in a wider set of industrial and social contexts, this might
weaken agglomeration economies and knowledge spillovers derived from clustering. New, detailed
and timely sources of data such as those we use in this analysis can help understand and balance
these trade-oﬀs.

4.2 Limitations and issues for further research

Our use of arXiv data raises some concerns. To begin with, this is a platform with low barriers to
entry, so many of the papers there might be of low quality. We have tried to address this problem
by matching the arXiv data with MAG, and focusing key parts of our analysis on highly cited,
hopefully higher quality papers. Future work should expand and further validate our conclusions
in other data sources such as patents or open source projects.
Second, to which extent does our research data capture changes in technology development and
business diﬀusion? Throughout our analysis we have assumed that the clustering of DL research is a
good proxy for DL R&D development activities with an industrial application. Although anecdotal
evidence suggests high level of industry participation in arXiv, and we ﬁnd a strong correlation
between the levels of activity in arXiv and CrunchBase, there is risk of biases if diﬀerent research
communities, sectors or countries display variation in their propensity to publish their work in
arXiv. Further triangulation of arXiv data with other sources, including peer-reviewed research
in comparable disciplines, as well as industry patenting and the ﬁnancial performance of companies
in DL-related sectors, would help to address these concerns.
Third, there is the issue of causality. While our analysis has a longitudinal dimension, and quali-
tatively controls for unobservables by comparing DL model estimates with other computer science
subjects, we cannot rule out that other local factors such as access to skills and ﬁnance or a
supportive policy environment might be underpinning the links between research and industrial
activity and DL research clustering that we have detected. Going forward, we would like to incor-
porate in our analysis shocks to industrial activity with an exogenous element, such as regulatory
changes, or industrial policy interventions so as to identify more precisely the causal eﬀects of
research/industry co-location in DL cluster development.
There are many interesting directions to extend our work:
First, our analysis says little about the mechanisms behind the link between research / industry co-
location and DL cluster development: are these links driven by knowledge spillovers, the formation
of a technical talent pool that researchers and industry both tap on, or access to ﬁnance (e.g.
adopters fund development activities in regional research institutions)? A better understanding of
those mechanisms would help to address the issues of causality above, and yield policy-relevant
implications about what programs to put in place to strengthen DL clusters.
Second (and relatedly), our analysis takes a siloed view of DL research clusters, only considering
geographical proximity to other DL researchers and technology businesses as a source of valuable
knowledge about new techniques and business applications.
In reality, researchers access this
knowledge through many other channels and further aﬁeld, including via popular international
collaborations such as NIPS. Going forward, we will address this by studying the network of co-
authorships and citations in our data, and trying to understand the role of international conferences
in the dissemination of knowledge in DL. This analysis could reveal cross-country ﬂows of ideas
and collaborations going against the narrative of a zero-sum global AI race dominating popular
debates.
Third and last, we have not considered in detail the technological characteristics of the DL ‘dom-
inant design’: what are its features and components, and how stable are they? What are the

23

parallel paths for DL that have been explored and set aside? Should some of them be maintained
to avoid a premature lock-in to suboptimal standards for the large-scale deployment of the AI GPT
[44]? As we mentioned before, some researchers have expressed concerns about the lack of robust-
ness and interpretability in DL systems, calling for their combination with older paradigms for AI
development. New techniques and methods are being developed in response to this. Identifying
what they are, and overlaying their geography with the geography of DL explored in this paper
could yield a richer understanding of the diversity of evolutionary paths for emerging technologies,
and their spatial dimensions. Rich text data from papers could be marshaled for this, using the
same NLP approach we followed in this paper.
All these ideas highlight the analytical and policy opportunities for using new data sources for the
analysis of emerging technologies, and turning AI-related methods and tools towards the analysis
of AI itself.

References

[1] Timothy F Bresnahan and Manuel Trajtenberg. General purpose technologies ‘engines of

growth’? Journal of econometrics, 65(1):83–108, 1995.

[2] Erik Brynjolfsson, Daniel Rock, and Chad Syverson. Artiﬁcial intelligence and the mod-
ern productivity paradox: A clash of expectations and statistics. In Economics of Artiﬁcial
Intelligence. University of Chicago Press, 2017.

[3] Joel Mokyr et al. The gifts of Athena: Historical origins of the knowledge economy. Princeton

University Press, 2002.

[4] Stephen Cave and Seán SOhÉigeartaigh. An ai race for strategic advantage: Rhetoric and

risks. In AAAI/ACM Conference on Artiﬁcial Intelligence, Ethics and Society, 2018.

[5] David B Audretsch and Maryann P Feldman. Innovative clusters and the industry life cycle.

Review of industrial organization, 11(2):253–273, 1996.

[6] Allen Scott and Michael Storper. Regions, globalization, development. Regional studies, 37(6-

7):579–593, 2003.

[7] Timothy Bresnahan and Pai-Ling Yin. Reallocating innovative resources around growth bot-

tlenecks. Industrial and Corporate Change, 19(5):1589–1627, 2010.

[8] Ajay K Agrawal, Joshua S Gans, and Avi Goldfarb. Economic Policy for Artiﬁcial Intelligence.

Working Paper 24690, National Bureau of Economic Research, June 2018.

[9] Iain M Cockburn, Rebecca Henderson, and Scott Stern. The impact of artiﬁcial intelligence

on innovation. Technical report, National Bureau of Economic Research, 2018.

[10] Jason Furman and Robert Seamans. Ai and the economy. Technical report, National Bureau

of Economic Research, 2018.

[11] César A Hidalgo and Ricardo Hausmann. The building blocks of economic complexity. Pro-

ceedings of the national academy of sciences, 106(26):10570–10575, 2009.

[12] Koen Frenken, Frank Van Oort, and Thijs Verburg. Related variety, unrelated variety and

regional economic growth. Regional studies, 41(5):685–697, 2007.

[13] Bronwyn H Hall and Manuel Trajtenberg. Uncovering gpts with patent data. Technical report,

National Bureau of Economic Research, 2004.

[14] Paul A David. The dynamo and the computer: an historical perspective on the modern

productivity paradox. The American Economic Review, 80(2):355–361, 1990.

[15] W Brian Arthur. The nature of technology: What it is and how it evolves. Simon and Schuster,

2009.

[16] Elhanan Helpman and Manuel Trajtenberg. A time to sow and a time to reap: Growth based
on general purpose technologies. Working Paper 4854, National Bureau of Economic Research,
September 1994.

24

[17] Michael E Porter. Clusters and the new economics of competition, volume 76. Harvard Business

Review Boston, 1998.

[18] P. Anderson and M. L. Tushman. Technological discontinuities and dominant designs: A
cyclical model of technological change. Administrative science quarterly, pages 604–633, 1990.
[19] W. J. Abernathy and J. M. Utterback. Patterns of industrial innovation. Technology review,

80(7):40–47, 1978.

[20] Steven Klepper. Entry, exit, growth, and innovation over the product life cycle. The American

economic review, pages 562–583, 1996.

[21] A. Scott and M. Storper. Regions, globalization, development. Regional studies, 37(6–7):579–

593, 2003.

[22] Mercedes Delgado, Maryann Feldman, Koen Frenken, Edward Glaeser, Canfei He, Dieter F
Kogler10, Andrea Morrison, Frank Neﬀke11, David Rigby12, Scott Stern, et al. The prin-
ciple of relatedness. In Unifying Themes in Complex Systems IX: Proceedings of the Ninth
International Conference on Complex Systems, page 451. Springer, 2018.

[23] Ron Boschma. Proximity and innovation: a critical assessment. Regional studies, 39(1):61–74,

2005.

[24] Matt Taddy. The technological elements of artiﬁcial intelligence. Technical report, National

Bureau of Economic Research, 2018.

[25] J. Markoﬀ. Machines of loving grace: The quest for common ground between humans and

robots. HarperCollins Publishers, 2016.

[26] Ajay Agrawal, Joshua Gans, and Avi Goldfarb. Prediction Machines: The simple economics

of artiﬁcial intelligence. Harvard Business Press, 2018.

[27] I. Goodfellow et al. Deep learning. MIT press, 2016.
[28] A. Karpathy. The unreasonable eﬀectiveness of recurrent neural networks. Andrej Karpathy

blog, 2015.

[29] Ajay Agrawal, John McHale, and Alex Oettl. Finding needles in haystacks: Artiﬁcial intel-
ligence and recombinant growth. Technical report, National Bureau of Economic Research,
2018.

[30] Avi Goldfarb and Daniel Treﬂer. Ai and international trade. Technical report, National Bureau

of Economic Research, 2018.

[31] Greg Williams. Why China will win the global race for complete AI dominance. Wired UK,

April 2018.

[32] Ian Sample Science editor. Scientists plan huge European AI hub to compete with US. The

Guardian, April 2018.

[33] AI Index. The Artiﬁcial Intelligence Index: 2017 Annual Report. Technical report, 2017.
[34] Nick Bostrom. Strategic implications of openness in ai development. Global Policy, 8(2):135–

148, 2017.

[35] Vladimir I. Levenshtein. Binary codes capable of correcting deletions, insertions, and reversals.

Soviet Physics Doklady, 1966.

[36] G. Ver Steeg and A. Galstyan. Discovering structure in high-dimensional data through corre-

lation explanation. Advances in Neural Information Processing Systems (NIPS), 27, 2014.

[37] Jean-Michel Dalle, Matthijs den Besten, and Carlo Menon. Using crunchbase for economic

and managerial research. 2017.

[38] Stefano Breschi, Julie Lassébie, and Carlo Menon. A portrait of innovative start-ups across

countries. 2018.

25

[39] Alex Krizhevsky, Ilya Sutskever, and Geoﬀrey E Hinton. Imagenet classiﬁcation with deep
convolutional neural networks. In Advances in neural information processing systems, pages
1097–1105, 2012.

[40] Pierre-Alexandre Balland and David Rigby. The geography of complex knowledge. Economic

Geography, 93(1):1–23, 2017.

[41] Miles Brundage. Modeling progress in ai. In AAAI Workshop: AI, Ethics, and Society, 2016.
[42] Gary Marcus. Deep learning: A critical appraisal. arXiv preprint arXiv:1801.00631, 2018.
[43] Mayer-Schönberger Viktor and Cukier Kenneth. Big data: A revolution that will transform

how we live, work, and think. Houghton Miﬄin Harcourt, 2013.

[44] Philippe Aghion, Paul A David, and Dominique Foray. Science, technology and innovation
for economic growth: linking policy research and practice in ‘stig systems’. Research policy,
38(4):681–693, 2009.

26

